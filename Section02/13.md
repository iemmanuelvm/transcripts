 In this video, I'm going to discuss some motivations and procedures for simulating data with the goal of using those data to evaluate and understand data analysis methods. I will then present a few different formulas and a few different concepts for how to simulate different patterns in data. So let us begin. Essentially, there are two reasons to simulate data. One reason why you would simulate data is to make inferences about the brain, to understand something about how the brain works or of course, any other system. So here the idea is that you are building a model, you are simulating data that has some constraints in it, and those constraints can be biophysical. They can be cognitive constraints, morphological like if you're trying to understand the dynamics of individual neurons, you might want to incorporate the physical structure, the morphology of individual neurons. Of course, there's always practical constraints to keep in mind, and this is something like this. So this is an example. This is a screenshot of a software program called Neuron, where you can simulate the activity of a neuron using biophysical constraints and also morphological constraints. So what you see here is it looks like, you know, just a random collection of lines. But in fact, this is a an outline this is a geometric outline of a neuron. So here you see dendrites. And I guess this is probably the cell body. And here are more apical dendrites. These are the somatic or basal dendrites. Or you might have a model that looks something like this. Now, when you see a picture that looks like this, you probably think of deep learning. But before there was deep learning networks, we were using models that look something like this to understand something about the cognitive, representational and computational architecture of the brain. So this would be a model that has some cognitive constraints and maybe also a few neural constraints. So this is one reason to simulate data. There is an entirely different reason to simulate data, and that is what we are going to be doing here, and that is to evaluate, understand, optimize and improve data analysis methods. And the reason why simulated data or generated data is useful for understanding and evaluating data analysis methods is the following. First of all, when you're learning about data analysis methods, you can just stare at a bunch of equations. I could show you a bunch of equations that govern the data analysis method, but that doesn't really lead to a good understanding, particularly because analysis methods have a lot of parameters. And it's not always obvious what the parameters are doing to the analysis method and what features they will highlight in the data. So simulated data help with understanding data analysis methods. The second reason is that when you apply some analysis method to real empirical data, you really don't know what the result has to be. And that's because we don't really know how the universe works. We don't know how the brain works. So of course, if you apply some data analysis method to some data, you're going to get an answer, you're going to get a result, but you don't really know what that result means or if that result is correct. So the idea is that you generate data that has the qualitative characteristics of real signals that we are interested in, and you use that to test the analysis methods. And then the idea is, let's see, the idea is that you run you apply your data analysis method to the simulated data and you see what the output of the analysis method it looks like. And if the analysis method is good, if it is a valid, useful method, then you should get the right answer. And you know what the right answer is because you are simulating the data. So this allows you to validate the analysis methods. It also allows you to understand the advantages and limitations of different analysis methods, because if you simulate data in such a way or you select certain analysis parameters, you might not get the correct result from your analysis method. And then that will help you understand the limitations of the data analysis method. And let's see if you can read through all these other things. I don't want to talk too much about all these different things. Different analyses have different sensitivities to noise and signal features. And you might remember in the very beginning of this course, one of the first lectures maybe was even the first lecture I talked about how in real data we have signal and noise mixed together and they can sometimes be difficult to separate, to isolate. And when you simulate data. You can control how much noise is influencing your signal, how much noise is getting mixed in to the signal of interest, and that will allow you to determine quantitatively the sensitivity of your analysis methods. OK, so then the idea of simulating data is you start with your analysis method and then you have to decide on the key features of the data to simulate. And that's really based on your hypothesis. It's based on what you were looking for in the data, what features of the data the analysis method is tuned towards. Then you go about generating data in what I wrote here, matlab, because this course is all based in Matlab, but of course it's equally applicable to other languages. And then once you've simulated your data, you can analyze the data. So apply the analysis method to the data that you have generated and then compare the results of the method to the ground truth, which is what you have simulated. And this comparison can be sometimes as qualitative, sometimes it's more quantitative. And then essentially what you do is build some intuition by changing the data features. So, for example, the signal to noise ratio or the features of the signal, you can change the analysis parameters and just build some intuition. And then afterwards you go back and you vary the parameters systematically and these would be the analysis method parameters. So if this all sounds a little bit vague or maybe you're not totally sure what I'm exactly referring to here, then don't worry. You will see plenty of examples throughout the course where we will be starting from a data analysis method, simulating data, analyzing those simulated data and varying the parameters. All right. So with that as a general introduction, I would like to take a few moments now to talk about different ways of simulating data, so different ways of simulating noise and different ways of simulating features. And I approach simulating data from this general idea of spectral theories in mathematics. So if you study different areas of math, you might have come across something called the spectral theory. So there's many of these spectral theories. There's the spectral theory of matrices, a spectral theory of the 48 transform. And the general idea of spectral theories is that you can take something that seems very complicated and express it using multiple simple parts. So we break up a complicated problem or a procedure or a data set into a bunch of simple components that we just mix together. And so that's my approach for simulating data. We are going to be ultimately generating some, you know, relatively complicated data sets. These aren't like super duper complex. But we are going to be generating some kind of complicated data sets that are based on taking a collection of simple operations and mixing them together, combining them. And sometimes it's only going to be, you know, maybe just one or two or three components to the model. And sometimes there's going to be more. But this is just something to keep in mind. So what I'm going to do now is show you a few different ways to generate noise and to generate signal. So for noise, there's going to be two different methods for generating so-called white noise. I'll explain what that means in a moment. And also one over F noise. I will also explain that, of course. And then for these signal, we are going to be learning a few different methods for creating ongoing signals and transient signals that are stationary and non stationary. So let us begin. So here is a collection of random numbers that are just connected by a line. So this is just pure noise. So to create white noise, we can draw numbers from two different distributions, a normal distribution and a uniform distribution. A normal distribution, of course, is also a Gaussian distribution or a bell curve distribution. And essentially this means that we are drawing numbers from a distribution where the probability is highest for numbers that are close to zero, and the probability of drawing a larger number or larger magnitude further away from zero decreases as you get further away from zero, either positive or negative. Generating normally distributed noise is interesting because as you add more and more of this kind of noise to a signal in general, then you start averaging over more repetitions and this noise will will basically go to zero because all the negative numbers will cancel out the positive numbers. And of course, you can shift the distribution by adding some offsets that can move it around on the X axis, and you can stretch this distribution by multiplying it by some number so you can change both the mean and the variance of this blue normal distribution. And then we have a uniform distribution of noise where all the values between zero and one are equally likely to be selected. And there is no possibility of getting numbers less than zero or greater than one. In this course, we will mostly be using uniform noise for generating random phase values. So phase values vary between zero and two pi. So to generate random phase values, we start by generating uniform distributed numbers and then multiplying that distribution by two PI. So that's going to stretch this to go from zero to one up to zero to two PI. OK, so this is white noise. The feature of white noise or the characteristic of white noise is that it basically looks kind of flat, plus some random fluctuations both in the time domain and in the frequency domain. So the power spectrum of white noise also looks exactly like this. So in fact, if I know when I just show you this, you don't even know whether this is the time domain white noise or the frequency domain power spectrum of white noise. So that is quite different from one over RF noise, which is also sometimes called pink noise. So it's colored noise. And what's interesting is that you look at this time series and somehow it looks more like realistic, right? It looks a little bit more plausible. It looks more biological. Now, what's interesting is that if you would generate a histogram of pink noise, it would still look like a Gaussian distribution. So just by looking at the data, you know, the numbers themselves, you can't distinguish pink noise from white noise. But what distinguishes pink noise? What makes pink noise special is the temporal structure. So the way these random numbers are put together next to each other, and in particular the exhibit a feature in the frequency domain such that relatively low frequencies have more power and relatively higher frequencies have less power. So this gives a one over F or F this frequency shape in the frequency domain. And this is interesting because that generates more realistic looking data, so you will learn, for example, in the next section of the course about these, that one of the primary features of real electrophysiological data is this one over shape. So this is the key feature of these data we are looking for. We can actually manipulate the shape of this one over F spectrum. So you can make this more steep, you can make it more gradual. And what we are going to be doing in this case is generating the data first in the frequency domain or specifying the frequency domain characteristics that we want for the data and then taking the inverse Fourier transform to get back into the time domain. That is one of several methods to create one over F noise. All right. So that's a little bit about simulating noise. Now I'm going to tell you a little bit about simulating signals or the, you know, features in the data that we actually want to be focusing on and for ongoing signals. One of the main ways that we are going to do that is through a sine wave. And then we can also change this formula around a little bit or add some modifications to this basic sine formula to generate more interesting and non stationary patterns. So here is the main formula for the sine wave. It is a sign to PI F.T. Plus Theta A is an amplitude parameter. So it defines basically the height of of this curve. F is frequency, which defines the speed of the oscillation. T is time typically in seconds, and theta is a parameter that defines the shift on the x axis. So kind of taking this whole function and sliding it back and forth. So left and right on the x axis. I will be talking a lot more about sine waves and how to interpret and modify these parameters later on in the course, but this is just a quick introduction. So this I call ongoing stationary. It's ongoing because it's well, it's it's just ongoing and it's a stationary signal because its properties are not changing over time. So it has one parameter for frequency and one parameter for amplitude, and that is constant over time. We can modify this to have a non stationary ongoing signal and that's going to give us something, a result that looks something like this. So here you can see this is a sine wave. Now the amplitude is constant. So this sine wave is always going up to one and touching down to minus one here. But you can see that the frequency is actually changing over time. So here the sine wave is a little bit faster. Here, it's slower and faster and slower and so on. This is the formulas, the set of formulas that governs this time series. And so what you do is you start with a vector F that is the instantaneous frequency that you want the signal to have. And then Delta is the data sampling rate t is time. So it would be the, you know, each individual time point and this generates some other vector called X and then X goes into the sine function, which actually looks a little bit different from the sine function you saw on the previous side. So it's sine two PI times the quantity X of T plus T of T t looks a little weird, but this is just indicating that it's the time point in the vector of time points and that generates each individual time point in the output vector y and that corresponds to the signal that we are going to be generating. Now the reason why we care about creating data in a way that looks like this is that this is actually a closer approximation to the kinds of signals that are actually measured in real brain signals. So the oscillations, the Narrabeen activity in real brain signals is varying in frequency over time. And so we want to be able to simulate data to capture that feature of the data. That's really important because we want to make sure that our analysis methods are sensitive to or robust to, depending on what the goal of the analysis method is, these kinds of fluctuations in instantaneous frequency. All right. So that's ongoing, non stationary. Now, I'm going to talk a little bit about generating transient activity. And here we are primarily going to be focusing on using Gaussians and integrating a Gaussian with other features, like a stationary or non stationary ongoing signal to create transient narrowband activity. So here is the formula for a Gaussian. It is Y equals A times E and is the natural exponential to the and then it's this whole term here in this entire term is fractional term is in the exponent of this natural exponential here. So it's minus four times the natural log of two. This is like a normalization factor, times T minus C, that quantity squared divided by H squared so A and then so this is what the Gaussian looks like. So A defines the parameter A defines the peak amplitude. So in this picture, the parameter A has a value of one point five. That's the peak. So you can see if you don't specify a the default peak is going to be at one and then we have C, that is the peak time. You can see it's subtracted from T, so it's shifting the time vector. So in this case, the value of C would be zero point five. And then we have this parameter H here, which is called the full with at half maximum and the full with the maximum describes the width or the shape of this calcium. So that is quantified by finding the amplitude at one half of the distance between the base and the peak here. So this is 50 percent of the gain or the half maximum. And then you go from the half maximum before the peak to the half maximum at the peak. And you see what is the width here. So this looks to me like it's a little bit over a second. So let's say this is one point, one seconds. So then the full with that half maximum, this parameter is going to be for this particular Gaussian. This would be, let's say, one point one. So I'm going to be talking a lot more about Gaussians and the formulas for creating a Gaussian in the let's see, that's going to be the section in the course on time frequency analysis and. Morleigh Wavelet convolution, so this generates a time domain Gaussian. We can also generate a frequency domain Gaussian and the formula is similar, but a little bit different. The idea of a frequency domain Gaussian is that we are creating this Gaussian in the frequency domain and then we can take the inverse Fourier transform of these or this shape, this power spectrum. And then in the time domain, that's going to give us an interesting shape. It turns out to be something called a Mallee Wavelet. So the formula for creating a frequency domain, Gaussian is again the natural exponential, and I'm writing it slightly differently here. So here are E to the power of this stuff. And here I'm writing EXPE and then in parentheses, like this is a function of everything that would go or the term that would go into the exponent of the natural exponential E. So I'm using you know, sometimes I use different notations to give you a little bit of familiarity working with different mathematical notations. OK, but you can see that the formula looks overall pretty similar. So we still have minus and now it's F minus C and that quantity squared. And here F corresponds to a vector of frequencies and C corresponds to the peak frequency that we are looking for. So in this case, the peak frequency would be looks like seventeen point five. So that would be the parameter C divided by two S squared where S is a shape parameter and that is equal to H times two pi minus one divided by four PI. So this is really just a normalization factor. We're really concerned with H here and H is the parameter that's also the full with enough maximum, just like in the previous slide. But this is now the photograph maximum in the frequency domain. So let's see. I would say this is probably maybe this is a full with Araf maximum of six. So the parameter H, which might be six here. All right. So that is the different categories of noise and signal that we are going to be focusing on in this course for generating data in order to understand and evaluate data analysis methods. I know it's a lot to get through in a short period of time, but you have plenty of experience implementing these formulas and generating data using these procedures throughout the rest of the course.
You have seen now in many videos so far in this section that the frequency resolution, so the number

of frequency points that you get corresponds to the number of time points in the signal.

So we saw that with the loop in the 48 transform the loop that goes over the different frequencies and

computes the DOT product with the signal.

And you also saw that a few videos ago with the explanation of the perfection of the Fourier transform

and why we need to have an frequencies each corresponding to end time points in order to get an end

by end square matrix.

That is inevitable.

OK, so now I'm going to talk in this video about modifying the frequency resolution when you need to,

and that's done through something called zero padding.

So this is just a brief reminder that the number of frequencies, the number of sine waves that we construct

in the three transform is a product of PN or is determined by N where N is the length of the signal.

This is the number of time points you have in your signal and that we also see here.

So we have the reconstructed vector of frequencies in Hertz and that goes from zero to Nykvist in N

over two plus one steps.

So the implication of this is that if you have a signal that has a relatively few, a small number of

time points so you don't have so many time points in your signal, the frequency bounds are fixed,

they are fixed at the low end by zero and they are fixed at the upper upper bound, the upper limit

by the Nyquist frequency.

Now, I'm going to talk in a moment about changing the sampling rate, but for now, assume for the

next few slides, assume that we have a signal with a fixed sampling rate.

So we are not changing the sampling rate.

All we're doing is taking shorter or longer segments of that signal.

So here we have a short signal with only a few time points, and that means we have pretty sparse frequency

sampling here.

Now, imagine what happens if we take more time points from that same signal.

So we just take a longer data segment.

Well, M is now higher, so zero hasn't changed.

The Nyquist frequency hasn't changed because we still have the same sampling rate, but we have more

points between Zero and Nykvist.

So the frequency resolution is higher and now we can take this to an even more extreme.

We can take an even longer segment of data, again, keeping the sampling rate the same.

So now we have this is a technical term here, buckets of time points, multiple buckets.

So we have to carry around lots and lots of time points.

And that gives us a very fine frequency resolution.

So a lot of frequency points between zero and Nykvist.

So what this means is that the frequency resolution is determined by the number of time points.

Now, you might have already been guessing and I've already mentioned something about the sampling rate.

So it is also true that if you have a relatively small number of time points, you have sparse frequency

resolution.

And then if you change the sampling rates, let's say you down sample the data, but keep the number

of time points the same.

That is actually going to increase the frequency resolution because you have the same number of frequency

points, frequency bins.

But the Nyquist is now lower, so those get packed into a smaller area.

So this is also true.

So it's also true that the frequency resolution is determined by the sampling rate.

However, in real practical data analysis, it is generally the case that once you sample your data,

once you record the data, you don't often change the sampling rate.

So you do a bunch of different analyses and you typically keep the sampling rate the same.

So therefore, this is the right way to think about it, that the frequency resolution is determined

by the number of time points.

So what do you do if you want to have more frequencies between Zero and Nykvist?

Let's say this is as big of a as long of a segment as you can take, but you really want to get this

frequency here because this frequency is important for your experiment for whatever reason.

Perhaps this is the frequency that you are flickering a light and you want to see the exact light frequency

represented in the brain.

So what can you do if you cannot just arbitrarily cut longer segments?

What you can do is a procedure called zero padding.

So as you might guess from the name, what we do in zero.

Padding is pad the signal with zeroes, so that looks like this here is our original signal.

It's just a little hill, but this is the original signal and what I've done here is zero pad.

So I've added a bunch of zeros to the end of the signal.

So here the signal is 20 points.

Along here, the signal is 40 points along.

So now it has twice as many points.

And that means that when we take the Fourier transform of this this signal, it's going to have twice

the frequency resolution as this signal.

Of course, we are still going to start with zero hertz and we are still going to go up to the same

Nyquist frequency because we're not changing the sampling rate.

We are just adding more data points.

And here is the important note that when you zero pad, you always add the zeros after the signal,

you don't add them before the signal.

You don't interspace the you know, the signal with zeros in here would give you some funny looking

signal.

You always put the zeros after the signal.

This can be a little bit confusing because when I talk about time domain convolution in the next section

of the course, we are going to be discussing zero having both before and after.

So with the Fourier transform for zero padding, for increased spectral resolution, you always zero

pad afterwards.

Fortunately, you generally don't really do the zero padding manually.

You let matlab do it for you in the FFE function and you'll get to see that later.

So why do we add zeros and not some other number?

Well, the idea is that a zero is not containing any additional information about this signal, so we're

just adding nothing to the end.

Now, there's a bit of a philosophical debate to be had about whether adding zeros is really adding

nothing, because here, in fact, we have no idea what happens after time point twenty.

So from time point twenty one to ten point forty, we have literally no clue whatsoever what is going

on with this signal because we didn't measure it out here and here.

What we are doing is assuming that the signal has zeros out here.

So in some sense, we are actually adding information that there was nothing happening here.

Nonetheless, this is the mechanism of zero padding to increase frequency resolution.

So this slide shows how to zero.

The question is, why would you zero?

What are the motivations for zero padding in practical data analysis?

There are in fact, three motivations for zero padding.

Your signals in the foyer transform, one of which I already mentioned, and that is to obtain a specific

frequency in the 48 transform.

So again, just to go back to this slide.

So imagine this resolution is the highest you can get with the data segment that you have, but maybe

it's really important for you to get exactly this frequency here.

Now, the thing is, based on the raw segment that you have, the original data segment, you don't

have any way of knowing what was going on here.

So what you do is add zeros to the end of the signal, and that allows for more frequencies, more sine

waves to be constructed.

So that is one motivation for zero having another motivation.

It's actually the third is just to smooth the spectral plots.

And here it turns out that as you add more and more zeros, you're basically interpolating the spectrum.

So you're just making the spectrum look a little bit smoother.

It tends to look a little bit nicer.

So for visual quality, for facilitating visual inspection, people will zero pad their signal in the

foyer, transform the second reason here.

The second motivation for zero, Petie, is to match the FFE lengths for convolution.

Now, if you're not already familiar with the mechanisms of convolution and in particular the convolution

theorem, then this statement probably doesn't make any sense whatsoever.

That's totally fine.

You can just pin this in the back of your brain and we will come back to it in the next section.

But essentially what we want to do in convolution is take the 48 transform of two different time series

and then in the frequency domain, we want to multiply their Fourier spectra frequency by frequency.

And so for that operation to be valid, their spectra need to have the same lengths.

They need to match up in all of the frequencies.

So then it becomes necessary to zero or two signals to make sure that they have the same length, the

same frequencies in the frequency domain.

Again, I will talk a lot more about this idea in the next section of the course.

So here you go.

Three reasons for zero padding.

And the mechanism is always that you add zeros to the end of the signal like this.
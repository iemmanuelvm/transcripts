Let us continue our adventures on spectral analyses of EEG resting state data.

Here we are going to use a different data set.

It has a different name you can see.

And the idea is that we are going to quantify alpha power over the scalp.

So if you are not already familiar with this term, Alpha Alpha refers to approximately 10 hertz oscillations

in the human cortex.

Now, I say approximately because there are some non personalities, there are also individual differences.

So the exact frequency will vary not only within a person over time, but also across different people.

So usually people would call Alpha Power something like eight to 10 hertz or, you know, different

people might use a seven to, uh, I'm at right at twelve before eight, 12 hertz or maybe seven to

13 hertz.

There are no exact boundaries, but it's approximately 10 hertz, plus or minus some reasonable width.

All right.

So what we're going to do here is load in this data set.

And of course, the first thing you should do is look to see what we have.

So we have just one variable in this mat file called EEG.

So this is an EEG lab structure.

And we've already had a look at these kinds of data structures before in the first section of this course.

So let's have a quick look here.

So what are the interesting fields in this structure?

We see that the number of channels is sixty for the sixty three trials or Epic's each apoc has two thousand

forty eight points with a sampling rate of one thousand twenty four.

So that means that each apoc each of these trials is exactly two seconds long.

And then we can look down here at the field data and that is a three dimensional cube of numbers.

So we have sixty four channels, twenty nine points and sixty three trials.

OK, so that just tells us a little bit about this data set.

Let's see.

So these data have 63 outputs.

Each episode is a two second interval cut out from around two minutes.

So we want to do is compute the power spectrum of each epoch separately so each two second segment of

data separately and then we average the power spectra together.

So that's important.

We're not going to average the time points together in the time domain.

Instead, we want to extract power from each segment of the data and then average the power spectra

together.

OK, and then so that's going to be the first step.

Once we finish this goal, then we want to extract the average power from between eight to 12 hertz

and then make a topographical map.

All right.

So let's get started.

Looks like the first thing we want to do is convert the data to double precision.

So when you look at this data here, you can see it's a 3D cube of numbers, but it is single precision.

So converting data to single precision means that you are losing a little bit of information.

You're losing some precision in the numbers.

Now, that can be useful because it reduces the data storage space.

So it makes the data files, the map files smaller.

On the other hand, some matlab functions either don't work or give more accurate results when the data

are in full precision or double precision.

So what we want to do is convert these data from single precision to double precision, and the function

to do that is just called double.

All right.

And then what we want to do is compute channe power.

So before we even start, let us think about what the size of this matrix should be.

So Channel Power actually should have the same size as the data matrix, right?

It should be the power values from the fifty, from all the channels and all of the Epic's and all the

segments.

And from all of these here it's time points.

But when we do the eight transform, we're going to get two thousand forty eight frequencies.

So in fact, this is going to be the same size as the EEG data.

Now, there's a few different ways to extract the channel power using F.T..

One way you could do it would be to have a double for loop.

So we could say for Channel I equals one to EEG, that number of channels, and then we could have four,

uh, trial I equals one to EEG trials and then we can compute the channel power.

As you know, this would be ABS and we need two times abs fifty of the data from this channel.

All the time points and this trial and so on, now this is totally fine if you set this up in a double

for loop, that's great.

That is a perfectly good solution.

What I'm going to do now is show you a slightly more advanced way to do this, and that is taking advantage

of the fact that the FTC accepts matrices as inputs.

So what I'm going to do is open up this F.T. file.

Now, this runs a compiled library.

So we don't actually see all the code down here.

We just see all of the comments in the help file.

So you could also type help 50, not 50 to help 50 and then get all of this information here.

I often find it easier to just open up a function file to read the help text like this.

That's, you know, then it's always here.

I don't need to worry about scrolling and all of this business.

OK, but what I wanted to show you was the optional inputs here.

So F.T. X, where X is a matrix of data and then we have the second input is empty and then the third

input is dim for dimensioned.

So that applies the FFE operation across the dimension DEMN.

And this second input is the number of points to extract for the FFE.

This is related to something called zero padding and changing the spectral resolution of the Fourier

Transform results.

That's a concept that I'm going to talk about in a few videos from now.

So we are just going to ignore the second input, but we do want to pay attention to this third input.

So let's see.

This is going to be pretty cool.

We are going to take the FFE and we're going to put that back in.

But for simplicity, I want to just start with just the FFE function.

So we are inputting the FFT data.

And now the question is, what is the dimension along which to compute the FFT?

And we have to think about this for a moment.

So if we were to compute the Fourier transform along the first dimension like this, we are actually

computing the Fourier transform across channels across the sixty four channels.

Again, that is, you know, in terms of like coding, it is technically correct.

We're going to get a result, but it is not a sensible thing to do.

Likewise, it is not sensible to compute the 48 transform across trials.

That doesn't make sense.

We want to compute the forty eight transform over time and time is in the second dimension.

So what we are doing now with this result here, let me even run this code.

What we are doing here is computing the channel, uh, FFT.

So it's not yet power, but here we get a matrix of Fourier coefficients.

There's four sixty four channels, two thousand forty eight frequencies now and sixty three epochs.

All right.

So this one line is the same thing as breaking this up into two loops over channels and over approx.

OK, so then we want to extract the amplitude and we also need to divide by PN, which is the number

of points.

So these are the two normalization factors for amplitude.

And then we want power this as power here.

So now I'm going to encase this in parentheses and say power, OK, now run that code, don't get any

errors.

So you can see it's actually a fairly complicated line of code.

There's a lot of stuff going on in this one condensed line of code.

And if you are ever confused at a dense line of code like this, the way to go about figuring this out

is to start with the innermost piece of code and then slowly work your way out.

And the innermost piece of code is the code that is inside the most number of parentheses.

So that corresponds to this.

We have the data and then it goes into the F of T function, goes into ABS and then gets squared.

All right, let's see.

So then we want to average over trials, uh, already around that.

OK, so we average over trials.

And then what we expect to see is a matrix of size channels by frequency's and that's exactly what we

get here.

Channels or trials is in the third dimension.

So we are taking the average over the third dimension.

All right.

So then we get a vector of frequencies.

You've seen this kind of code several times before.

And then here we are going to make a plot of the power spectrum for all of the channels at the same

time.

So this is pretty interesting.

You can see actually, let me I'm going to run this again.

Let's see a.

So here we actually don't see much.

It's kind of hard to see what's going on because this one over Heff is superduper steep.

Look how steep that is.

So I'm going to zoom in a little bit.

Let's see.

So set before setting the y axis limit, I'm just going to tighten up the x axis limit.

So this is pretty interesting to see what enormous variability there is in the power at these low frequencies.

And like I discussed in the previous video, let me zoom in to about three hertz.

Like what I mentioned in the previous video, it's difficult to say whether this is an actual peak at

one hertz or whether this is an artifact of having a real one over a spectrum, plus a high pass filter

at zero point five hertz or so.

So without knowing more about what happened to these data, I would be reluctant to interpret this as

a peak.

Now, if you gave me this data set and you told me that this was really the raw data, the only thing

you did was subtract the mean.

You mean centered the data, but you didn't do any trending.

You didn't do any high pass filtering, then we would have enough information to look at this and say,

OK, this is definitely a peak.

Otherwise, I believe these data actually were high pass filter at point five hertz.

So I don't think that this is a real peak.

OK, anyway, so what's interesting to note is that you see quite some variability and also quite some

consistency across the different channels.

So some channels have really, really a lot of low frequency power.

Some channels look like they have a little bit of a peak here.

We see this pretty healthy, robust alpha peak at around, you know, 11 hertz or so, 10, 11 hertz.

You can also see that it's it's more prominent in some channels, less prominent in other channels.

And then it's also interesting to see that there's a little peak here, around 20 hertz.

Twenty five hertz.

And it's only a couple maybe, you know, maybe three channels seem to have some energy at twenty to

twenty five hertz.

So it's pretty interesting just qualitatively to look at this.

Now, the thing is, we want to know where are these channels on the head, these three channels versus

let's say the three channels with the lowest alpha power.

Now, we can't extract that information from this plot.

What we want to do is create a topographical map so we can see how these dynamics are distributed over

the scalp.

And so what we are going to do, the way we are going to approach this is by averaging all of this.

So we're not just taking the peak value.

We are going to take an average.

Averages tend to be a bit more robust to noise or non representative samples.

So average the data around a window here and then make a topographical plot across all of the channels.

All right.

So let's see now to extract Alpha Power.

I'm going to define the boundaries in Hertz to be eight to 12.

And then here we need to convert those into indices.

So the thing is that if we look at Hertz eight and 12, you can see that the 8th index into the vector

Hertz is three point five hertz.

So if we would just take the average of power from eight to 12 in frequency indices, that's actually

like this range here, which is fine.

You could also plot that.

But what we are interested in is Alpha here.

So we need to figure out what are the indices in the Hertz vector that are as close as possible to eight

and 12.

So I'm going to do that using the D search and function.

So we first input the vector that we want to search through and then we want to input the values that

we want to look for.

Now, this is going to produce an error.

And if you're ever using it, well, OK, that's not the error that I expected.

Uh, this is the error that I was expecting.

So if you're ever using D search N and you see an error that looks something like this, X and XYZ should

have the same column dimensions.

The solution to fixing this problem is pretty simple, essentially d search and is always expecting

column input.

So it once the inputs to be in columns.

So we can see this is a row vector, this is not a column vector.

So we need to transpose this to make it a column vector.

And now unfortunately it's still going to give us an error because this variable alpha bounce, you

can see it's also a row vector.

We need to make this a column vector so we could transpose it here and then it's going to work.

And you could have also left this as a row vector and transpose it here.

You can see now that alpha bounce is a column vector.

So now let's see, Freck IDEX is seventeen and twenty five.

So that's interesting.

So now we see that the 17th and twenty fifth index into the power spectrum correspond to eight to 12

hertz.

All right.

And now we want to extract the average power from those two boundaries, or that is, say, all the

data points between those two boundaries.

So let's see, here we are.

Obviously, there's something wrong going on here.

So we want channel power from all of the channels, from these indices.

So that's not quite correct.

But I'm going to get back to this in a moment and then let's see, then we want to.

OK, so actually we need so you can see this parenthesis is additional.

We have one in parentheses, too many.

You can see when I put the the cursor over this.

Parentheses, and it gives me this horizontal line going through it now that fixes the problem of the

parentheses, but it still doesn't give us what we want.

The problem actually is that this comma, too, is supposed to be inside the mean function.

This comma, too, is telling us that we should be averaging over the second dimension.

Now, the thing is, the way this code is written here, it's going to get frequency's 17 and and 25

and indices, which is eight and 12.

So let me zoom in a little bit and show you why this is an error, why this is not the right thing to

do.

Let's go.

How about six to 14 hertz?

So what this code is doing is only getting these two specific values at 17 and twenty indices, which

corresponds to eight and 12 hertz.

So if you just run this line of code, what you're averaging together is all of these data points and

all of these data points, you are totally missing this actual alpha burst here.

That's the thing that we want and we're totally missing it.

So what do we actually want to do?

Well, we actually want to do is take all of the points, all of the frequencies between and including

eight and 12, not just eight and 12.

So let's see.

So that is the first index to the second index.

And this is now going to give us all of the numbers between seventeen and twenty five.

So all of these that's also interesting, by the way.

You can see that this power spectrum is still relatively narrow.

So even eight hertz might be a little bit too low.

Nonetheless, that's what the instructions were.

So I'm going to stick with eight and 12 for now.

All right.

So the size of this variable is 64 by one.

So there's 64 numbers in this vector.

Is that really the right answer?

Is that the the proper size that we expect for this result?

The answer is yes.

It definitely is.

And the reason is that we want one average power value per channel, and that's what we get.

We have sixty four channels.

All right.

So let's make a plot.

And here you go, there we see the topography of alpha power.

It is maximal at posterior central site.

So here we get the most amount of alpha power and then there's also, it looks like some alpha power

up here all the way at the front.

Maybe this is some artifact or something.

And it looks like there's a little bit of alpha power at some other electrodes as well.

But the strongest one is here.

So that's the end of this video.

I hope you found this exercise interesting and enjoyable.

What we did here was take the principles of static spectral analysis that we have learned about in the

past several videos and applied them to real data sets to get some qualitative inspection of average

alpha power.


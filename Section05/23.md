The goal of the Fourier transform is to get a time domain signal into the frequency domain, that transformation

from the time domain into the frequency domain is absolutely perfect.

It is lossless.

The Fourier transform is not an approximation of the signal.

It is an exact representation of the signal.

So no information is lost.

That is what I mean by the perfection of the Fourier transform.

In this video, I'm going to provide two explanations for why the Fourier transform is a lossless operation,

why we don't lose any information in the foyer transform.

So I'm going to talk about this from a statistics perspective.

This is a bit of an analogy and also from a linear algebra perspective.

In fact, these are really just different ways of looking at the same explanation.

But I hope that you either have a statistics background or linear algebra background.

So I hope that at least one of these explanations, maybe even both of them, will gain some traction

with you and will help you understand why the foyer transform is lossless.

So let's start from statistics.

Let's think about a multiple regression problem.

So imagine we have our data set here.

That's the signal.

And we have a series of independent variables.

So the time domain signal is the dependent variable and the complex steinway's is our independent variables.

So again, we are thinking about this like a multiple regression problem or an ANOVA problem where we

are trying to account for variance in the dependent variable.

So the time domain signal based on variability in the independent variables.

So here's the thing.

In the 48 transform, we have any data points.

So the signal is endpoints long and how many complex waves do we have?

Well, we have any of them.

Half of them are the positive frequencies, half of the negative frequencies.

But for this context, that doesn't matter.

We have NP progressors and they are all independent of each other.

So there is no redundancy.

They're all separate from each other.

So now if you're trying to build a multiple regression model where you were trying to explain variance

with of NP data points based on any independent variables, the question is how many degrees of freedom

do you have and how much of the variance in the dependent variable do you account for within progressors?

Well, the answer is that you end up with zero degrees of freedom because you have the same number of

predictors as you have data points.

So you necessarily explain one hundred percent of the variance.

There is no residual variance in the dependent variable.

All of the variance is accounted for by these set of independent variables or explanatory variables.

Now, from a statistics perspective, if you're explaining this idea to a statistician, that statistician

would tell you that this is a terrible model, right?

A statistical model shouldn't have zero degrees of freedom.

It shouldn't explain one hundred percent of the variance.

But the goal here is not to have a compact, minimal representation.

The goal here is to have a complete perfect representation.

So therefore, it actually makes sense to have a set of basis functions, a set of independent variables

or explanatory variables that account for 100 percent of the variance in the signal.

So this is one perspective.

This is one analogy for thinking about why the Fourier Transform is a lossless operation.

So now I'm going to explain this again from the perspective of linear algebra.

So what you're looking at here is a matrix of complex sine waves.

So remember that in the loop to implement the discrete time for a transform, you loop over frequencies

and then at each frequency you create a complex valued sine wave.

So imagine taking all of those complex values sine waves and putting them inside of a matrix.

It would look like this.

So here we have time on the x axis and this is frequency on the Y axis.

So, for example, you can see the top line here is two flat line.

So we have the yellow line and the white line.

So the yellow line corresponds to the real part and the white line corresponds to the imaginary part.

So this first line here is straight because that is the DC component.

That's the zero hertz frequency.

So that's just a vector of all ones.

And then we get to the next line, which is still this pair of white and yellow lines.

And here it's corresponding to the real part and the imaginary part of the complex sine wave.

So do you see as you go down, is that these sine waves are getting faster and faster until we get to

the middle where we have the Nyquist frequency and then after the nightclothes frequency, it looks

like they're getting slower and slower.

As I mentioned in a previous video, what's actually happening is that these Steinway's are still technically

getting faster.

But because the sideways down here are faster than the Nyquist frequency, they are getting aliased

into lower frequencies.

So this is the positive frequency spectrum.

This is the negative side of the frequency spectrum.

OK, so that is what this matrix represents.

Now, notice already that this is a square matrix.

Well, OK, it doesn't actually look totally square here in this picture.

But remember that we have an Steinway's and complex valued Steinway's and each individual sine wave

is endpoints long where PN is the length of the signal.

So that means that this is an N by N matrix.

OK, so then what we do is we take our signal and we put that into a vector.

Now here in this vector, time is actually going down on the Y axis.

So it's a little bit different from here where time is on the x axis.

So time is going down and the X axis here now corresponds to the voltage fluctuation.

So this would be positive and negative voltage fluctuations.

So now what we do is multiply this matrix by this vector and that gives us another vector and that corresponds

to the DOT product between each row here in this matrix, which is each complex volume sine wave and

this signal here, this real valued signal.

And that gives us a complex Fourier coefficient at each point here, which is now corresponding to frequencies.

All right.

So let's call this Matrix F for Fourier Matrix.

And remember, this is an end by N Matrix.

OK, we're here.

I'm calling an M by M, but the point is that it's a square matrix and it is a full rank square matrix

that has a rank of M or I guess I should call this NP because I use the end for the number of time points.

But anyway, so this is a square full rank matrix is full rank because every row is independent of every

other row, and that's because all of these leaves have different frequencies.

Even for the positive and negative side of the spectrum, the imaginary parts will have a phase offset.

So there is no redundancy in this matrix.

So what does that tell us about this matrix?

Well, what that tells us is that this is an inverted matrix.

This matrix has an exact inverse so we can write out this equation.

So the Fourier matrix F times the data vector X equals the four A vector X.

So this is the time domain signal and this is its Fourier spectrum.

So this is the equation that I showed in the previous side.

And now the question is, how can we solve for X if we already know capital X?

So we already know the Fauria coefficients.

How can we find out the Time series data again?

Well, this is pretty easy.

We know that this matrix is investible so we can invert the Matrix F and put it on both sides of this

equation.

Now, the fact that this matrix is investible tells us that this is a perfect transformation matrix.

There's no information loss, there's no null space.

There are no empty or null parts of this matrix.

So.

It's a perfect linear transformer, it can go from one side to the other side of the equation through

the forward matrix or the inverse operation, and we don't lose any information.

So there you go.

In this video, I gave two analogies for why the freeway transform is a lossless procedure from the

perspective of statistics and from the perspective of linear algebra.

I hope that at least one of these explanations, or maybe both were intuitive and understandable to

you.

In the next video, I'm going to continue discussing this concept of the implication of the perfection

of the Fourier transform for computing this inverse and getting from the frequency domain back into

the time domain that's done through the inverse Fourier transform.

And I'm looking forward to telling you about that soon.
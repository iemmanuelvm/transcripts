In this video, we're going to work with Topographies and we're going to do a couple of things, make

topographies over time so we get a time series of topographies and also look at different options for

plotting topographies and compare plotting and topography from a single time point compared to topographies

from an average around a Central Time point.

So let's get started.

We're going to load the sample EEG data set that we've been working with quite a bit here.

I'm going to find the time points that I want to plot the topographies of.

So basically we are going to plot the topographies of the voltage activity at minus two hundred milliseconds,

minus one hundred and fifty milliseconds, minus one hundred milliseconds and so on, skipping insteps

of 50 milliseconds all the way up to eight hundred milliseconds.

Now, the thing is that we need to figure out a way to convert these time points in milliseconds into

indices.

In the data set, so here I'm showing you two ways, one is four lines of code, one is one line of

code.

Both are fine here.

Essentially, we are comparing the time vector against each time point that we want.

So it's done in a loop.

And then we take the minimum of the absolute value of this difference, which will basically return

the closest time point to that function minimum.

Now it turns out that this is also going to give you exactly the same result using the function search.

And however, it's interesting to note that this method, even though it has the loop and even though

it has four lines of code, this is actually faster than D search.

And now if you're only searching for a couple of time points in this case, this is, let's see, twenty

one time points.

So in this case, it doesn't really matter.

Maybe it's a difference of a couple of milliseconds, but it can happen if you are really searching

for many, many time points.

If you have to convert many, many time points, let's say thousands of time points or tens of thousands

of time points from milliseconds and indices or frequencies into indices or anything else like that,

then it turns out that this is actually going to be quite a bit faster than this search and method.

Another thing I would like to point out about desertion is that it wants to work with the vectors Columbines.

So if you run decirte end and you get an error that looks like this X and XY sort of the same Collum

dimension, the first thing that you should think of is checking whether one or both of these vectors

are real vectors or column vectors.

You can only see that this one is a row vector.

So I'm going to transpose this.

However, when I run this line again, I still get the same error.

And it turns out that EGT Times is also a row vector, so therefore that also needs to be transposed.

OK, so here we're going to create a topography time series at exact time point, so these exact time

points and actually maybe I'll show you this for your reference.

So here we have times to plot.

I'll just put this out again and then we have ITG times and then he idex so you can see that these are

not exact.

And that's because there is no time point corresponding to exactly minus two hundred milliseconds in

the data.

The closest we can get is minus one hundred ninety nine point two one eight eight.

And then there's probably some other numbers after that.

Now of course this is really, really close.

You don't really have to worry about this.

You might as well just call this two hundred milliseconds.

OK, so what we do here is go in a loop and I'm looping over all the time points here.

I create the subplot.

I'll talk about these two variables in a second and then I'm using this tuple plot in the function which

you've seen before, for example, when projecting dipoles onto the scalp.

And then I compute the average to the mean of the EEG data from all of the channels and only this one

exact time point and all the trials.

And then I'm averaging over trials.

So this is computing an ERP now.

You could if you prefer, you could compute the ERP outside here so you could say something like compute

the ERP and then say ERP equals, then this would be mean here.

And of course now it's not this one time point.

This is all the time point.

So you could do this.

But it turns out that if you say, you know, everything with Colon's like this, then it's actually

easier just to leave the colon's out.

So then here you would want to say ERP all channels and just this one time point.

So either of these methods are fine.

Technically this is a little bit faster.

This is a bit better because you were pre computing this matrix.

So you don't need to rerun the mean every time inside this loop.

On the other hand, in this particular case, it's not such a big deal because this is a fairly small

matrix.

So the increase in computation time here is not really a major factor.

And actually, no, I would like to comment about this line.

So let me run this and show you what it looks like.

Now, I have these two lines of code here that say, sublight GMR and supply GMC.

So this is for subplot geometry and then the rows and the columns.

And basically this just computes for any number of time points that we're going to plot.

So any number of topographies, topographical maps, this figures out how many rows do we need and how

many columns we need to fit all of these topographical maps in here.

OK, so now let's think about what we were looking at here.

So these are ETG topographies.

Again, you imagine you're looking down on the top of someone's head.

So this is the nose, the left here and the right ear.

And the colors correspond to interpolated electrode active or voltage activity across the different

channels.

In this map, in these maps, each dot corresponds to the physical location of an electron, OK, and

then you see here indicates the time.

So at minus two hundred milliseconds, the topography looks like this at plus three hundred fifty milliseconds,

the topography looks like this and so on.

Now it's a little bit difficult to compare across the different maps, and that's because the color

axis is scale uniquely for each of these maps.

So each of these maps has its own color scaling.

So I can show you that I'm going to click on this map to activate it and say, get Selam.

So this map goes from minus five to plus one, whereas this map here at four hundred milliseconds goes

from minus.

Oh, wait, did I do that?

Right.

So this goes from point one to plus eight point five, so these these two maps are kind of comparable

in some sense because you can compare the topographies, but the color is totally different.

So this red here is actually somewhere around eight and a half micro volts, whereas this red here is

somewhere around one microphone.

And that is why it's useful to explicitly specify the color limits and that you'll see now and now when

all the color limits on are the same, all the topographies has the same color limit.

You can directly compare these maps against each other in terms of the color.

So now you see that actually before time zero, there's really nothing repeatable.

There's nothing phase locked before time zero.

And that, of course, makes sense.

The individual whose brain we were recording here didn't know what was happening before time zero.

OK, so these are for exact time points and now we can make this a little bit more robust.

So individual time points might be a bit noisy.

There might be some unrepresentative data in an individual time point just by chance.

So therefore it's often useful to average around a particular time point.

So now what I'm going to do is repeat this procedure, except instead of plotting only the value from

one hundred and fifty milliseconds, it's going to be the average values from one hundred forty milliseconds

to one hundred and sixty milliseconds.

Approximately, and that's given by this time window here, so here it specified in milliseconds, this

is half the window and here I convert that into Ines's.

So basically for a time window of 10 milliseconds, how many sample points does that end up being?

So the formula is this.

You just have to divide it by 1000 over the sampling rate.

And the one thousand is just a factor to get us into milliseconds.

So with a sampling rate of two hundred and fifty six hertz, it takes two point five six samples to

get exactly ten milliseconds.

Now that's going to cause some problems for indexing.

So therefore I.

So then we can say that three times depth is approximately ten milliseconds, actually a little bit

over 10 milliseconds.

It's around 12 milliseconds.

So now that changes this topographical map slightly because now instead of just averaging the data over

trials, so averaging over the third dimension, we also need to average over the second dimension,

which is time points.

So now I've created this separate variable here times to average, and that is the center time point

minus the time window to the center time point plus the time window.

So we can see that this is going to be seven time points long.

And that makes sense because it should be the center time point minus three to the center time point

plus three time points.

All right.

So I will plot this and I'm putting this in a separate figure.

So this is figure to previously read and figure one, and that's going to allow us to basically go back

and forth between these two and compare them.

Now, you will already notice that there are some remarkable differences between these topographies

and these topographies.

In particular, I've turned the electrodes off.

Let me go back here, turn the electrodes off.

So now that it's not plotting the black dots for the lecture locations and I've specified the number

of contours to be zero.

So here you see there are these ISO contour lines.

And here I've specified that there should be zero contour lines, which means that there are no contours.

Now, personally, I find these maps to be a little bit nicer to look at.

They are a little bit cleaner, but this is a matter of personal preference.

So now I'm going to go back and forth between these two.

And actually, you know, I think it's probably just in the interest of comparing these directly.

I'm going to rerun this code with this option, with these options commented out.

OK, so now we can compare figure two.

This was with a window and figure one.

This was just with a specific time point.

So you can see going back and forth between these two, they're not identical, but they're also not

hugely different, which is good.

You know, we're only averaging twenty milliseconds.

So if they looked really different than probably there was a coding mistake somewhere, but I would

argue that figure to.

So computing a window around the mean, around the peak time point, I mean, is a better way to go

in real data because this method is more robust to individual noise peaks or non representative data.

The final thing that I would like to point out in this video is that it's interesting to compare these

results with and without the average reference.

So I encourage you to take a minute now when the video ends, to add a line of code here that will compute

the average reference of the data.

Then you can make these topographical maps with average reference versus what you see here, which is

the yellow reference, how the data are stored in the matched file.

And when you do this, it's also a good idea to put the common average reference topographies in a different

figure so that you can go back and forth between the two figures and have a more closer qualitative

look of the differences.
 I'd like to start with a general discussion about why it's useful to simulate data and how to go about simulating data. First of all, there are two reasons, two general reasons to simulate data in neuroscience. One is to simulate data in order to test data analysis methods. This is the primary motivation for simulating data in this course. And I'm going to talk more about why simulating data is useful for testing data analysis methods in a few minutes. First, I just want to tell you the other reason is to make inferences about the brain or about any other biological or physical system that you are interested in studying. So here with this second point, the goal is to derive a set of mathematical equations that are constrained by biology or that somehow reflect principles of biology, and therefore the goal of simulating data is to understand something about the brain. Now, that is not what we are doing in this course, in this module. And the key difference is that if you are generating test data to understand data analysis methods, you don't necessarily have to be constrained by biology. And I can give you an example. Take a pure sine wave. Now, the brain does not generate pure Steinway's. Certainly the brain generates a lot of rhythmic activity. The brain generates a lot of activity that is sinusoidal. It looks a little bit like a sine wave, but it's not a pure sine wave. So generating pure sine wave is not going to tell us a whole lot about how the brain works. However, generating signals with pure Steinway's can be a really powerful and insightful method for generating test data to understand data analysis methods. So that's one example. So there are several reasons to stimulate data for testing and data analysis methods. For example, and this is probably the primary reason simulated data allows you to validate your data analysis methods with ground truth data. Now, the thing is, when you have real data, empirical data that's measured from the brain or any other system, you don't actually know what the real truth is. Of course. I mean, that's kind of the goal of science. If you knew what the real truth is, you wouldn't need to do the experiment and collect the data. So the problem is that if you get some results from some new data analysis method, then you don't really know whether that result reflects something that's really out there in the system or it's just some quirk of the method. So when you simulate data, you can test your analysis methods and you know what the result has to be, you can quantify how closely the result matches the simulated data. Furthermore, simulating data allows you to understand the advantages and the limitations of the analysis methods that you're applying, no analysis methods are perfect. All analyses have advantages and limitations. And using ground truth data will let you understand how robust the method is, for example, to various amounts of noise or maybe different kinds of noise, different types of signals and so forth. Third, simulating data allows you to understand better how the analysis methods work, and that's a really important concept. So it's important to understand how analysis methods work for when you are applying analyses to empirical data. Fourth, simulating data will help you understand your data better. And that's because although the simulated data don't necessarily need to have biological or biophysical constraints, the data do need to have characteristics that are similar to the data that you acquire. So simulating data forces you to think about what are the key characteristics of your observed signals. And this, in turn leads you to think more carefully and more critically about your data and the more carefully, the more critically you think about data, the better your analyses are going to be and the more appropriately you will be analyzing your data. And also, for this reason, simulating data, I believe, improves your thinking skills, your critical thinking skills, it also improve your programming skills. And finally, I think it's fun. Maybe you disagree, but I think simulating data is just a little bit of fun to do. OK, so here's another important point data analyses on their own are never right or wrong. Analyses are appropriate or inappropriate for some particular situation or some particular types of data. All data analysis methods have parameters and all parameters introduce biases. All analysis methods have different sensitivities to noise or to signals. And all analysis methods can give unexpected or uninterpretable results. If you push the method too far, or, for example, if the method make certain assumptions about the data and those assumptions are not met. So this is just explaining a little bit more some of the ideas that I listed on the previous slide. OK, so how do you go about simulating data? First of all, you start with the analysis method, you figure out what is the analysis method that you want to apply. Once you know the analysis method, you have to think about the key features of the data that you need the simulated data to capture. Maybe the key features are about the characteristics of the noise. Maybe the key features are about the timing of the signal, or maybe the key features are about the rhythmicity and the frequencies present in the signal and so forth. Then you sit down and start simulating the data. So notice you don't just start simulating data first. You have to start by thinking about what is the goal of simulating the data. Then you can run the simulated data through your analysis method and come up with some way to compare the result of the analysis method against the ground truth, that's typically going to be something like R-squared, some measure of the similarity between the result that you get from the method and the simulated data. Then I encourage you to build some intuition by playing around with the simulated data and playing around with the analysis parameters. So it just kind of randomly poke around with different analysis parameters, different simulation parameters. Try and get a bit of an intuition. This is not really a thorough, rigorous investigation here. This is just you playing around and trying to build a little bit of insight. And then once you feel like you've gained some intuition, then you start systematically varying the parameters and plot the results. So now I want to show you a few examples of what point six might look like. So here's an example of testing different analysis methods with different parameters using simulated data. The exact details of the method and the data don't matter. Mainly, I just want to show you the concept that, for example, here I'm varying a key analysis parameter, the full with half maximum. So this is a parameter that is systematically varied. This is another parameter that systematically varied whether the data are fit with a sign or co-sign. And the key result here is on the Y axis. So the fit to the data and basically higher numbers are better. So at this plot tells you is that this range of parameters of this parameter, the four with that F maximum, somewhere around four to seven for a sine wave, it is the best for this simulated data. Okay. And then we can go through all these, but it's basically the same that we're quantifying how well the result of the data analysis fit the simulated data as a function of one or more analysis parameters. Now, again, this is not something that you can compute with real empirical data because with real empirical data you have the result of the analysis, but you don't know what the real ground truth is.
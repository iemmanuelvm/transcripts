 Now, I'm going to talk about the other multiple comparisons, solution from permutation testing, and that is extreme pixel values. So let's start again. We will talk about the mechanisms and then I will mention the assumptions. And then at the end of this video, I will compare the advantages and disadvantages or differences between cluster based correction and pixel based correction. All right. So pixel based correction works in a similar way to cluster correction, except in the second loop over all of the Permuted iterations. So after you've gone through one loop to create all of the null hypothesis maps, you go through a second loop, you go back through all of the permuted maps, the shuffled maps, but now you don't need to threshold. Instead, all you do is look through this map and you find two pixels. You have two pixels from this map or two pixel values, the pixel value that is the smallest, so the most negative and the pixel value that is the most positive. So you're looking for the two extremes. Now, remember, we start from the same assumption that we did in cluster correction. So we assume that this map, nothing in this map should be significant. This map is a null hypothesis. It's an empirical null hypothesis map. In theory, it should be all zeros if there's no differences between conditions. But then, of course, it's not going to be all zeros. There's sampling variability and noise and so on. So it happens that there's going to be some distribution. So we take the smallest part, the most extreme negative value and the most extreme positive value. And we say in this entire map, these are the two values, the two extreme values that we can expect under the null hypothesis. All right. And then I think you can guess what is the next thing we do. We go to step two. We go to the iteration, the second iteration, which is the second null hypothesis map. And we do exactly the same thing. We find the largest pixel, which might be this one, and the smallest pixel or the pixel with the most extreme positive value in the pixel, with the most extreme negative value. And then we repeat this for all the maps and that's going to build up a distribution again. So these two values from each map and that distribution is going to be bimodal. It's going to look like this with zero in the center. So these are all of the extreme negative values and the extreme positive values over our and different iterations. Maybe that's one thousand if you did a thousand permutations. And then we need to identify actually two thresholds to separate thresholds, the two. So if we're using a P value of five, that would be two point five percent of the distribution. So half of five percent of the distribution on the negative tail and half of five percent of the distribution on the positive tail. And these become your two thresholds. Now, it's important here to have two separate thresholds, assuming you're doing a to tell test, because we don't know for sure that the distribution will be mirrored. It could be that the positive values are much more positive. They're further to the right and the negative values are only a little bit to the left. So that depends on the characteristics of the data and so on. OK, so then you take these two thresholds and you apply them to your actual data, your observed data, and then you go through your observed statistical data and then you say any pixel that is so any any pixel with a statistical value in the map here, that is between the two point 5th percentile and the ninety four ninety seven point fifth percentile, those pixels get turned to zero and then whatever is left is something that we will accept as being statistically significant. So it's interesting to compare the cluster correction and the extreme pixel correction. So this is the map from extreme pixel correction. This is from cluster correction that I showed in the previous video. So there's a couple of differences that are noteworthy. One is that in cluster correction, you retain the entire cluster, even if individual pixels in that cluster are not really, really strongly significant. So these can be weakly significant, but because you have a lot of weakly significant pixels that are all touching each other, the entire cluster or this entire island remains one super threshold cluster. On the other hand, with pixel correction, you don't pay any attention to whether the pixels are touching each other. That has no effect. So you can have this kind of awkward thing where there's, you know, it used to be one cluster and then you get these like little islets carved out in here. Because these values had large pixel. These pixels had large values, these pixels had large values. And, you know, there's a couple of pixels in the middle here that had pretty relatively small values. They were significant enough to survive this thresholding, but they were not extreme enough. They were not large enough to survive this thresholding. OK, so that's one observation. A second observation is that with extreme pixel correction, you can actually have one or maybe two pixels that are just standing by themselves like this or this. This looks like a little pixel all the way up here. Now, I don't know if this is real or not. My intuition is that this is not something that I would trust. This is not something that I would write an entire scientific paper about this one pixel. But technically, this does survive our statistical thresholding. OK, so that leads us to comparing the multiple comparison correction methods. So cluster correction favors big clusters or heavy clusters. And I put this in red because I don't know if this is necessarily a good thing or a bad thing. It is something to keep in mind that when you do cluster correction, even real meaningful, actually true results can be removed from your results maps if they are in relatively small clusters. On the other hand, extreme pixel correction can detect small clusters, even clusters that are, you know, just the size of one pixel. So cluster correction, you know, despite what I just said, it is actually a sensible approach in neuroscience. Partly that's because we induce some spatial and spectral autocorrelation by means of time, frequency analysis, and also because our general understanding of how the brain works is that there is autocorrelation in brain activity over time. So cluster correction actually is a sensible approach. And with extreme pixel correction, the interprete ability, particularly on this one pixel issue, depends on the pixel size. So if you have actually pretty large pixels, then it's possible that interpreting one pixel is safe and reasonable. But if you have really tiny pixels that are like one millisecond and one hertz, then yeah, if you see one significant pixel here, it's a little bit hard to believe that this finding will replicate in an independent sample. OK, so and then the final thing, which is a negative about a disadvantage for cluster correction, is that the sensitivity can be frequency dependent. So what do I mean by that? In time frequency analyses, there tends to be more smoothing at lower frequencies and a bit less moving at higher frequencies. Again, part of that is a signal processing issue about the amount of smoothing that gets imposed down here versus up here at higher frequencies. And also part of that seems to be just something about how the brain works at these lower frequencies might be present for longer and higher frequencies might be a little bit more bursty. But because lower frequency activity tends to be smoother and higher frequency activity tends to be less smooth, there's actually going to be a bias imposed by cluster correction towards the lower frequencies, which naturally have larger clusters. Now, if that is a concern, one thing you can do is to run your cluster correction twice, let's say first only considering frequencies below some threshold frequency and then run cluster correction again above the frequency. So, for example, if you are looking at activity in the range of, let's say, two hertz to one hundred and twenty hertz, that's a pretty big range. Maybe you want to run your cluster correction separately for two to four hertz and then again separately for thirty forty to one hundred and twenty hertz. So I'm just making up these numbers, but it's just an illustration of one way to get around this possible issue. OK, so all of this said, you know, I want to present a fairly balanced approach here. But that said, cluster correction is by far the most common multiple comparisons correction method in the neuroscience and cognitive neuroscience and electrophysiology literatures when doing time, frequency or related analyses. So I would recommend sticking to cluster correction. And there's nothing wrong with extreme value pixel correction. But just keep in mind, it's less commonly used, I think, because you still end up with a lot of these tiny little blips here that can be difficult to interpret.
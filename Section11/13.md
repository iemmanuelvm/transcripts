 Let's talk about Arabella's and guessing or inferring statistical significance based on Arabize so here is a question. We have data here and we have these bars and error bars. And this tells us the note underneath the figure tells us that these error bars indicate the standard errors of the mean. And the question is, are these conditions? So you imagine this is condition A in this condition B, are these two conditions statistically significantly different from each other based on looking at the plot? What do you think? I'm going to go off on a small, unrelated tangent here. Teaching online has both advantages and disadvantages. The main advantage, of course, is that I can reach many, many more students from all over the world. I'm not constrained only to teaching the particular small number of students who are lucky and fortunate enough to be able to come to wherever I am and be in a classroom with me. But on the other hand, what I really like and what I find really rewarding and important about teaching live in front of a group of students is that we can interact, we can all talk to each other. We can have a classroom discussion where different students can debate with each other or disagree. They can disagree with me that I find really rewarding. And that's just totally missing from this online medium. So normally, if I'm teaching this lecture in a course, you know, with students sitting in front of me, then I am going to get us into a discussion because there's always going to be people who feel differently about this question. Some people will say no, some people say yes, and some people will say, I don't know. OK, but what do you think? Perhaps someday if you meet me, you can let me know what you first thought about this question. But now I'm just going to tell you the answer without a discussion. The answer is we have no idea from this plot, from this graph. We have absolutely no idea whether these conditions are statistically significantly different. And that's because what these error bars are telling us is the variance around the the means of the variance over different individuals. For example, imagine if I would show you all of the individual data. So imagine now each of these blue lines corresponds to one individual, one research participant, and then you can see that every single line is going up, every single line. Some subjects show the effect stronger. You know, this one only shows a weak effect, but it's still going in the same direction. So, in fact, these two conditions are highly, statistically, significantly different from each other. The effect is really large. They're really different from each other. So in this case, the error bars are telling us about how much variance there is across the population, across different individuals. That doesn't say anything about the actual effect. Now, I could have set this up differently. I could have told you different information about this, what these bars are actually referring to. In fact, I told you very, very little information and that was intentional. I wanted to make it a bit ambiguous. So now I'm going to give you a little bit more information. Imagine that what these bars represent are beta coefficients. So regression coefficients from a multiple regression that was run over or for each individual subject. So then what you see here is the average beta coefficient. And here you see the 95 percent confidence interval around those that average. And then this is zero. This this horizontal line here corresponds to zero. Now that I've told you this, what can we say? Not so much about whether these things are significantly different from each other, but what can we infer about statistical significance based on these air bars? Well, in this case, what we can infer is that this regression coefficient at the so whatever this is reflecting in the model, this is statistically significant. So significantly different from zero at the group level. So across the group of individuals, this beta coefficient is significantly different from zero and this is not significantly different from zero. This is not statistically distinguishable from a zero beta coefficient or no effect. And now we can make that inference because I told you that these bars reflect parameters and the the error bars reflect confidence intervals. So here zero is contained in the confidence interval. So we cannot determine significance or we cannot make a claim about significance. And here the error bar does not include zero. So we can make a claim that this is significantly different from zero. So it's ambiguous. Looking at error bars can be tricky. You need to know more information about what the error bars are showing in order to determine significance and. That is something you have to be mindful of whenever looking at error bars, because we all have this tendency, we have this immediate tendency to interpret error bars as reflecting significance or is indicating significance if two error bars do not overlap. Now, the thing is, it is sometimes possible to infer significance from error bars, but only in some situations. It depends on what's being shown in the plot. It depends on what the error bars reflect. So it is sometimes possible to infer significance, but not always. There are definitely many situations where error bars do not tell you anything about significance. All they tell you is about variance. So the point is you should always be cautious about making inferences from error bars, never assume significance from error bars without making sure that you have enough information. And I guess the general point here is never assume it makes an -- out of you and me.
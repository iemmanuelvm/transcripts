 Now that you have a pretty good idea of the mechanism of permutation testing, let us extend our knowledge to permutation testing in real data. This will be a pretty cool application. So the goal here is to determine whether there are statistically significant differences in power, time, frequency, power between Channels six and Channel seven. And this is going to be in the V1 data set. All right. So what we want to do is start by extracting time, frequency, power from all trials from Channel six and seven from the V1 data set. All right. So we load in the data set and then we are going to extract the number of points and the number of trials. And that is the second dimension and the third third dimension. OK, then we specify which channels to use here. All right. So here we are going to save the time point. So we're going to do post analysis temporal downsampling now in this data set. The time vector is given in seconds, not in milliseconds. So you have to be mindful of that. Different data sets might come in seconds or milliseconds. So if this were milliseconds, this would be a pretty awkward time range to say we have, you know, minus point one millisecond to one millisecond. That's not a terribly long period of time in milliseconds, but in seconds it's fine. It's a little strange to go up to one point one four, but that's nothing particularly wrong with that number. All right. So then we have our frequency ranges and here we define the frequency. So we're going to have linearly spaced frequencies from the Min Freck to the Max Frech in NUM Frex steps. So then here we are setting up for the wavelet. And it's good just to have a quick look through all this code, just to make sure that whatever strange person with a really bizarre sense of humor who writes all this code for us, they, you know, they sometimes play tricks on us. So good to have a quick look through. So this looks fine. This all looks fine. And then we have the FFT parameters. This all looks fine as well. Here we have a loop where we create the wavelet. So we have the the the parameter for the Gaussian. So the number of cycles divided by two pi f and then here we have the complex Morleigh Wavelets of the time domain complex valued Marlay Wavelet e to the I two pi fifty times E to the minus T squared divided by two squared. OK, so all that looks fine. Then we take the end con point fifty of the wavelet and then here I'm going to normalize the wavelet. So that's going to be temp X divided by the maximum of temp X. All right. Very nice. So I would like to plot one of these wavelets just to make sure that it looks good. So we have time bias, but the real part of Complex Morleigh Wavelets and it looks really, really skinny. But this is actually the highest frequency. This is what do we go up to 90 hertz, I think. Yeah. So this is at the highest frequency. So we don't really expect it to be really wide. But if we zoom in, this looks pretty plausible. This looks pretty good. OK, so let's see. Let's move on now. Here we are going to run convolution to extract time, frequency, power. And this is a reminder that we need to store all of the single trial data. Now, why do you think we might need to store all of these single trial data if we want to compare the average power between Trial Channel six and Channel seven? If we want to compare average power, can't we just take the trial average power from these two channels? Well, the answer is that we still need all the single trial power because we are going to have to permute all of these data somehow and we'll talk exactly about what to permute later on. But we're going to need all the single trials for the permutations. OK, so here is the spectrum of data X1. So this is going to be Channel one. So we are reshaping the data from this channel all the time, points in all trials to be a vector and then we take the Nikonov point fifty and then we can copy and paste. And this is the same code except we are taking Channel two here. All right. So that looks good. So let's see, initialize the time frequency data. So this is a two by frequency's, by time points by trial. So this too is of course, going to correspond to our two channels. So here we have convolution. We do the multiplication of the data by the spectrum of the data, by the spectrum of the wavelet inverse for eight. Transform, trim the wing. And reshape to time by trials, and then we want power on all the trials from Channel One. Now, of course, this is in quotes here, because it's the first channel that we listed, not from channel number one. In fact, this is channel number six. Let's see. Don't forget to downsampled by selecting only the. Hmm, something's missing here, but I think we understand what is the intention here. So let's see. We want to actually let me run these lines of code so we have some data to work with. So this is a 1500 by 200 matrix. And it's the analytic signal. It's the result of wavelet convolution. So let's see what we want. We want the magnitude of these wavelet coefficients and then squared. So now that is almost correct, except we need to downsampled. So we want to get, uh, let's see. So it's all of the trials, but it's not all of the time points. It's just going to be times to save time, save IDEX. So let's run this and see if this line of code works. OK, that looks good. And then here I'm going to copy and paste and now I copied and pasted and do I need to do anything that I do everything correctly. I'm sure you saw it. It is not totally correct. I need to get variable as to analytic signal from electrode do. All right. So let's run all of this code here. And so for convenience, we are going to compute the difference in power between the two channels. Now, this actually is average. So we are taking the average of all the power from all the trials or averaging over the fourth dimension, which is trials. So average from channel to minus the average from Channel one. So that goes into this variable diff map. And this is a there's only a two dimensional matrix. This is frequencies by time. But remember, this is downsampled time, not the full temporal original temporal resolution. OK, so then we do some visualization and I'm just going to run all of this code and keep my fingers crossed. Let's see what happens. OK, so we don't get any errors and this looks pretty legit. So here we have time, frequency, power from Channel six, from Channel seven, and this is the difference between them. So what we see here is that Channel seven has stronger gamma power. It's, you know, in the first stimulus window, it's a little bit stronger. And here in the second stimulus, we know it's a lot stronger. And then numerically at least, it appears that Channel six has more gamma power earlier in the trial, earlier in the stimulus onset period. So when it's read here, because of how I set up the subtraction, red colors mean more for Channel seven and blue colors means more for Channel six. Now, the question is, what can we interpret from this plot? What is safe to interpret? Well, you know, just kind of looking at it. And intuitively, it seems like this is probably significant. I'm just guessing, you know, just based on the color intensity, this I don't know. It could be statistically significant. What about these things or this little, you know, these little wisps coming up here? I really don't know if they're safe to interpret. My intuition tells me that this sort of thing is not statistically significant, but I really have no idea. That's what we need inferential statistics for. All right. So let's get to it so we specify our p value of point of five. And here I'm defining a Z value that corresponds to this P value. So what I'm doing is basically inverting the normal distribution from a P value to give me a Z value that corresponds to point of five. Now, this line of code is not going to work for you if you do not have these stats toolbox, because the norm in function is unfortunately in the stats toolbox. So if this line of code doesn't work, then it's totally fine. You just set Z value equal to one point six and if you want to be really precise, you can do one point six four four nine. OK, so this gives us our Z value, our standard deviation units that corresponds to a P value of zero point zero five. So and then we are going to loop through 1000 iterations in permutation testing and here I'm going to create a matrix that's going to store all of the results of the permutation testing and notice the size of this matrix. It is one thousand by thirty, five by one hundred and twenty five, so thirty five by one hundred and twenty five that those dimensions we've already seen before, that is the number of frequencies and the number of downsampled time points. And then a thousand of course is for. Iterations in permutation testing, so that means we are going to store every permutation map that we are going to be shuffling through here. OK, so now there's a question of how do we actually do this? How do we set up the permutation testing? What do we actually shuffle? What feature of the data are we going to shuffle? Now, if you don't already know the answer, I encourage you to pause the video and think for a moment about what might be the way to set this up and to shuffle the data. This is an example that I discussed a few videos ago in the slides where sometimes it's not so trivial to figure out what exactly the null hypothesis predicts and what you should do with your data for the null hypothesis. So to discuss this, I'm actually going to call up this figure again. I think I'll just show this whole thing in the entire figure. So this is the difference between Channel six, Channel seven, minus Channel six. Now, the null hypothesis is that Channel six and seven have the same amount of power on average. So that would predict that this map would be zero everywhere, which here I'll turn on the color bar is going to correspond to this pale green color. So the null hypothesis is that this entire map is pale, green is zero, the difference is zero everywhere. Now, the implication of that null hypothesis is that any given data point could be taken from Channel six or it could be taken from Channel seven. So the wrong thing to do is to shuffle the time points. The null hypothesis says nothing about time or time points. So the wrong way to do shuffling here would be to shuffle the time points or do the cut and switch procedure that I introduce you to at the end of the slides a few videos ago. Similarly, the wrong thing to do, the wrong thing to shuffle would be frequencies. Our null hypothesis says nothing about frequencies. So the only correct thing to do here, the only correct feature to shuffle, is the mapping of channel label to trial. Except that's also a little weird because these all come from the same trial, right? It's 200 trials and it's always, you know, that we have two different channels, but they come from the same exact two hundred trials. OK, so the way that I am going to implement this is by pretending like we have 400 trials. So I'm going to create this matrix called T.F. three D. So this is a frequency by time by 400 matrix and the 400 comes from trials and trials. So the first 200 trials are from Channel six and the next two hundred trials are from Channel seven. So then the idea is that the true difference, which we computed up here, wherever that was up here, we can also get this difference by averaging together the first two hundred elements of the third dimension and subtracting that from the average of the second two hundred elements in the in the third dimension here. OK, so and that leads us to the mechanism that I have implemented here for shuffling these data. So we are going to randomly pick from 200 of these trials for Channel six and randomly pick the other ones for Channel seven. OK, I hope that makes sense. If you have any questions, you have to scream them into your computer really, really, really loud. Otherwise I can't hear you. Just kidding. Of course, if you have questions throughout the course, you can post them in the Q&A form. OK, so what I'm going to do here is randomized trials, which also randomize is the mapping of trials to channels. So what I'm going to do here is come up with this random ordering of numbers from one to four hundred and then I'm going to create a new T.F. 3D matrix and that's going to be all of the frequencies without shuffling any of the frequencies all the time, points without shuffling any of the time points and then all of the trials, except now I am shuffling the order of the trials. So in this matrix, the first trial is actually well, let's talk about the second trial. So the second trial in this matrix is actually trial. Two hundred and thirty four from the original matrix. And that means that Channel six and Channel seven are getting mixed up in the first two hundred trials here. So then I have a line of code which looks almost exactly like this difference, this diff map code here, except I am taking the first two hundred trials and then the next two hundred trials. So I hope you can see that this is going to shuffle the mapping. Of trial times two and channel label. OK, so we loop through this and it shouldn't take too long. Well, OK, that took around 15 seconds or so. But through the wonders of technology, I you don't have to wait through all that time. OK, so what we want to do is compute a segment. This is where we're going. This is going to be a Z map of the real data against the null hypothesis distribution. And actually, you know, let me let me start by exploring this thing a little bit. So we have this matrix perm maps and let's see what it looks like. So histogram and let's look at all of the permutations, all the iterations for how about frequency ten and ten point thirty? This is not milliseconds. Of course, this is the indices. And I need to say perm maps here and let's go for maybe 40 bins for the histogram. So it's pretty interesting. You see, at this time, frequency point, we have a looks like a fairly normal distribution. And when you're computing differences, you will often get permuted empirical null hypothesis distributions that look Gaussian or that approach Gaussian. And we can try this elsewhere, maybe one thirty and I don't know, twenty one. Twenty five. OK, let's go for one 20. All right. Also looks a bit calcium here. OK, so now we want to compute the mean of the null hypothesis distribution and that is the mean. So perhaps and then we want the mean over which dimension. Yeah, that's right. We want the mean over the first dimension because we are averaging over all of the permutations. We don't want to average over frequency or over time. So same thing here. We have a standard deviation of PPM maps and let's say we don't even need the one there. OK, so these give us our maps. And now it's also pretty interesting to make an image of these guys. I mean, h not and oops. Oh, this must be right with Singleton. Dimensions have always tricky. Let's see, I'm going to squeeze out these singleton dimensions right here. So then we never need to worry about them ever, ever again. Let's see. So here's what this looks like. Axis X Y. So this is time. So I'm not you know, there's no this is not time in seconds or anything. This is just indices. This is frequency indices. So time and frequency. And it's interesting to see that, you know, even despite the permutation, we get some some colouring here. And then what's also quite interesting is to look at the standard deviation maps. And this shows actually, you know, kind of similar to what you would expect for the real data. You remember that actual difference map also looked a little bit like this. So that's not so surprising where there are true differences between the two conditions. There's also going to be a lot of variability because that's where the differences are. So you're promoting them, you're shuffling the differences and that's going to lead to larger variances. OK, so now we want to threshold the data. This is a multi step procedure. So first we are going to create a Z map. So the Z score is the observed data, which we call dif map minus mean H not so minus the average of all of the permuted maps divided by the standard deviation of H not OK. And then uh let's see. So normally I. OK, fine, let's look at this. I mean I'm going to show it in a moment. So here we go. And we know these are Z scores so we can actually set the color limit meaningfully. Let's go like minus three to plus three. Let's try that. OK, so these are actually pretty respectably large Z values here. This is saturating the plot. OK, so what we want to do now is threshold this image at our P value by setting any sub threshold values to zero. So we want to say any pixel in this Z map where the Z value is smaller than our threshold Z value, which we defined earlier based on P equals point of five and we set those to be zero. So let's run this line of code and then we are going to be doing some plotting. So let's see. All right, so here we get our plot, so let's see this first plot here, this top left plot, this is this is the raw defense map. So no thresholding. This is what we saw before here. What you see is the threshold in Z map that we just computed right here so that you see here, we're just making an image of the threshold. It said map. So all of the pixels that have a statistical Z value that is smaller than the threshold, those are all set to zero, which on this map means light green and all these Supre threshold pixels get set to, well, they retain their set value here. And this is showing something that's very similar to what you see here. The main difference is that here you see all of these red maps. Let me show you the code for this. So you see still the dif map. So I said Z map, but this is the the raw power difference here. And then what I've done is find all of the boundaries of all of these things, all of these borders around these islands here, and those get put into this contour function, which is not contour f fulfilled. This is just drawing contours. So you can see that here you see the raw power plot and all of the significant regions that are highlighted. Now before closing this video, there is two points that I would like to make. One point is about the P value. Yeah, the thresholding that I've applied here and the P value. I would like you to pause the video and think about whether this is whether we are performing a one or two tailed test and whether we are using an appropriate P value or not. So the answer is that what we are doing, in fact, is a two tailed test and that you can see it's to tell because I'm taking the absolute value of the Z map. So that's going to basically flip the negative tail onto the positive side. And what that means is that this Z value is actually a little bit liberal. It's a little bit liberal because we are testing both tails at zero point zero five. So in fact, although we specified a P value of point of five, we are testing the positive values at point of five and we're also testing the negative values at point of five, which means that in this code here, it's a little bit tricky is an easy mistake to make. The actual P value that we've implemented here is zero point one, not zero point zero five. It's zero point zero five on the positive tail end, point zero five on the negative tail. And then we combine them together with this code. So the P value actually becomes zero point one, the effective P value. OK, that's the first thing I wanted to point out. The second thing is, you know, how much of this stuff do we really believe, you know, like this? We want to believe this. I want to believe I'm not so sure about all of this crazy business here. But what about this little thing right here? Do we believe that that's a real effect? I mean, it is significant at a well, you know, our p value threshold, it is significant. But I would like to point out that we have the size of Z map. So the product of the size of Z map is four thousand three hundred and seventy five. So there are four thousand three hundred and seventy five pixels in this map. And we used the same P value threshold for every single pixel, which in fact the way we set this up was zero point one. So the question is, is it appropriate in statistics? Is it appropriate to do four thousand three hundred and seventy five tests using a P value of five or eight point one? Even if we divided this by two, we still get a uncorrected threshold of zero point zero five. So what we have here is a problem of multiple comparisons and we need to address that somehow. Otherwise that the chance of alpha error is the possibility of getting false positives is way too high the way that we have done the statistics in this video. And that leads us to the next video. So keep watching.
 In this video, we are going to create a church. This will be a non-linear chirp and then we will perform a time frequency analysis of that chirp. So here is where I set up the parameters, using, again, an unusual sampling rate. So I don't know this video and the last video. I guess I just felt like taking a normal sampling rate like one thousand twenty four or one thousand and adding one to it. So anyway, this signal is going to be four seconds long. So I'm saying four times the sampling rate and here I have a time vector. So here is again a different way to create a mean centered or zero centered time vector. So first I create a time vector that goes from zero to the number of points divided by the sampling rate. So this is going to be from zero to four seconds. And then here I'm subtracting the mean, which is just means. So that will ensure that we get a time vector that's centered at zero. So here I'm going to create the chirp. So that's down here. It's going to go from five hertz up to seventeen hertz and then back down. Although these parameters themselves don't make so much sense until you first see what the shape of the chirp is going to be. So I'm creating this to be something called a lipless distribution, which is a pretty neat looking function. It's E to the minus and then the absolute value of X or the time vector. So let me first show you what the lipless distribution looks like. It's pretty neat looking functions and it's a plot time V by F m which stands for the frequency modulator. So here is what the distribution looks like. It's almost like it reminds me of a Gaussian, if you would take a Gaussian, but kind of push the outside holes down so they are concave instead of convex. So instead of going up like this, it goes up like this. So this is the lipless distribution. You can see it's not actually down to it's not going down to zero if you would plot this further out in time than it eventually approaches zero. So this does have a maximum of one, but it doesn't have a minimum of zero. It has a minimum of around one point three or whatever that happens to be around time minus two. But what I want to do is stretch this so that this lowest point is five hertz and this top point is seventeen hertz. And that's going to become the instantaneous frequency time series. So what I need to do first is normalize this so that it ranges from zero to one. So that's what I do here. I subtract the minimum value and then I divide by the maximum. This is an important concept, taking a function and dividing it by its maximum so that it has a maximum gain of one. And actually, I think I'll show you this one step at a time. So this is the original function. Now, I will show you this again. So now it's gone, it goes down to zero on both sides, however, it no longer goes up to one, it goes up to, you know, point eight, five or so. So therefore, I'm going to divide by the maximum and that will give me a function that ranges from zero to one. So if you ever want to take any function, any time series and you want to scale it so that it goes between zero and one, you just need to apply these two lines of code. Now, from these two lines of code, you could make any other arbitrary scaling, you could scale it from minus one to plus one. In this case, I'm going to scale it from five to 17 and I'm going to do that by adding the smallest value that I want. So that's going to shift up the entire spectrum or this entire function. And then I'm going to multiply to scale it up by not the maximum frequency, but the distance between the maximum and the minimum frequency. So finally, this is what the result will look like. You can see it starts at five and it goes up to seventeen. Now, this is going to be the vector of frequencies. And here that is converted into a chirp. And I'm intentionally misspelling chirp here because actually chirp like this is already a function on its own. In fact, it's a function to create a chirp. So you are probably now familiar with this function for creating a chirp. So sign of two PI times the quantity of the time vector plus the cumulative some of the frequency. Instantaneous frequency vector, and then that's either multiplied by the sampling interval or divided by the sampling rate. All right. So here in this cell and doing some plotting, I plot the frequency time series, which is already plotted right here. And then I plot the chirp. And then here I'm plotting the power spectrum, actually, technically. Oh, no, it is the power spectrum here. OK, so here you see what that looks like. So this you've already seen this, you can see a sine wave is getting faster and faster towards the middle and now it's getting slower and this is the static Fourier transform. So one FFE over the entire time series. And this reiterates a point from the video about non stationary in the section of this course on spectral analysis. Now when you look at this Time series, you don't really get the intuition that this it's associated static Fourier transform. It is correct. If you look at this for a while and you think about it, you can make this make sense. So this frequency or the frequency content of this signal ranges from five to 17. So that part makes sense. And actually, if you think about this decay, that also makes sense because these values have more representation here and up here is the least amount of power up towards 17 hertz. All right, but the point is that this is not really a great way to understand the dynamics of this Time series, that's the important thing, and that is exactly the motivation for a time frequency analysis. The spectral features of this signal are changing over time. OK, so therefore we are going to do it wavelet convolution. Now, I'm not really going to say anything about the code in this cell. This is basically the same as the code in the previous video about creating more late wavelets. So now we skip down to convolution. And to perform convolution, you need to. So this is the guts of convolution right here. You take the Fourier spectrum of the data, multiply it element wise, multiply by the full spectrum of the wavelet or more generally the convolution kernel, and then you take the inverse Fourier transform of that spectral point Y's multiplication. And this is convolution, so this is the convolution result. And now the result of convolution is longer than the original data in particular. It is half the length of the wavelet, too long in the beginning and half the length of the wavelet too long at the end. So therefore, we trim off these wings of convolution. OK, so now let me take a few steps back, now that I've explained the meat and potatoes of convolution up here, I'm specifying some parameters. So this is the length of convolution. Normally, I introduce this as end plus and minus one, so the length of the signal plus the length of the COL minus one. However, it turns out that in this case, both the signal and the kernel have the same number of time points. So you can do two times and. And now here I take the 50 of the data, and this is an interesting feature to keep in mind because the spectrum of the data don't change with the different wavelengths, of course. So you only need to compute the efficacy of the data once, and that can be done outside the loop over frequencies. And the wavelet, in contrast, of course, that does change with each loop iteration here. So inside this loop, I'm also creating or taking the 50 of the wavelet. Now, this convolution result is a complex value time series. It's complex valued because although the signal is real valued, the wavelets are complex value. So the result is complex valued. What we are interested in is power. So we extract that as the magnitude squared and then here I make a plot. So let's run this. And I hope you agree that I assume you agree that this function, this vector of instantaneous frequency is closely matched to this. There's a little bit of smoothing. You can see smoothing is an intrinsic part of time frequency analysis. And in fact, very often smoothing is actually a good thing. You want to smooth out the time frequency plane a little bit. That helps account for some minor jitter, some little variances and facilitates averaging. You can also see that there's some edge effects here. So there's also going to be effects resulting from convolution. Now, there's one line that I would like to discuss, which is this line here. And this is where I take the spectrum of the wavelet and then I divide the spectrum by the maximum value. In fact, that's really similar to what I did up here. Whereas this here and I said here, this is a way of ensuring that any time series has a peak of one and that's what we're doing here. So now what I want to do is illustrate this to you, why this is important. So I'm going to create one wavelet and then I'm going to plot the magnitude of this. And now you can see this. You go from zero to 40. Maybe that's good. OK, so by the way, this is not frequency. This is just frequency indices. In this case, I don't actually need to convert it into frequencies. And instead, what I want to do is bring your attention to the Y axis. So this is the power spectrum or the amplitude spectrum of the wavelet at the first frequency. And you can see that has a maximum of a little over 500. So maybe it's five hundred and twenty or so. Now in convolution, you are literally point wise multiplying the spectrum of the wavelet by the spectrum of the data. So you can think of this as like a gain function. This is like the gain function that you think about when you are applying a filter. Now, if you are applying this Gaussian gain function to data, the data in this frequency range are actually going to be scaled up by a factor of 500, a little over five hundred. And so that means the amplitudes will change. And furthermore, this gets even worse because let's see now I'm just going to plot a different one and a different wavelet. And let's see, how do you hold on and then plug this again? Let's make this and red and now let's see, uh, set. Uh. OK, so now you see two wavelets. So this is the first frequency. This is the last frequency. So you can see that the height of this wavelet is somewhere around one hundred. So the regain function is different for this wavelet than for this wavelet. And for that reason, if you don't include this normalization, then you are going to get a result that looks like this. Now, in some sense, this is still kind of accurate. You can see it's correctly following out the frequencies here, but the amount of energy is not really accurate. So it looks like there's a lot more power at lower frequencies and a lot less power and higher frequencies. But that's really not what you see in the Time series if this were an accurate depiction of the time, frequency dynamics. Then this amplitude should go down and then it should go up again, but that's clearly not the case. The amplitude of the amount of energy in the signal is constant. It's just the frequency that is changing over time. So therefore, this normalization helps account for that.
 I think I'll do this video backwards, not that I'm going to talk backwards, but I'm going to start at the end with the final conclusion and then I'll go back and show you some of the code. So here is the final conclusion. These two time frequency plots look really, really similar. Now, if you look carefully, you will find a few places where they differ. I just happened to notice this thing here. This is a little bit different here. And you can probably pick a few other places. But these are really, really similar. And qualitatively, these two maps show exactly the same thing. So what is the difference between these two maps? Well, that difference you can see here, this is the number of megabytes that is occupied in the computer's MATLAB buffer for this matrix versus this matrix. So this result versus this result. The results on the right side is around three quarters of a megabyte and the result over here is a fraction of a megabyte. Now, that might not seem like a big deal because this is still less than one megabyte. However, this is just one time frequency plott for one channel and one condition. Imagine if you had one hundred and fifty channels and six conditions. Now these matrices can start to get really, really large. They can be multiple gigabytes per image just for having one image. That time frequency map can be really large. And the problem with having really large matrices is that when you write them out to disk, they will be slow to write out. They will take up a lot of space. And when you want to import the data back into Matlab, that will also take a long time to import the data. And if you have many such datasets, you're probably just going to run out of space. So wouldn't it be nice if we can downsampled the data, the results of the time frequency analysis without really losing any information? OK, now with that as an introduction, that is going to be our goal here. We are going to downsampled the results of a time frequency analysis. And I wanted to make an important distinction here. I'm not down sampling the data. That's not the goal. The goal is not to downsampled the data. The goal is to downsampled the results of time frequency analysis after you've used the full sampling rate data. And we start from this line here. We load in a data set and we specify this vector here. I call it times to save. And this is a factor in time points in seconds and it goes from minus point two to one point two seconds, skipping insteps of point to five seconds every two hundred and fifty milliseconds. You can see it's only a handful of data points at six time points, and that's actually what builds this entire map. So this entire map is only six time points. And now this map, this full time frequency map, that's actually all of the time points. So that's fifteen hundred twenty seven time points. So this is three orders, two to three orders of magnitude more dense than this one. And yet they show more or less the same results. OK, so now let's see what we do here. So all of this stuff is the same as what you've seen before, this is setting up for the time frequency analysis. The only thing that's really new here is how initializing these two matrices. So I have the time, frequency, full time, frequency down sample. And you can see the difference is they both have the same number of frequencies. This one has length of the number of time points in the original data, and this has length of the number of time points in the front coming from the variable times to save. And here we do convolution create the wavelet run convolution. This is all stuff you've seen before. In previous videos here I compute the Power Time series for each frequency. Now notice this is still a fifteen hundred and twenty seven times. So up until this line of code, we are still using the full temporal resolution of the data. We're not doing any downsampling of the Time series data here. You can see I'm either entering that entire vector into this full matrix or I'm extracting only these time indices corresponding to these time points in seconds. And that goes into the T.F. down matrix. And that's really the only difference, and now here we plot the results, so making a contra function of the downsampled version and a contour of the the full matrix and those you see here and then here, there's one plot that I left out that I didn't show you. And that is a time course, a power time course from one frequency. So I just picked frequency thirty more or less at random. Actually, that's not a terribly interesting frequency to show. There's not a whole lot of interesting stuff happening at 30 hertz. So here the black line shows the full resolution and the red line or some of the red dots shows the downsampled version. And now the question that you want to ask here is, are we losing any information, not are we losing data? Because we are we're dropping all these points. Are we losing any information? In other words, would we come to a different conclusion about what the brain is doing purely based on the red dots if we ignore all the black dots? Now, in this case, I would not feel totally comfortable with this extreme level of downsampling. Essentially, we are down sampling here to four hertz. And it's for her, it's because I specified that each successive time point is point to five seconds, which is two hundred fifty milliseconds, which is four hertz. So each dot is four hertz away from each subsequent dot. So I think that's a little bit extreme. I would typically go for something much smaller. Well, not much smaller, but a bit smaller. I think I typically go for somewhere around maybe 30 or 40 milliseconds. So this is 30 milliseconds here and I'm going to run all this code again. And now you can see let's look at these red dots, so now I think it's really clear that we are not losing any information based on the red dots based on downsampling. There is no way that you were going to come to a totally qualitatively distinct interpretation of what the brain is doing purely based on the red dots. And I'll show you again now you see it a little bit better. So the red dots really capture all the dynamics that are in the original signal. Maybe if it's relevant, you can set these points to go out further. But still, you see a huge difference, basically an order of magnitude difference in the amount of data, the amount of space that is required for the full matrix relative to the downsampled matrix. And yet the results don't really differ in any meaningful way. So in general, I recommend downsampling the results of your time frequency analysis. I think it's generally always a good idea also because it's very easy to implement. Now, if you're just doing one channel, then it doesn't really matter. But if you have more than a dozen or so channels and it's generally a good idea to do this.
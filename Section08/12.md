The way that most people conceptualize frequency information is think about the number of cycles per

unit time.

So, for example, ten hertz means 10 cycles in a period of one second.

However, there is another way of thinking about frequency, which is the frequency, the instantaneous

frequency at each time point, or I guess more precisely, you would say the frequency from one time

point to the next time point or the speed of an oscillation or rhythm from one time point to the next

time point.

In general, that's called instantaneous frequency and it's actually pretty easy to compute.

I discuss that more in videos in that I mentioned in the background section.

This course in my YouTube videos.

You can also look up this paper here.

This is where I talk about not only the method for one method for computing instantaneous frequency,

but I also discuss a possible biological or physiological interpretation of changes in instantaneous

frequency over time as it relates to brain processing and information processing.

So what I'm going to do in this video is illustrate this method frequency sliding.

I'll show you in the code how it's computed, which is actually just these two lines of code here.

I'll talk about that in a minute.

And we're going to start off with some simulations.

We're going to see the effects of noise and simulation, and then we're going to look at the results

in real data.

All right.

So let's start by simulating some data.

So I'm going to simulate using a sampling rate of 1000 hertz or kilohertz.

And this is going to be four seconds.

So four times the sampling rate starting from zero.

That will give us four seconds of data.

And you can see all of this noise parameter and it's initially set to zero.

So we're not going to add any noise here.

So let's run this.

And now here I'm generating a multipolar, instantaneous frequency chirp.

So this is a signal that will change in frequency over time.

You should recognize this formula or this line of code from the earlier section in this course on simulating

data here you see.

So here I generate the pure signal and then here I'm adding noise.

You can see this is just purely random numbers, amplitude multiplied and scaled by this noise variable,

which here is zero.

So in fact, right now this line does nothing.

All right.

So let's from this and here we go.

Here we are computing the instantaneous frequency.

Essentially, we are just extracting the phase angle time series from the signal via a procedure called

the Hilbert Transform.

Now, I haven't actually talked about the Hilbert transform yet in this section, but I will talk about

it in a later video in between Project one and Project two for this section.

But essentially, the Hilbert transform is a way to convert a real value signal, which is what we have

here to a complex signal, a complex value signal, something called the analytic signal.

And from that analytic signal, we can extract a phase angle time series and an amplitude time series

here.

We're primarily interested in the phase angle time series and then we take the derivative of the phase

angle time series.

It gets unwrapped.

That's because phases naturally wrap around from two pi to zero.

Or you can think about it from minus pi, from plus by back to minus pi.

So we unwrap the phase angles, take the derivative, which essentially gives us the difference between

each successive time point and then scale that by two pi over the sampling rate.

Essentially this is just converting this derivative into Hertz and that's it.

That gives us an estimate at each time point of the frequency at each time point.

And that's interesting here, because we know that this chirp here, this multipolar chirp is going

to change in frequency over time.

OK, and then here I'm also computing the static power spectrum, and that's just going to be interesting

for comparison.

So run this code and then here we do some plotting.

I think actually what I don't do is plot any phase angle times here.

So let me do a little bit of extra plotting for you.

I'm going to plot plot time by signal.

So here you see what the signal looks like.

So it starts off kind of let's call this medium speed.

It gets faster and then here gets slower, but faster, a bit slower and so on.

Now, what I plot here is the fate, the phase angle time series.

So that is, uh, I call this Engle's.

So here you see the phase, an all time series now, it looks quite similar to the signal itself and

in this particular case, it's not so surprising.

The signal has no amplitude modulation, so it's always constant amplitude.

So therefore, the phase angles are going to look a whole lot like the original signal, just a little

bit sharper.

OK, so now you see that it's wrapping around, so every time we get up to pay, it suddenly goes back

down to minus PI.

So therefore I unwrap the signal

that looks like this and that's converted this into something that keeps going up and up and up.

Now, this is monotonically increasing, but it's not increasing.

It's not increasing always at the same rate.

And the instantaneous frequency is basically.

And tell us how fast these phase angles are increasing.

So here they're increasing more quickly.

So the instantaneous frequency is higher here.

They're increasing slower.

So the instantaneous frequency is lower.

So now you can see I'm going to plot the derivative of the discrete derivative, the difference out

outright.

So when you compute the derivative, you actually get a result.

That is one time point less than the original signal.

So you can see angle.

This is four thousand.

The signal is four thousand nine points.

But this variable, in fact, is only three thousand nine hundred ninety nine.

And that actually makes sense because if you compute the derivative of two numbers, you only get a

single number back.

So that means when plotting, you don't plot from you don't plot the entire time vector.

You have to say one, two and minus one.

OK, and then here you see, so you get some edge effects here.

So we have to zoom in a little bit to ignore them.

So let's see, I'll just, uh, zoom in.

Now, this is going up and down, reflecting that the signal is getting faster and slower and faster

and slower.

Now, this is not the frequency in the Y axis.

This is in units of radians.

Right, because so far we're only dealing with radians.

So therefore we scale this by two PI and then the sampling rate and that's just going to convert radians

into Hertz.

So let me to actually now I'm basically just putting in Freck, so.

Let's see in South Africa and again, we still have exactly the same age of you always get these weird

edge of facts when you compute instantaneous frequency.

But now we can zoom in and now you can see this is the instantaneous frequency.

It's going up to 20 and then down to four or three or whatever.

And who knows if this is accurate because we haven't seen what the fragment variable is, but that's

what this plotting does here.

So here you see again the time domain signal.

Now, this is the static power spectrum here.

So one FFE over the entire signal in general, this is really hard to interpret because of the non stationary.

So there's strong frequency, non stationary in the signal.

And so that means that the power spectrum here is technically accurate, but a little bit difficult

to interpret.

And if you look at the red line here, this is the ground truth.

That's the way is that that's frech mud here.

So this is the vector of frequencies that we use to generate the signal.

You can see that that's that this is in the right range.

So this fragment goes from you know, it goes from around four up to the highest values can be somewhere

close to 20.

And you see here, it starts down at around four or maybe this goes down to three and this goes up to

around 20 or maybe a little bit higher.

Nonetheless, the instantaneous frequency vector that we computed looks a whole lot more interpretable

compared to the static frequency spectrum relative to the ground truth.

OK, and you can also see there's some edge effects.

So you get some wiggle artifacts here that's partly coming from the Hilbert transform.

And just in general, you're always going to get these kinds of edge effects.

You can see the edge effects are kind of rippling outwards here.

The longer I should say, the lower the frequency, the longer these ripple effects are going to last,

even continue into here.

OK, so this looks good, the next section here is about cleaning the instantaneous frequency signal

by means moving.

Now in this case, we don't really need to clean it that much.

It looks pretty smooth already.

However, what I'm going to do now is add a little touch of noise.

Let's even call this point one amplitude of noise and rerun this.

So now you see this in the time domain here.

This doesn't look like a lot of noise.

It's still super clear what's going on here.

But this looks like, you know, it's almost entirely a black background.

And the problem here is let me turn off the set function and run this again.

The problem is that these tiny, tiny noise fluctuations end up having a huge, huge effect on the instantaneous

frequency.

So much so that some of these numbers don't even make any sense.

What does it mean to have, you know, minus 30 hertz and then jump immediately up to plus 40 hertz?

And the issue here is really about the phases, so if I plot the time by the angles, then you can see

that the phases get quite noisy writers these little.

And you think this should be insignificant.

You think this should have a very, very small effect, but this end up just amplifying.

So here you see the unwrap phase angles.

Again, this doesn't look like a big thing.

However, when you take the derivative, one of the consequences of taking the derivative of a signal

is that very small fluctuations become amplified.

So now when I take the derivative, I say one, two and minus one, and then I take the derivative of

the unwrapped phase angles.

Now you can see that the noise here appears to be much, much larger than the original signal.

OK, so let me recreate this figure, uh, with this thing like this.

OK, so this is not good.

So we need to do a little bit of cleaning.

Now, in this particular case, the noise happens to be randomly distributed, positive and negative.

So then it turns out that means smoothing is a pretty good solution now means smoothing is not always

a good solution.

And in real data you'll find that means smoothing an instantaneous frequency time series is generally

not the right solution.

However, cleaning and noisy data is very specific to the type of noise and the way that the noise was

introduced.

So here I generate broadband.

That's the key thing here.

It's broadband noise that's low amplitude and it's random.

So mean something happens to work well here.

The way that I implement this means moving is in the frequency domain.

So I create a kernel which is all once divided by the number of numbers just to make this kernel some

to one.

And then I do convolution so you can see him doing and plus and minus one and then I'm implementing

that mean smoothing as the Fourier transform of the kernel type of frequency was multiplied by the four

transform of the signal and then the inverse Fourier transform of that spectrum multiplication.

And that gives us our means smoothed result.

This is actually equivalent to looping over all the time points and in the time domain computing the

average around each center time point.

OK, and then I plot that smoothing kernel as well so you can see that reduced the noise.

So this blue line now looks a lot better.

It's still not perfect, it's still quite noisy, but it maps much better onto the red line, which

you can no longer see, unfortunately.

But you'll remember that that basically looks the same here.

So you can try increasing the smoothing.

It turns out also a good way to noise the signal is to narrow band, filter the data to get rid of a

lot of this broadband noise.
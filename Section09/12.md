 What we're going to do in this video is compute phase synchronization, and in particular I PC and play, so phase clustering and phase lag on the same data set before and after applying the law. Plus, it's going to be super insightful. I hope you enjoyed this video. Well, I hope you enjoy every video, of course. But this one particularly so. All right. Let's see. So first, we're going to load in the data. Let's have a like a bird's eye view of this script. So we loaded the data pick two channels. We're going to compute synchronization between these two channels and then we go over frequencies and we're going to create a time frequency map of synchronization. And then let's see. So here is the loop over frequencies. Where we do, we rebuild the wavelet, we run convolution and we get the phase angle time series differences and we compute ISPCC and play and then we make plots of phase clustering and phase lag indices. All right. So that's like the big bird's eye view. Let's go back and go through this code line by line so we load in the EEG data set, set these two channels, and then here we have our frequencies. We're going from two hertz to 40 hertz in some number of steps. So we get to choose how many steps. Now, in some sense, you can kind of pick whatever number you want. You could say two steps. You could say, you know, some really, really large number of steps. But let's do something a little more realistic. How about 34? And here we specify the range of the full with that half maximum. So the four with the half maxima will go from point three seconds. So 300 milliseconds at two arts up to 100 milliseconds at 40 hertz. So that means the Gaussian is going to get the Gaussian that creates the wavelets is going to get narrower as we increase in frequency, which is a sensible way to construct the tradeoff between temporal precision and spectral precision. All right. So here we specify our time vector for the wavelet and the frequencies of the wavelet. Now, this should go from two to forty. So let's just have a quick confirmation. Hmm. And this looks like it goes up to one. So that looks a little strange. But then actually, when we look at the number here, this is actually ten to the forty. Let's actually plot this. So plot, Freck. So these are the frequencies that we are going to extract from the data. Yikes. This is way, way, way, way, way above the Nyquist frequency. What is going on here? Well, what's going on here is that we are having logs based, a function log space to create logarithmically space frequencies between two and 40 hertz. And so what we're missing here is scaling this down by log 10. You remember I discussed this in several previous videos. So let's run this line again now and see, OK, this looks a lot better. So now we're going from two hertz up to 40 hertz. That is certainly a reasonable range given what we expect from EEG data as well as our sampling rate. OK, so here we have the convolution parameters. We have the length of the kernel, the length of the data. So we're going to be extracting data from all time points and all trials. And then we have M plus and minus one for the length of the result of convolution. All right. Here we take the safety of the data and let's see all of this looks good. I think this is actually all correct. Have Channel one and Channel two. OK, so then we get the two spectra here. All right. And then we have to initialize the time frequency data matrices. Now, I don't know offhand what these what the sizes of these matrices should be. So what I'm going to do is look down here to where this gets applied in the code, and then I can see that both these variables are two dimensional and they are both frequency by time. That's also sensible because we are just computing synchronization between two channels, between a pair of channels. So frequencies by time. And also looking through this code, I see that we're not doing any post analysis post convolution temporal downsampling other results. So we have the original temporal resolution here. OK, and that tells us how we need to initialize these things. So they are both zeros and initialize them by zeros. And we have no Frex by EEG dot points. Now you could if you want, just copy and paste this here, but notice that both of these matrices are getting initialized to exactly the same matrix. This is a. Exactly the same thing on the right hand side of this equation, so therefore, if you like, you can use another function called deal like this. And I don't know if I've introduced the deal function in this course, but it's a pretty handy function to know about. So you can say, let's see, output one, output to output three. And then I write deal and let's say about the number one, two, three. Now the number one, two, three, that's just a number. But if you want to assign exactly the same number to a bunch of outputs at the same time, a bunch of variables at the same time, that's where you would use the deal function. So I wrote a deal. And then these three variables as the output of the function deal, and it just dealt out this input to each of these outputs at the same time. So it's a bit like, you know, dealing cards. You're dealing this card to all three of these players at the table. So with that in mind, we can write deal zeros and then we want to output play and ISPCC like this and then we get zeros for or zeros matrices for both of these variables. So it's a pretty neat function in this case. That only saved us one single line of code, but it's a pretty handy function to know about anyway. All right. So let's see. Here we are looping over frequencies. We create the wavelet. So it's E to the I to pi 50 times E to the minus four times log, two times time squared divided by the four with that half maximum squared for this particular frequency. OK, so I think that this is correct and I'm going to run this and have a look at this wavelet just to make sure that it looks OK. So time will play out the real part of the wavelet and yeah, that looks pretty good. So for this lowest frequency at two hours, I think point three seconds for forward, that half maximum might be a little bit small. It might be a little bit narrow because it would be nice to have, you know, maybe more than like one full cycle at this wavelet. You can also see that the integral here over time. So the cumulative sum is probably not going to be zero. So this kind of actually technically violates that one of the formal requirements of a wavelet that the integral is zero. Anyway, I think I'll just leave that for now. It's OK. OK, so let's see. And then there's a question, is this line necessary, this line here, do we need to normalize the wavelet in the frequency domain in this example? In this analysis here, the answer is no. And the reason is that all we care about is the phase angles and the phase angles do not depend on the amplitude. So it's totally fine, of course, to leave this line in here. I would leave it in here just because I think it's it's good practice to get in the habit of having this normalization in here, but also nice to realize that we don't actually need that line here. OK, so we create the wavelet and then we run convolution for the first channel, which is the inverse Fourier transform of the wavelet spectrum times the data spectrum. And then here's a little question. Is this second input here and is this necessary for this line of code? Again, the answer is no. This is actually not necessary. And that's because Anquan is the same as the length of these spectra and the inverse FFT and the F.T. will by default use the number of points as the number of so. So the endpoint for the FFE is going to be the number of points in the spectrum in the first input into this function. So therefore this is not necessary, but it also doesn't hurt. It's not bad to have this in here. OK, trim the wings and reshape back to time by trials and we can confirm that this is a time by trials matrix. OK, so then we do the same thing for Channel two and then here we extract the phase angles and then we get the phase angle differences between Trial Channel one and Channel two and then put that into Euler's formula to give us complex vectors whose angles are defined by the phase angle differences. So that looks good and the size looks good. Now, one thing I would like to point out, there's an easy mistake that you can make here, which is to accidentally omit the parentheses here. Now, when you do this, multiplication takes priority over subtraction. So if you have a line of code that looks like this, what you are actually implementing or what Matlab is going to. Implement is equivalent to this here. So you're saying E to the I times the angles of Channel One minus the angles of Channel two. This is unfortunately not going to give a Matlab error. This is a math error. It's not a coding error per say because we're not doing anything illegal. But you just have to be mindful of this at the I hear this imaginary operator. This has to multiply the phase angle difference, not just the phase angles from the first channel. So that's an easy mistake to make. Let's see. So it looks like this now. I have to rerun this and let's see. Now we compute ISPCC and play and we're averaging over trials. So here we take the average of all of these complex vectors and then the magnitude of that average. And then we're averaging over the second dimension, which is trials. And then here for the play, we get the oilrigs phase angle differences, project them onto the imaginary axis, compute the sign of the projection onto the imaginary axis, take the average over all of those signs. And again, is the average over the second dimension. And then we take the absolute value and OK, this all looks good. Let's run this whole loop here. All right. So that ran pretty quickly and let's play the two super curious. Aren't you curious? I'm very curious. All right. So what we are looking at here is the synchronization between Channel F, Z and P o8. It was FC Z and Posidonia for phase clustering versus phase lag index. And these are on the same color scale. So they are directly comparable. Now, it's quite interesting to see when you look at the play, the phase like index, you see that most of the map is pretty small, fairly close to zero, and you get these two little bursts of synchronization here shortly after the stimulus onset. So and that's a burst in. Looks like theta and a burst in Alpha. And here for the phase clustering, this looks quite the opposite. It's really, really high everywhere. In fact, the color is totally saturated almost everywhere in this time, frequency plane. And in fact, the only time when it actually gets small is somewhere around here where you actually see increased synchronization. Now, what is going on here? How do we interpret this? I think this is one of the questions here. Let's see, are you surprised at the difference between phase clustering and phase lag and how do you interpret this difference? Well, maybe you're surprised. To be honest, I'm not so surprised because I've seen these exact same two plots for, I don't know, more than a few years, I guess. But it is surprising. And what I believe is going on is that there is a spurious inflation, hyper inflation of synchronization values due to volume conduction, due to the fact that FZ that and pothead are measuring a combination of distinct neural populations and shared neural populations from the same deeper sources. And those shared contributions are all filtered out by the Peli. They're all ignored by the Peli because the synchronization has a phase difference of either zero or PAE. OK, so what we're going to do now is compare the previous results to the results from the plaza. And so let's see what we want to do here. We want to copy and paste the code from above, except use the policy and instead of the voltage data. OK, and then we're going to put the those plots down here. All right. So let's see how much we need to copy. Certainly we need to copy and paste this stuff and this and this. Now, the thing is, we are not actually using different wavelets, different frequencies. You know, all of this stuff actually really should stay the same. Right, because we want to be able to compare the new results against these results so we don't need to copy and paste all of this stuff. Now, if you prefer, instead of copying and pasting, you could also just modify this code here that will prevent you from having to, you know, recreate the wavelets on each iteration of the loop and so on. But that part's not so important. So I'm going to copy and paste here. So the first thing that we need to do, of course, is compute the replacement. I'm going to write each lap. Remember, I've introduced this idea in some previous video that it's useful to create a new field in the structure for the lipless in rather than overwriting the original voltage data. So then we can sell access to voltage data if we need to for subsequent analyses. Let's see, this function was called Look Plus See in X and we input the data and then the X axis or X locations for the channel, the Y locations for the channel and the Z locations for the channel, run that and that works. So that's good. And here we take the feed, not of the data, but the application. So the data of course, but different variable name. And here we can initialize again. That's fine. Create the wavelet. That's the same. This is the same. Actually all of this is the same. So let me run all of this code here, make sure that I'm not missing anything. OK, that's good. And let's see. Now we need to do the plotting, so that's going to be here. I will copy and paste this. I don't want to copy this line because I don't want to clear this figure. We're using the same figure. And what do we need to change? We need to change. This is going to be subplot. Subplot. Geometry is still two by two. So we have two rows and two columns. But now, instead of the first panel, the first subplot, we are going to put this into the third subplot. And this I will call LE Plus scene and set of voltage. And then here, of course, this is going to go into the fourth subplot and this is also the LE plus Ian. All right. So let's do this plotting here and wow, quite different, isn't it? So first, let's discuss the, uh, the play with voltage versus the plus and compare these two. So what you see is overall, they look quite fairly similar, but definitely not identical. So even though the phase like index is blind to volume conduction, the results can still change before versus after applying the law plus in. And that is because the LE plus in is not simply a spatial filter that removes volume conduction. That's kind of what we use it for. But that's not how it works. The way that the LE plus in works is by filtering out or attenuating low spatial frequency information in the EEG. So we are changing the topographies of the EEG. We are changing the data by applying the lipless. And now that's not a bad thing. That's equivalent to temporally filtering time series data, which is what we're doing here. But it is important to realize that although the LA Plaza is a really great spatial filter for computing, electrode level connectivity and also other kinds of analyses, it will change the data. It's going to change the data. And you also saw this in the Matlab video where I first discussed the lipless in real data. And you saw that there were some channels that look really similar before versus after applying the Persian and other channels that look really different. OK, anyway, that's just a reminder. I think there's still overall a lot of qualitative similarities between these two plots. But what really changes, of course, is these two this is remarkable. All of this bright white stuff, which I said was most certainly attributable to spurious artifacts from volume conduction that's now basically completely gone. And in fact, the phase clustering with the LA Plasty and data now looks really, really similar to the results of the phase lag index. In fact, it just looks like, you know, if I would have shown you these two maps without the title and without showing you the Matlab code, you might have just thought that this is a smoothed version of this, that these two are the same and this one is just smoothed a little bit. So pretty interesting that the LA Plaza and has such a powerful effect on a level synchronization.
In the first video of this section of the course, I mentioned this distinction between connectivity

over time versus over trials.

Now, that distinction might have seemed a bit mysterious back then, but now you are smarter.

You are a more knowledgeable, intelligent person than you were 10 videos ago or whenever that was in

particular, because now you understand the mechanism of computing synchronization in time series data.

So now I'm going to get back to this issue and discuss it a little bit more, make sure that it's a

really clear distinction.

And then I will spend a moment at the end about the advantages and limitations of different or these

different dimensions over which to compute connectivity.

So here is that figure that you saw before.

So now you can interpret what these lines are.

This is time each of these rows corresponds to a trial.

And what you're looking at here are the phase angle differences between two electrodes.

So this is the phase angle difference time series.

This is in radians.

This y axis here would be in radians.

And then you now know that the idea, the way that we quantify synchronization is by generating a distribution

of phase angles that prescribed these vectors in the complex plane.

So you have all of these unit vectors here and this circle and they have a length of one and an angle

that's defined not by the angles of any of the individual electrodes, but by the phase angle difference

between the two electrodes.

OK, and then the question is, how do we generate how do we populate this circle of of vectors?

Do we get these vectors by populating at each time point over the different trials or over time?

So then each vector corresponds to a different time point within one trial.

So I hope that distinction is now clear.

In this case.

We are computing phase synchronization over trials.

The term here is ISPCC, but of course this applies equally well to phase lag or really any measure

of synchronization.

So do you populate this distribution based on vectors that are taken from a single time point over all

of these different trials?

Or do you do this over one trial and get all the time points and then generate that distribution?

So when should you compute phase synchronization over trials and when should you compute phase synchronization

over time?

So over time, computing synchronization over time makes sense if you have a resting state task or really

long tasks resting state, obviously, because you don't have trials, there is no inherent repetitive

trial structure.

So it doesn't even make sense to compute synchronization over trials for resting state data.

And this could also be the case for long tasks.

This could be, for example, let's say you're doing a memory task, so you show your research participants

a picture and they're supposed to remember the picture.

And then nothing is happening for, let's say, 10 seconds.

They have 10 seconds where they're just keeping that picture in their mind, in their working memory.

Now, in that case, you might also compute connectivity over time.

The downside, the limitation of computing connectivity over time is that you have no temporal resolution

or poor temporal resolution.

And that's because you can see here.

So in this diagram, the way I've drawn this here, we get.

So this is one trial.

Imagine this is time zero here.

We get essentially one value, one synchronization value for the entire trial.

Maybe this is one second.

And you already know that a lot can happen in the brain in one second.

So maybe there is like really, really strong synchronization here, but no synchronization here.

And then you average all these time windows together and you are potentially reducing your sensitivity

to detecting synchronization because you're just averaging over a large window of time.

So that is a risk that doesn't necessarily happen.

But there is a potential risk that the temporal resolution decreases.

You're putting a lot of time points into the same analysis.

So the over trials method, so synchronization over trials.

This is the most commonly done synchronization method for trials.

If you have repetitions of a particular stimulus that's happening and you have dozens or a couple of

hundred of these trials, and of course, this also maximizes temporal resolution.

And that's because with connectivity over trials, you have a different connectivity value for each

individual time point.

So you computing the connectivity that's consistent over trials.

Between these two electrodes at each individual time point, so then the temporal precision of connectivity

over trials is really just determined by the temporal precision or the smoothing of the wavelengths

that you apply.

So how much smoothing is already intrinsic to the time frequency analysis?

Now, of course, you could use the you could get more temporal information out of connectivity over

time.

And I'm sure you're already thinking about this as I was describing it.

And you could do that by computing the synchronization over time, for example, in windows.

So instead of getting one connectivity value over this huge time window, you could do this in little

blocks of time.

Let's say, you know, maybe you want to set that window of time to be, I don't know, three cycles

at the frequency that's used for this step of convolution.

So let's imagine that this is 10 hertz.

We're looking at synchronization in 10 hertz that maybe you want to set the window size to be 300 milliseconds.

That would give you three cycles at 10 hertz.

So, of course, there is a way to be flexible and combine the advantages of synchronization over trials

with the synchronization over time.

Nonetheless, these are just things to think about as you're doing your analyses.

So my recommendation is that you use synchronization over time when you have resting state data or if

it's like sleep data, spontaneous data where you don't have a trial structure or if you're doing if

you need to extract a single trial connectivity.

If you want a connectivity value per trial and a separate connectivity value per trial, then you could

use connectivity over time and connectivity over trials would be kind of your standard go to method

for if you're looking at phasuk changes in task related experiments, like with many other ways of analyzing

data and possibilities for customizing data analysis methods.

This is also a choice that there's no you know, there's no right or wrong choice there.

You just have to think carefully about what makes the most sense for your particular experiment and

your particular hypothesis.
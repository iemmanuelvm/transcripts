You have seen throughout this section of the course just a tiny little taste of all of the possible

connectivity methods, and it's not even possible, even if I wanted to do a completely thorough teaching

experience of all the connectivity methods that you can possibly apply to your electrophysiology data,

that would still be impossible, because every year and multiple times a year, there are new connectivity

methods that random people are, you know, sort of coming up with or adapting from engineering or physics

and introducing to the literature.

So there are many, many choices for which connectivity methods to use, which parameters to use, how

to set up the connectivity analyses and so on.

So there's many choices.

I am not going to give you any specific advice in this video.

I did try to give a little bit of specific advice in several previous videos, but otherwise I just

want to kind of discuss this issue more generally.

So this is a totally non exhaustive list of various connectivity measures that are used in the literature.

Now, some of these I focused on more in this section, a few other of these I've mentioned and talked

about.

But there's lots of other methods that I haven't really discussed and a lot of other methods that aren't

even listed on this slide.

So what do you do?

How do you know which analysis methods you should use?

Well, here I'm going to give you some general considerations that will help you make your decision.

I can't make this decision for you.

These are just questions to ask yourself and to discuss with your colleagues and your collaborators

when deciding on which analysis method to use.

So are there volume conduction issues that you have to address?

And how are you going to deal with those volume connection issues in this section?

I presented two different approaches for addressing volume connection.

Do you want a directed synchronization like Granger causality or are you happy with and a symmetric

measure of synchronization?

Are there some physiological constraints?

And by this I mean, are there neuroscientific theories that are guiding your choices so you can draw

on your theoretical understanding and your predictions or hypotheses about what's happening in the brain,

and then let that guide your decision for what analysis you should do, as opposed to saying, well,

you know, now I learned in this course how to do Method X, so now I'm going to apply Method X to all

the data I have.

A much better way to do it is to start by, you know, some some brain theory, some physiological theory

and then figure out what is the most appropriate analysis.

Another consideration that can help guide your making is whether you are replicating or following up

on previous research.

And if that's the case, then you should try to stick to the methods that the other research used as

close as possible.

So if you are trying to replicate someone else's findings, then you should try to use their methods

as well.

And you can also think about whether your whether you're doing your connectivity analysis in a strict

hypothesis testing framework or if this is more open exploratory data mining kind of an approach.

All right.

So these are some general considerations.

If you don't know which method to use or if you have a method, but you don't know which parameters

to use or how to set up the the the choices that you have to make for, like picking time or frequency

windows and thresholds and so on.

Then my general advice is to motivate one method, pick one method that is strongly motivated based

on theory or or prior data or publications.

And then once you've decided on that method, continue to use it consistently throughout.

So any possible biases or weird things going on with that one method are applied equally well to all

of your analyses.

So that is one approach or you can do it another way.

You can use a lot of different methods and then report all of the results so you can test out five or

six different connectivity analysis methods.

But then you should.

So if you're doing that, that's fine.

I encourage multiple methods, multiple analysis approaches to doing research.

But then, of course, the wrong thing, which is borderline unethical, is to pick the results that

you think look best and then only report those.

So if you were using a lot of different connectivity methods, then it's good to report all of those

methods from all the analyses that you've done.

And then yet another possibility, which is kind of related to these to both of these, it's kind of

an interaction between these two is to do with an experiment.

Replications also sometimes called split half reliable.

Or cross-validation, the idea would be, for example, imagine that you have 40 data sets, so then

what you can do is take like ten of those data sets.

You pick ten data sets at random and you try a bunch of different methods, a bunch of different parameters,

all sorts of wacky things.

And you just pick the methods and the parameters that you that give you the nicest looking results in

that sample of 10 data sets.

And then you put those 10 data sets aside.

You don't analyze them anymore, but you use the analysis protocol that you developed on those 10 analysis

methods and you apply those to the other 30 data sets.

So now the idea is that you're potentially overfitting some those 10 data sets, but then you're applying

the methods, the protocols, the analysis procedures to the 30 data sets that you haven't yet analyzed.

So that would also be a valid way of doing within experiment replications or cross-validation.

OK, so I hope this helps you a little bit, at least navigate through this really complex, rich world

of connectivity methods.

In the next video, we are going to get to a problem set.

It's going to be really fun.

I'm already looking forward to it and I hope you are, too.
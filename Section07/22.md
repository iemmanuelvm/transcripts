 In this video, we are going to put into practice some of the material that we learned about in the past, several videos in particular regarding decibel normalization and choosing different bass line windows. So we're going to do is analyze the same data using different time windows for the normalization. So these are the times in milliseconds relative to stimulus onset set. So minus 500 to minus 200 and so on, down to minus 800 to zero. And so here what I'm doing is just transforming these from numbers in milliseconds into indices that we can index. So let's see, I've already cleared out everything in the workspace, so there's nothing in the workspace. So let's start running some of this code. Oh, when we get an error, unable to resolve the name eg time. So e.g. that times of course is in the sample data set, so we need to load in that data set here. So OK, so now this works so we get the baseline or the time indices that we are going to be using for the baseline windows. So set up some wavelet and convolution parameters. We are going to extract frequency information from two hertz to thirty hertz in 40 linearly spaced steps. And we are going to use Channel one and we're going to use a range of cycles from four cycles to 10 cycles with increasing frequency. So let's see. Let's run all this. Here we are defining the parameters and the number of cycles and let's make sure this works o invalid expression. So let's see. We have log space from log 10. I explained why you need this a few videos ago from range cycles one to range cycles end, which is the same thing as two. So that part's fine. And then here we are dividing by a normalization factor goes here. Unfortunately, although this is a very clear piece of text, it is not valid code. So this needs to be two times PI times the frequencies, which is probably called Frex. I usually call this variable Frex. Yeah. OK, so now let's see if this works. So the number of cycles normalized looks like this. OK, so then all of the rest of this looks OK. So here we have the FFE parameters, we have the length of the wavelet, the length of the data, which is points by trials. And of course we have the length of convolution and plus and minus one. So then compute the spectrum of the data first vector arising out all of the data and then taking one. So we are creating a super trial, taking one big FFE of that. And then here we have our time frequency matrix will be size based IDEX one. This means the number of rows in the matrix of baseline window options. So this is going to be a four by frequency's by time matrix. All right. It's very good. Now perform convolution. So we're looping over frequencies, create the wavelet. So that's E to the I to 50 times E to the minus T squared over two squared. So that part looks good here. We normalize the wavelet and I'm actually going to get back to this line in a moment. Run convolution. So this is the meat of convolution here, the most important bit. And let's see. So I think all of this looks fine. Yeah. OK, so I would like you to think about whether this line of code here is actually necessary. I've discussed this several times. I've motivated this. I've explained why we do this Max value normalization. I'm actually going to make a claim now that this line of code is not necessary for this particular exercise, for this particular video. And I would like you to think about why exactly this line of code is not necessary here. OK, so I'm leaving it in now and then I'm going to rerun the code later and without this line and explain why it's not necessary. Let's see. So here we do the normalization and let's see. So we are defining color limits. This is going to be for the plot. And then I'm not sure what this comment refers to. Percent change because I don't see. I think that's OK. Oops. I think this is this comment is probably and also this variable name is copied from some other code where I was also implementing percent change. Because that doesn't even get used anywhere. OK, so I admit that I'm a little confused myself, but I think what happened is I copied some of this code from elsewhere. And and, yeah, I just I forgot to edit that out anyway. It doesn't matter. So here we are looping over the different baseline windows. So we extract the activity. And this is an interesting line of code here, because you might think that this is a mistake. You might think that I should actually be computing this activity and this baseline here from the base I index. So let's look back up and see what's going on here. So if we look through this loop, which we've already run through, notice that although this T.F. variable has four elements in the first dimension, we are only ever putting the power data into the first or the fourth element of the first dimension. So, in fact, if I were to say T.F. and then give me, you know, show me all of the information in the first dimension for frequency one time point one, we see that it's all zeros in the first three dimensions and then we get some power value for the last element here. So in fact, that's actually just kind of a clever way to to go through this. So here we are defining the base ith index into this first dimension, but we're only ever using it for taking it from the power, from the fourth dimension. So it's a little bit of tricky coding here. So anyway, here we extract the time, frequency, power and here we are going to compute the baseline. So this is the baseline over from from the power dimension, from all of the frequencies and these particular time points. So and then we are averaging over the third dimension. So let's run this here so we can see that activity is. So this is a one by 40 by 640 matrix. So we are going to have to keep in mind that there is a singleton dimension in here. There's still a three dimensional matrix. And then the baseline is that see what that looks like? So now the baseline is one by 40, which is the number of frequencies, so we can actually plot this, I can say plot Frex by baseline. And what this is showing me is the baseline power over different frequencies. So it's pretty interesting, you see that there's, um, there's a one over off and then there's a lot of power here in Alpha and then there's also some power here in beta. So what do we want to do here? Well, for starters, I'm going to squeeze out this singleton dimension here. So that's going to get us from a three dimensional matrix with a singleton dimension to a two dimensional matrix. And then what we want to do here is something like activity, activity divided by baseline. However, this code like this is not exactly going to work. And the reason is that this is a matrix and this is a vector. So it's not possible to divide a matrix by a vector just like this. Instead, what we need to do is expand this baseline for all of the time points. So what we want is a matrix of 40 by 640 where every element in the time dimension is exactly the same as these values here. And the reason why we want every element to be exactly the same over time is that every time point in the activity map is going to be divided by the same base line for that particular frequency. So we can do this in two ways. We can use the function Repp Mapped, which stands for Replicate a Matrix. So we want to do is replicate this and convert this into a 40 by 640 matrix. So the first thing we're going to do is transpose this. So it goes from a row vector, which is what it is now, to a column vector. And then we want to repeat that column vector such that it forms a matrix of one by IEG points. So let me copy and check the size of this and you can see this ends up being a 40 by 640 matrix. And now I'm going to make an image of this so we can see what it looks like. Now, notice it's all flat lines going across here and that makes sense. This is frequency's going down here. This was that alpha peak that you saw in the line played a moment ago. And this is a little beta peak. And then what you see here is all 640 time points. So the baseline is the same for every time point. OK, so then we can I think all of this code will run now. OK, good. So this is one way to do it. You could also solve this using another function called BSF fun, which I won't show you right now. If you're curious, you can see if you can figure out how to get this to work, how to get basically this division to work with. It's fun. I show that later in the code and other examples in later videos. OK, so then finally, let's create this plot and this is just making a contour map of the time frequency data from this baseline time window. So you can see is that well, it's interesting to see how these differ. So this is the baseline time window minus five hundred to minus 200 that I claimed in the lecture in the previous video that this is really the best baseline normalization. This one is obviously wrong. It goes from zero to three hundred milliseconds. So it includes the stimulus related activity in the quote unquote baseline. And these ones are also OK, but not as good as this one. And that's because the baseline time window goes up to zero where we get a little bit of temporal leakage from the early stimulus activity. All right. So before I close this video, I made a claim that we don't actually need this line. So I'm going to do a comment out that line, make this B figure twenty, and then I'm going to run all of this code again, maybe even reinitialize the time frequency matrix. So it's technically not necessary. And what you can see is that it produced exactly the same plot. I'm now you know, you can look up here, I'm actually going back and forth between these two figures and the results are identical. They are exactly identical. So why is this line of code not necessary? Why don't we need this line? And the answer comes from the decimal normalization. So what that line of code is doing is just changing the. The magnitude of the activity on the y axis and here we are normalizing out that activity, so whatever we do to it that will affect all of the frequency points within a time series equally is going to be undone by this baseline normalization. So that means we could also take this time frequency map and say, you know, we could multiply this all this time frequency power by some really large number. And it doesn't change anything because, well, it changes something here. But those changes all get undone here. And that's because this scaling factor extends into the activity and into the baseline equally. And so it gets normalized out. So that's pretty interesting to know that this line of code is only necessary. This max value normalization of the wavelet in the frequency domain is necessary only if you want to interpret the raw power in terms of the units of the original data. So we saw in a previous video with ETPs, with phase clustering that you don't need this line of code if you're just extracting phase values. And now in this video, you see that you do not need this line of code, if you will, be decibel normalizing the power values. 

I have mentioned several times before that there are multiple ways to implement a time frequency analysis

so far in this course, I really only told you about time frequency analysis via complex Morleigh wavelet

convolution.

What I'm going to do now and over the next several videos is introduce you to a few other methods for

time frequency analysis.

So we have the Filter Helbert method.

And then soon, I think in the next video I will tell you about the short time for you to transform.

And then a few videos later, I will tell you about another method called the multi taper method.

So in total, I'm going to introduce you to four different time frequency analysis methods.

In this course, these are not the only four.

There are many other methods, but these four, I think, are the most commonly used and other methods

are basically, you know, mostly just different variants of one of these methods anyway.

So let us begin I'm going to start talking about the Hilbert transform and what the Hilbert transform

does and why it's useful.

So let's start with this.

This is a real valued wavelet now for our present purposes.

We not needing this because it's a wavelet.

I'm just treating this as a signal, as a way to illustrate to you how the Hilbert transform works and

what it does.

So we have a signal that happens to be a more wavelet.

Now, this is a purely real value.

Morleigh Wavelet.

This is not a complex valued wavelet.

There's only a real part here, just a cosine.

So this is what the real value Morleigh Wavelet looks like in the time domain.

And this is what the amplitude spectrum of the more they wavelet looks like in the frequency domain.

So here are the positive frequencies.

Somewhere around here will be Nykvist and these are the negative frequencies.

And because this is a real value signal, the amplitudes gets split between the positive and the negative

frequencies.

So we have this symmetric spectrum.

Now, what would happen if we take the Hilbert transform of this wavelet?

It would look something like this.

And what you can see is that this actually is a complex value signal.

So when you take the Hilbert transform are very real value signal.

The output is, in fact a complex valued signal.

So it has a real part and an imaginary part.

The real part is in green.

The imaginary part is an orange dash line.

So why does this happen and how does the Hilbert transform work?

Well, the way that the Hilbert transform is implemented in computers is often something like this.

Now you look at this and this looks familiar.

This is the power spectrum of the complex Morleigh wavelet.

But that's actually not what we created.

What we created was the Hilbert transform of a real valued wavelet and in fact, what the Hilbert transform

does.

So the mechanism of the Hilbert transform is to take the F.T. of the signal, which is this go into

the frequency domain zero out all of the negative frequencies, double the amplitude of the positive

frequencies, and then take the inverse Fourier transform.

And so what happens when you do that?

You know, you go from here from a real value signal into the frequency domain.

You obliterate the negative frequencies, double the amplitude of the positive frequencies, and then

take the inverse for you transform that ends up giving us a complex valued wavelet.

Now, the goal of the Hilbert transform is not necessarily to give us a complex valued wavelet persay.

Instead, it is to give us a complex value signal, also called an analytic signal that we can use to

extract power or amplitude and phase information in addition to the real part of the signal.

So application of the Hilbert transform.

It converts a real value signal into a complex value analytic signal.

This result, as it turns out, is analogous to the result of complex Morleigh wavelet convolution.

So what you can do with a Hilbert ised signal is extract the magnitude and phase just like you would

with a with the result of complex wavelet convolution that you've already learned so much about.

So let me show you a little bit more of an example.

So here we have the signal and this is a real value signal.

Here is the Hilbert transform of this signal.

So you can see it as a real part and that has an imaginary part.

And then we can take the magnitude or ABB's of the Hilbert transform of this signal.

And we get this envelope here, this analytic envelope, or sometimes called the amplitude envelope.

And we can also extract the angle from the Hilbert transform of the signal, and that would give us

something like this.

This is a phase angle time series now similar to what you learned in the section on estimating phase

in the relationship between phase and amplitude in a section on the Fourier transform.

These values, these phase values all the way out here are basically meaningless.

These are impossible to interpret.

The signal is zero.

There's the the amplitude is basically zero.

And so these coefficients are these complex numbers are so close to the origin that it's just really

not possible to estimate the phase values with any real accuracy.

OK, so one of the features of this signal is that it is very well localized in the frequency domain.

So it looks like this in the frequency domain.

This is a narrowband signal in the frequency domain.

What would happen if we applied the Hilbert transform to a broadband signal like noise?

So now what I've done is exactly the same procedure as in the previous slide.

However, I replaced the signal as a Morleigh wavelet with just white noise look something like this.

So here you see the output of the Hilbert transform.

So that's the real part and the imaginary part.

Here you see the magnitude and here you see the phase.

Now, this does not look like a phase angle time series that we expect.

Right.

When you think about what a phase angle time series would look like, it has this kind of sawtooth pattern.

Of course, this is with the phases kind of artificially plotted on this Cartesian linear plot like

this.

Really, these phases are spinning around.

But this does not look like the typical phase angle time series that you would expect.

Why is that the case?

Why are these phase angles all kind of screwy and not what you would expect them to look like?

And that is because of this really, really important point, and that is that the power and phase at

each single time point resulting from the Hilbert transform come from the frequency that has the most

power at that single time point.

Now, when we go back to this example, we have a signal that is very well concentrated in the frequency

domain.

So that means that these angles in this this magnitude is basically coming from the same frequency.

But when we have white noise at every time point the frequency at which each time point has most power

is going to change wildly from time to time point.

So it's entirely possible that at this time point, ten hertz has the most amount of energy and at this

time point ninety seven point three hertz has the most amount of energy.

And here it's like one point seven hertz has the most amount of energy.

And that's because this is a purely random signal.

It is not constrained in the frequency domain.

OK, so therefore the output of the Hilbert transform is interpretable only for narrowband signals.

So that means that you shouldn't apply the Hilbert transform to broadband data.

So you should only apply the Hilbert transform to narrowband data.

But of course, EEG and LSP are broadband phenomenon.

They have energy at a whole range of frequencies.

So what is the solution?

What do we do about this?

Well, I'm sure you have already guessed it.

We have to filter the data first so we apply a filter to the data that gets us from our original signal,

which is broadband to a filtered signal, which is narrowband.

And then you can apply the Hilbert transform to this narrowband filtered signal.

Now, you already know that wavelet convolution is Narrabeen filtering with a Gaussian.

What I'm going to talk about now is FBAR or finite impulse response filtering.

OK, so I'm going to talk about designing FBAR filters and in particular I'm going to focus on Bumpass

filters.

The mechanism would be the same if you are doing a high pass filters or low pass filters or notch filters,

which are also called Benschop filters.

But I'm just going to do my explanation in terms of bad pass filters, because bad pass filters are

obviously what you would use for time frequency analysis.

So the way that you design and F.I., our band pass filter is by coming up with a set of points that

show gain on the Y axis and frequency on the x axis and the frequency has to go in units of Nykvist.

So the number one in frequency.

So so basically the frequencies get normalized to Nykvist.

That's what I meant to say.

So the value of one corresponds to the Nyquist frequency.

This is.

A pretty useful normalization because you want these filters to be able to be designed without having

to worry about the sampling rate.

So that's why you only specify in terms of Nykvist.

So, for example, a typical Bumpass FBAR filter has specifications that look something like this.

So you have six data points.

You need one at zero.

That's for D.C. and you need one at one, and that's for Nykvist.

And then you have four other points.

And these define the shape of the filter in the frequency domain.

So these two points would correspond to the cutoffs that you are interested in.

So let's say you would like a filter that goes from eight to 12 hertz.

So this point here could be eight hertz and this point here could correspond to 12 hertz.

Of course, you would have to convert that into the fraction of Nyquist that 12 hertz ends up being

based on the sampling rate and so on.

OK, and then we have these other points here, and this is called the transition zone.

So this point is eight hertz and maybe this point is, I don't know, six hertz and this point is twelve

hertz.

And this might be 15 hertz.

The idea of having a transition zone like this is that you don't want to specify the filter with perfect

edges.

You don't want a sharp edge in the frequency domain.

And the reason why is because that will introduce a sharp edges in the frequency domain.

When you take the inverse Fourier transform that sharp edge, that's going to produce a lot of ripple

effects in the time domain, which can introduce artificial oscillations into your data.

And this I discussed before in the static spectral analysis section on sharp non stationary.

OK, so this is generally the idea.

So then the transition zone is typically around 10 percent or maybe 15 percent.

So this point would be 10 percent of whatever this point is and this point would be 10 percent plus

whatever this point is.

So then you have your ideal filter that you specify like this, and that's indicated in this red line,

and then this is the set of numbers that you apply to a Matlab function like F.R. else, or FBAR p.m.

or there's a bunch of other there's several different mechanisms, several different algorithms for

computing and FIA filter.

There's also another one called FLIR, one where you only need to specify these two points.

And Matlab will try to make this these transition zones as narrow as possible without introducing too

many artifacts.

The outcome of this function, for example, Fiorelli will be a filter colonel in the time domain,

and that might look something like this for this particular filter.

So it's interesting to look at this thing.

You can see that it kind of looks a little bit like a wavelet.

I mean, it's not exactly a sine wave and a Gaussian, but you can see that it has some kind of ringing

and as some sort of rhythmic components.

And it does have something that looks, you know, it's not really a Gaussian, but you can see that

there's some kind of like a tapering function that's enveloping this filter kernel.

And then this filter kernel gets applied to the time series data and that gives you a narrowband signal.

Now, that signal that you get back is going to be a real value narrowband signal and then you would

apply the Hilbert transform to the output of the filter.

Now, particularly when you are just starting, when you were designing new filters, it's really important

to inspect this filter kernel carefully.

And in particular, what you want to do is look at the amplitude spectrum of this filter kernel and

plot it against the requested filter that you input it into the FARC or other function.

So that would look something like this.

And this allows you to evaluate both qualitatively and quantitatively the quality of the filter that

you got back.

So, for example, you can see that this actual filters of the black line.

Here is the amplitude spectrum of this filter.

Colonel, it's not really terrible, but it's also not so great.

You can see it's well, we get an overshoot.

So we're actually amplifying some energy here at, you know, whatever this is.

Twenty five hertz and we're undershooting here a little bit.

So we're missing part of this.

And I guess over here it looks OK.

So if you look at your filter in the frequency domain there and it looks something like this, then

essentially you want to play around with the parameters of the filter a little bit and come up with

a another filter kernel that looks a little bit more solid.

Now, one thing you could do here is increase the frequency resolution and that you can do by increasing

the number of time points, the number of time points in your filter, Colonel, is called the order

of the filter.

It's also sometimes called the taps.

So the number of taps in the filter or the order of the filter is fancy terminology, but it's basically

just the number of time points.

So the more time points you have, the larger the order of the filter, the better the frequency domain

response is going to be.

This is the case for our filters.

IIR filters are another matter.

I will talk about those in a moment.

You can also try changing the width of so the bandwidth of this filter, you can make this narrower.

That should help with a filter like this.

And you could also change the transition zone so you can make the transition zones a little bit wider,

a little bit gentler.

And that will also help give you a better, cleaner and higher quality filter, Colonel.

But you can see that there's quite a few parameters in designing FBAR filters that we don't have to

worry about with more they wavelets.

So I already mentioned several.

Let's see, I mentioned the exact algorithm.

I mentioned the order.

I mentioned the bandwidth and I mentioned the transition zones.

So already quite a few dimensions of this parameter space that you can play around with in order to

make sure that you get good, well designed, high quality filters.

That is actually one reason to prefer more wavelet convolution over Filter Hilbert as a method for time

frequency analysis.

OK, I want to say something very brief about FLIR versus IIR filters.

And then after this, I'm not really going to talk a whole lot about filtering other than some illustrations

in Matlab.

I'm not really going to talk much more about the mechanisms of filtering.

We could have an entire, you know, 20 hour lecture series just on fire and IIR filters, but I'm not

going to get.

Deep into that rabbit hole, so the name finite impulse response, infinite impulse response, the kernel

length, so the length of the filter kernel for fire filters, it's long.

It's typically hundreds of points long, sometimes thousands of points long, depending on the frequencies

and so on.

And I our filters tend to be really short.

They tend to be maybe two, three, four, sometimes five.

You might see a IIR filter that gets up to seven points long, but that's pretty rare.

Once these IIR filters start getting longer, once the order gets higher, these filters become wildly

unstable and just unworkable.

Now the thing is that IIR filters are really fast to implement and I will explain why that is in a moment.

So if you were doing real time online filtering, then you might need to use an eye.

Our filter if you're doing offline filtering and then I recommend sticking with an F our filter.

They are slower.

They're slower because the kernel length is much longer.

So the order is, you know, we're talking about half a dozen points here versus hundreds or thousands

of points here.

So there are a little bit slower.

But to be honest, I mean, this is factually correct.

But on modern computers, this is not a real limitation for filters are still generally pretty fast.

Now, the thing is that FIA filters are much more stable.

They are they give higher quality results, particularly at estimating phase values.

IIR filters are less robust.

They are more sensitive to noise or other unusual features in the data, and the quality is generally

going to be lower.

So that's the tradeoff.

If you have to filter the data really fast, IIR filters are better but less accurate.

If you have the you know, if you're doing offline analyses, then definitely go for FBAR filters.

They will add, you know, a couple of seconds to your data analysis pipeline, but they are higher

quality.

They give more stable results.

And the reason for this is that FIA filters involve multiplying the data with the kernel.

So you get your kernel, you multiply it by the data, something that's a little bit similar to convolution,

although it's not formally a convolution.

And that gives you the result.

The way that I our filters work is you take your short little kernel and you filter a little piece of

data and then you take the data that you've just filtered and used that as an additional part of the

kernel for filtering even more data.

So you're using the data to filter more data.

So that sounds very fancy.

And it's it's you know, it's quite clever.

Whoever came up with these Mr. Infinite Impulse response, I guess.

But in practice, this can mean that if there's weird things happening in the data that can introduce

artifacts into the kernel itself, which means that strange things happening in the data are going to

just reverberate further down the data and get worse and worse over time.

Now, if your supervisor is like 80 years old, then he or she probably insists on using IIR filters

because, you know, back in, like the 1970s, the computational power just wasn't good enough for

FBAR filters.

If you are doing your research based on IIR filters, then you shouldn't be concerned.

The thing is that at best, in the best case scenario, FBAR and I, our filters will be equally good

and then in other situations, FBAR filters will be better.

So it's I find it unlikely that you're going to get really qualitatively different results, like amazing,

beautiful results with an FOIA filter and total unpublishable, horrible, meaningless and yeah, just

terrible results with air filters.

So don't worry too much about it.

But if you are starting new research, then definitely go for F.I. our filters.

All right.

So that leads us to the filter Helbert method and it's a really complicated procedure.

Let's see how to do it.

Step one is to filter.

Step two is to apply the Hilbert transform and step three is to extract power and or phase.

So this is a slide that you have seen before.

This is for extracting information, time, frequency, power and phase information.

And the Narrabeen filtered signal from Wavelet Convolution Complex Morleigh Wavelet Convolution.

And now with the filter Hilbert method, it's all of these steps are exactly the same.

The only thing that's different is here.

So here you Narrabeen filter and apply the Hilbert transform instead of doing complex Morleigh Wavelet

convolution.

Otherwise, the procedure is all basically the same.

Now, you might be wondering what are the situations when you should prefer filter Helbert method over

complex wavelet convolution and how do they compare with each other?

Now, I'm not going to get into the differences and the comparisons in this video because I want to

have a longer, separate video just on that topic.

So for now, suffice it to say that Filter Helbert and Complex Morleigh Wavelet convolution are in general

more or less the same.

They give you really, really, really similar results.

There are a few situations where you would prefer Filter Helbert over Wavelet convolution, and I'm

going to talk about that in a later video.

That video title is going to be something like comparing Wavelet Filter Helbert and Short Time F.T..

So you have something to look forward to in addition to the next video.


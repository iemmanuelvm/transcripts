Now that you have a bit of background about using linnear least squares algorithm to do within subject

or cross trial regression analysis, I'm now going to walk you through a couple of examples.

There's going to be two examples.

They're both closely related to each other.

But we're going to start off with something that's a little bit simpler and then we work to a full time

frequency map of correlations.

OK, so let's start by loading in our data set and let's hope to see what is contained in this data

set.

So we have a couple of variables.

EEG data, Frex and Arties.

So EEG data, this variable is thirty by ninety nine and the comment period tells us that this variable

is frequency's by trials.

So we don't actually have any time in this data set.

There's no time, there's just frequencies and trials.

So this is obviously a vector that contains all the frequencies.

And here we have the variable RTC, which is reaction time.

So it's basically how long the research participant took to press the button on each of ninety nine

trials.

So what we want to do here is correlate the reaction time with power at each frequency over all the

different trials.

OK, and that's what it says here.

So the goal is to test whether EEG frequency power is related to reaction time over trials.

OK, so then let's see, we're going to start by showing the data and well, just looking at this line,

obviously something is missing, but we don't really know what we're supposed to plot.

But I think if we look forward to the next line, we can see that it's going to be trials on the x axis

and reaction time, response time on the Y axis.

So this should be variable artiste's.

So let's already take a look at this.

So here you see the reaction times.

This is in milliseconds.

So five hundred milliseconds is one half of one second.

And here's the ninety nine trials over here.

So it's interesting to see there's some variability, there's some fluctuations.

Sometimes this person press the button a bit faster, sometimes they pressed a bit slower.

And it's also interesting, kind of looks like there's a downward trend mostly here.

Maybe it goes up a little bit here, but it kind of looks like they get a little bit faster gradually

over the course of the experiment.

Anyway, that's not really the point.

The point is we want to see whether these fluctuations are meaningfully related to fluctuations in the

EEG signal.

And that is probably what we are going to be producing an image of here.

So here we have trial on the x axis and frequency on the Y axis.

So I'm guessing that we are supposed to make an image of EEG data.

OK, so here you see the data and it's a little bit weird at first to interpret because this is not

a time frequency map that you are so used to looking at.

This is actually a trial frequency map.

So each column here shows the power spectrum of a single trial.

So there's no time in here.

We don't have time.

The frequencies are just at or each frequency value.

Each pixel value is the average power in some time window.

And I think what you're supposed to see is that there's also variability across trials in the frequency.

So, for example, if there was no variability, if the brain were perfectly deterministic, noiseless

system, that responded exactly the same way on every single trial, then you would expect the colors

here at each row to be identical.

But they're not identical, you see, is quite a bit of variability across trials at each frequency.

So the question is, are is this variability across trials in the EEG signal related to this variability

across trials in the behavior?

OK, so here's a question.

Is there a lot or a little bit of variability in the art or the brain signal over trials?

Well, OK, these are an apology quotes for a reason.

These are totally non-technical terms.

The main point, the main reason why I ask this question is exactly this discussion that I just had.

I want you to think about the fact that there is variability and maybe the variability in this variable

is meaningfully related to the variability in these variables here.

And by these variables, I mean all these different frequencies.

OK, let's see.

So let's start by computing the effects.

And by this I mean the multiple regression over different frequencies.

So we are going to regress this trial series here onto each row in this matrix.

So each frequency of the data.

So we loop over the different frequencies here.

I create the design matrix.

So let's have a look at this matrix.

Let's see.

I need to initialize this.

So the design matrix, as I discussed in the previous video, is a matrix that generally has at least

two columns.

The first column is All Ones.

This is called The Intercept.

It captures the just the general offset term.

In our example here, the intercept is going to capture the fact that the average reaction time is greater

than zero.

So the fact that reaction time is not average to zero means that we need this intercept term here.

Now, you could actually get rid of this intercept term if you would mean center everything.

If you would force the mean of all the data to be zero, then you don't actually need the intercept

term.

However, it is pretty typical in in statistics and regression modeling to keep this intercept term

here.

So I recommend it.

OK, and then we have the second column of our design matrix and that is the independent variable,

which in this case I'm taking as the EEG signal across the trial.

So this is this column is contains the power values from the lowest frequency, whatever that first

frequency is.

I guess it's two hertz.

So this is the power at each trial at two hertz.

And that is basically this.

So this column here is this first row down here, OK, and then this is the Matlab implementation of

the least squares algorithm, which I introduced you to in the previous video.

Now, as I mentioned in that in the last video, if this line of code looks weird and you don't really

understand the math or why we have all these X's in here, then don't worry about that for now.

The math behind these squares and proving that this equation is the optimal one, it's not really,

really difficult, but it does require quite a bit of background about linear algebra that I don't get

into in this course.

OK, but so suffice it to say that what this gives us is a vector of two variables, and this corresponds

to the intercept and the slope for this particular design matrix mapped onto the arts variable and for

cross correlation analyses.

What we are actually interested in is this slope parameter here.

We're not so much interested in this intercept.

This just tells us where the data across the Y axis when X equals zero.

So essentially we're really just interested in this slope term here.

So that's why I say so.

I call this variable T.

I think that probably stands for temp because we don't really need this variable except here.

So I'm only taking the I'm only storing the second element of this vector, which is minus point three.

And then here I'm scaling it by the variance of the standard deviation of the data.

And I will explain the reason for that in a moment.

So let's start by running all of this code and then we make a plot.

So let's see.

This is going to be a.

A lot of frequencies on the x axis, so notice you kind of fluidly going back and forth between putting

frequencies on the y axis and over here on the x axis.

That's something that you're going to have to get a bit used to.

We often do this sort of thing in advance signal processing.

OK, and then here we see this is called the beta coefficient, and that's actually just the output

of the LI squares.

So that's the slope here is often called the beta coefficient.

Now, the thing is that this beta coefficient ends up being a mix of scales between the scale of the

dependent variable, which is reaction times that's in milliseconds, and also the scale of the data,

which is in units of microworld squared.

So it's power actually.

I think it's baseline subtracted.

But anyway, so these are very different units and the units get mixed together in this beta coefficient.

And so the issue is that, you know, the arties variance, the variability in Arties or the scale of

the arts is of course the same for all the frequencies, because this variable is the same for every

frequency.

But the data are changing in their variance and their magnitude over frequency.

You can already see that in this plot, the colors are redder over here and bluer up here.

And that's also because there's a one over F that's embedded in here.

And so the reason why I'm scaling up by the standard deviation is essentially to put these into units

that are more related to our T and normalized for the standard the difference in the standard deviation

over the different frequencies.

OK, and then what I'm doing down here, let's see how we get here, we are going to create Scatterplot.

So each of these dots essentially shows a correlation coefficient between each power at this frequency

and the reaction time over different trials.

So I'm going to interpret this function, this curve in a moment, but it's going to facilitate our

interpretation if we can actually visualize the data that are producing these numbers.

And so that's what we're going to do here.

We're going to produce some scatter plots with least squares, lines.

That's what this function does, least squares line for a couple of different handpicked frequencies.

And I handpicked frequencies eight and 20 hertz.

So that's going to correspond to this peak here and this peak down here.

So let's see.

So now we need to plot.

So we are plotting the EEG data by the reaction time.

And so what do we actually want to plot here?

Well, you might initially think so.

Let's just look at the size of this matrix.

So its frequencies by trial.

So we certainly want to plot all the trials because that's also the size of Arties.

So we want to plot one frequency.

Now, you might think that it should be something like this, F.I..

However, this is not correct because F.I. is just looping over one to two.

In fact, we want the Frex to plotts, which is the index into the Frex vector that corresponds to the

frequencies closest to eight hertz and 20 hertz.

OK, so in fact what we want here is frex two plots and then the fifth element in Frex to plot.

So let's see.

OK, so here we get these to scatterplot, so this is ETG energy on the X axis and Arty's on the Y axis

and I guess maybe it's not baseline subtracted.

These are all positive values anyway.

So this gives us some insight into how to interpret this function here.

So basically what we do is run the correlation, a regression between ETG energy and at each frequency

over each trial.

So, uh, overall, the trials that each dot here corresponds to a single trial and then we basically

fit a line here and then we take the slope of this line.

So at this frequency range, so at eight hertz.

But you can see in this whole range in general and also down here, we have a positive correlation.

So on trials where there is more energy, there's also a longer reaction time.

So the research participant took longer to press the button.

And conversely, here at twenty hertz, we see that it's negative.

This beta coefficient is negative, meaning that there's a negative relationship.

So at this higher frequency range, in the same data set, the same channel we have on trials where

there is larger energy, so more energy at this frequency, more power, then there's actually faster

reaction time.

So it's interesting to see that there's this complementary relationship between the brain behavior correlations

at low frequencies and the brain behavior, correlations at higher frequencies.

And that is the answer to this question here.

So how would you interpret these results?

All right.

So that was all very interesting.

What I want to do now is take a step further and essentially repeat this code, repeat this kind of

analysis.

But now I'm going to do it over all time frequency points.

So not just get a spectrum, but get an entire time frequency map.

So let's go through that code.

Uh, let's see.

So now we're using our familiar EEG data set.

And what I'm doing here in this code is extracting the reaction times.

You don't have to worry about this code too much.

It's basically just working with this EEG lab EEG structure.

So if you're using the EEG lab toolbox for your own research, your own data analysis, then I encourage

you to go through this code and make sure you understand it.

But because it's you know, it's useful, you can use you can adapt this kind of code for extracting

other kinds of trial, varying information.

But if you're not using EEG lab toolbox, then this is really just housekeeping.

The whole point of all of this is just to get this arties variable, which is just the same variable

that we had from the previous data set.

Now, we've already seen these data, but of course, it's always a good idea to inspect your data.

You can look for outliers or unusual variables.

If this is artes, you could also look for zero.

There shouldn't be any arties of exactly zero milliseconds.

So that would indicate that there is know something went wrong on that trial.

Anyway, I've already cleaned these data so we can trust them.

OK, so now we create our design matrix.

So the design matrix is going to have to aggressor's and that corresponds to the intercept and the arties.

So in fact, I'm actually designing or creating the design matrix here slightly differently from how

I did above.

Above, I created the design matrix and as an intercept and the EEG signal.

And now is the intercept and the reaction times as the independent variable and the dependent variable

is going to be the brain signal.

So let's see.

So we want a column of one.

So this is going to be one and then we want IEG trials by one.

So this is going to give us our first column in the design matrix, all ones.

And then we want Arties and let's see how this design matrix looks.

Hmm, we get an error, it says dimensions are being concatenated, are not consistent.

So actually the problem here is that Arties is defined as a row vector.

So all we need to do is transpose this to get a column vector.

And now we see our friendly little design matrix.

So two columns intercept and slope, which or the art of agressor from which we are going to extract

the slope.

OK, then this code here, this is just standard wavelet convolution.

I'm not going to discuss this because this is all stuff that you are now experts in your total expert

at Complex Morleigh Wavelet convolution for time frequency extraction.

The main thing that I will point out here is that we are not averaging over trials.

We are saving the data from all of the trials.

So we have in one matrix all the frequencies, 30 frequencies, six hundred and forty time points and

ninety nine trials, all in the same matrix.

And of course, you know, it makes sense that we save all of the individual trial data because we need

to compute regression analysis over the trials.

All right.

So here I'm just showing a little bit of time frequency data.

We see the time frequency power maps for three trials and just the first three trials.

It's just the way I wrote the code.

And then here's the average for all the trials.

And I think I'm just trying to illustrate here that there is some variability, quite a bit of variability

over the different individual trials.

And at the trial average level, you see some nice low frequency bursts over here.

All right.

So now for the regression model.

So this is pretty interesting about, you know, thinking about how to set up this analysis because

the least squares formula works only for two dimensional matrices.

But we have a three dimensional matrix.

So one way that you could do this is by running through a loop like I did in the previous exercise.

So the first part of this video running through a loop over different frequencies or over different

time points and then computing the regression model.

But I'm going to do a little bit of a trick, and that's by reshaping this into a time by or a, uh,

trials by, uh, time frequency points.

So this is pretty similar.

It's analogous to this super trial trick that we use in convolution.

So now we have ninety nine by nineteen thousand ninety nine trials and nineteen thousand time points

times frequencies.

And this is basically just a little trick and that allows us to fit the entire model in one line of

code, which is pretty cool.

So now we get this result of two by nineteen thousand and the two here corresponds to our two terms

that we get from the regression, the intercept and the slope.

And then of course nineteen thousand is four time points and frequencies.

Now we already know, I've already discussed that we don't really care so much about the intercept.

We are mainly interested in the slope.

So therefore we want to reshape this back to a time by frequency matrix.

I'm going to write Reshape B and now we just want the second element of the first dimension of B, that's

the slope.

And then we reshape this back to B time by frequency and that's length of Frex.

And let's see how this looks.

All right.

Very cool.

So now we get a time frequency matrix.

But this is not time, frequency power.

This is time frequency regression coefficients or brane behavior correlations.

Very nice.

So let's look at some matrices.

These are going to be the design matrix and the data matrix.

So here we have the design matrix over here on the left, it has two columns.

The first column corresponds to the intercept.

It's just a you know, there's no variability in the intercept.

Of course, maybe I'll call up the design matrix again.

So here's the design matrix.

The first column is all ones.

The second column has variance, of course, because that contains the arties.

That's the thing we are interested in.

And then here we have our data matrix.

It looks kind of funny.

It looks a bit like it's shuffled or phase shuffle or something.

In fact, this is all of the time frequency points.

So this is trials.

And then for each trial you have a time frequency map and this is like the time frequency map, linear

ised over here.

So in fact, what you're looking at is this is going up through all the frequencies for ten point one

and then it goes through all the frequencies for ten point two.

Then it goes through all the frequencies for ten point three and so on like this until you get all the

way through all the time points.

OK, so that's just showing what the data look like.

Let's see the results.

That's the most exciting part.

OK, so here we are creating.

A contour, so an image of the beater map that we reshaped, uh, look at this, so, OK, so we get

an error.

This is an area about the size of the sizes of these different things.

I think I actually wrote the code wrong.

Let's have a look at this Beda matrix.

And this looks pretty neat, but it's it's oriented the wrong way.

So that was my mistake.

Actually, this is supposed to be frequency's by time like this.

And that is exactly why you should always carefully, visually inspect all of your code as you're going

through it, particularly in the beginning.

Let's try again, huh?

This looks so much nicer, don't you think?

This gives me like a sense of existential goodness when I look at these kinds of nice results?

OK, so what are we looking at here?

This is a time frequency plot, but the colors here do not correspond to power, but instead correspond

to this regression coefficient, which is basically a scaled correlation coefficient between brain and

behavior.

So, for example, this blob here indicates that on trials where there is more low frequency, so theta

around six hertz or whatever, on trials where there is more theta power, there is also a larger reaction

time, which means a slower reaction time.

And this blue blob here curiously indicates the opposite.

So trials where there is more low frequency power here in this time window, there's a faster reaction

time.

Now, I've gone through the statistics of this this blob here.

This is reproducible in this subject, but also in lots of other data sets.

This kind of an effect is published in the literature elsewhere.

This is not really reliable.

So if you would do statistics on this map and you learn about how to do statistics later on in the course,

you will find that this is reliable.

This is not really reliable.

This is just kind of weird thing that happened in this particular data set.

OK, but anyway, the last thing that I want to point out here is that we still have because I didn't

scale the power or normalize the power at all.

We still have one over Eugh that's embedded inside here.

So that means that in theory it could be that this effect here is actually a lot more robust than it

appears to be on this map.

And that's because this map basically mixes to effects.

It mixes the actual correlation between the brain signal and the behavior, the reaction time and the

one over half change in power.

So if you are doing these kinds of correlations for real, then you have essentially two options.

One option is to normalize so you can take the the Z transform of the power over the different frequencies.

So you're normalizing out that way.

Or you can compare this to a null hypothesis distribution and apply permutation testing to transform

every pixel in this time frequency into a statistical Z value.

And then we'll also normalize out for the power differences across different frequencies.

So the main point of this video was to show you a real application of computing brain behavior correlations

over different trials within an individual subject.

I hope you found it useful and I'll see you in the next video.
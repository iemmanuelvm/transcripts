Now that, you know, the theory of computing, the kind of fluctuation analysis, I want to walk you

through how this looks like encode.

So let's start by loading in this data set.

It is called DFA, the trend and Fluctuation Analysis Data.

And because we haven't worked with this data set before, it's useful to type who's and just see what's

contained inside this variable.

So we have a time vector, a sampling rate and a variable X, which is the same number of time points

as the time vector.

So it's pretty safe to assume that this data variable X is our data.

OK.

Out of curiosity, let's see what sampling rate is.

So it's a little over kilohertz.

Ten, twenty four.

OK, so what we are going to do is compute the DfE on Narrabeen Amplitude Time series, as I mentioned

in the previous video.

So I'm implementing a method here that is called the Filter Hilbert method.

If you are not familiar with this method filter Hilbert, then don't worry about it.

It's going to be discussed in detail very soon.

I think it might even be the next video, but it's certainly coming up very soon in the course.

This method is equivalent to Morleigh Wavelet convolution in the sense that the output of the Filter

Hilbert method is a complex, valued analytic signal, narrowband complex signal from which you can

extract the magnitude of the signal in the phase of this signal.

So more on that in in a later video.

But I just want to show you what this filter FDX function is doing.

The EFG is for Frequency Gaussian because I don't believe I've introduced this function before.

So essentially you input the data, which is just a time series, a sampling rate and a peak frequency

and a full with that half maximum.

So then what this function does is creates a Gaussian in the frequency domain and then it multiplies

the data by the Gaussian.

So you see, that's really, really similar.

It's essentially the same thing as wavelet convolution because you take the data, you take the more

they wavelet, which is the Gaussian in the frequency domain, multiply the spectra together, take

the inverse Fourier transform.

That's essentially what we're doing here, except we are creating the Gaussian in the frequency domain

instead of first creating the wavelet in the time domain.

So anyway, the point is that for now you can just trust that the output of this set of functions filter

and then Hilbert is going to be very, very similar, comparable to the output of Morleigh Wavelet convolution.

And then we take the absolute value to get us our power time series, OK?

So I think we're going to start by plotting, but maybe I'll even plot these first.

Let's see plots.

I'm just too curious and impatient to wait to see what these data look like later.

So plot time back by X.

And so here we see that this is EEG activity and it's one hundred and ten seconds.

So it's a little bit under two minutes.

Now normally this is probably a little bit too short of a time series to really compute a reliable estimate

of the exponent, the DfE value.

However, this is just for illustrative educational purposes, so I think that's OK.

So now we have plot X and now I also want to plot X Filt, which shows us our power time series.

So that's what this looks like.

So this is a power time series at 10 hertz.

OK, and now what I'm going to do is create data with a theoretical and expected first exponent or DfE

value of zero point five, which is just pure white noise.

As I mentioned in the previous video here, we set up our scales.

So we're going to have 20 scales and the range and in time units is going to go from point zero one

to point to now.

This is not a value in seconds.

This is a value in fraction of the total signal length.

So you can see this is N, which is the number of time points and times point of one and end times point

two.

So that means that what these ranges actually reflect is the number of ultimately here.

It's the number of points.

And here I'm specifying this infraction.

So we are going to go from the shortest time scale being a point or so, one percent of the width of

the signal, the duration of the signal going up to 20 percent of the duration of the signal.

So one percent corresponds to around.

It's actually ends up being a little bit over a second.

OK, and then remember that these have to be we need a log spaced scales between the lower bound and

the upper bound.

So that's what I'm doing here.

I'm using the log spaced function.

And what we need to input here is the ranges and ranges one, and this ends up being range is two.

And then we need a 30.

Input here, the third input into log space is the number of scales are the number of increments between

the lower bound and the upper bound, and that is this variable here and scales.

OK, so here we have oops, I need to run this very well.

So here we have our vector, our range of scales that we are going to actually use in units of indices.

OK, and then so this is going to be the variable for the root mean square.

So our message, we're going to save all the root mean squared.

And you'll remember from the previous video that the number of arms corresponds to the number of scales

we need.

One root, mean square, average root, mean square for each of these scales.

So we have zeros.

And then I'm going to set this up as an scales by one.

OK, so let's see what this looks like.

Hmm, this is unable to use curly brackets to index into zeros.

What does that mean?

This is actually just a typo.

We have curly brackets here, but we're trying to use a function and to use a function in Matlab, you

always need to use parentheses.

All right.

So that looks much better.

OK, and then here we also do a plot, which is what I already showed here.

So here we get our white noise.

This is pure white noise.

And here we have our real data.

OK, so now we're going to go through these various steps that I introduced in the previous video.

So the first one is to integrate and means enter these signals.

So that's actually these two like subparts of step one, all in the same line of code.

So what do we need to do?

Well, we need to mean center and we need to compute the cumulative sum.

So let's mean center first.

We have random noise minus the mean of random noise.

Now, of course, the expected mean here is zero because these are, uh, whereas these are normally

distributed random numbers.

So I do already expect that the mean is going to be close to zero, but we can get it even closer to

zero.

So now we have means centered and then we compute the accumulative sum, which is also the discrete

integral.

So we are basically integrating the signal over time.

So that's for the noise.

And then we have X for DfE.

So that is the signal that we use for the DfE analysis.

And that's the same.

So cumulative sum of X Filt minus the mean of X felt.

So there you go.

Let's run these two lines, make sure that works, OK.

That looks good.

And then we're going to plot these two signals and here's what they look like.

So it's already kind of interesting.

You see, this one looks smoother, doesn't it, compared to the integrated noise now, which you expect

to see here is actually just basically tiny little fluctuations around zero.

This is pure noise.

There shouldn't really be any long term trends in this signal, but there kind of are.

And that just indicates pure sampling variability.

We could generate more white noise and you would get some other random looking random walk.

Here, the reason why this signal is smoother is because there actually are trends, there are slow

trends in this signal and they're kind of hard to visualize here in this version and the original version.

And so in the integrated signal version, you see these long time scale trends a bit more easily visible.

All right.

So now what we want to do is compute the root mean square over the different time scales.

So we have a loop that goes over all of these timescales and here inside this loop.

So let me set up this for the first loop or the first iteration in this loop here.

I'm computing the total number of Epic's, the number of segments that can possibly fit into this scale.

So this tells me NN equals ninety nine.

So that means that this time scale exists.

So the first scale is that corresponds to 1100 time points.

We can get ninety nine segments out of this time.

Ceres signal.

And so let me close this.

So then here what I'm doing is reshaping the noise vector into this number of scales and that's going

to give me these Ampex or data segments.

So now we have eleven, forty seven by ninety nine.

So you can think of this as being timed by trials, except these aren't really trials persay because

there's no stimulus event that we are time looking to, but it's still time by segments.

OK, and then here I'm trending each segment in this in this matrix and then here is where we compute

the main square.

So we take all of the time points and then we square them and then we take the average and we are careful

to compute the mean over the second dimension.

Hmm.

But wait a minute.

Let's think about this for a moment.

Here we have so this variable is time by APACS, by segments.

And we are we want to compute the root mean square.

So we the root mean square of each individual segment.

So we have to mean so we square first and then we take the average.

But is that really the right dimension?

Well, obviously it's not because I wouldn't be spending so much time talking about it, but the idea

is that if we are averaging over the second dimension, we are going to end up with an average over

segments at each time point.

Let me show you the size of this.

So this is going to give us 1100 answers out of this, but that's over each segment at each time point.

But that's actually not sensible because the data are not timelike to anything in particular.

They're kind of arbitrarily cut up into segments.

So, in fact, what we want to do is compute this average over the first dimension.

Let me show you the size of that now.

So we compute the average over the first dimension that gives us ninety nine values, ninety nine average

squared values or energy values.

And that actually makes sense because this should be done.

This root mean square computation is done for each segment separately and then we average over all the

different segments.

So it gets a bit tricky here.

So let's see.

So we take these.

So yeah.

So all the data points squared and then average over time and then take the square root and then here

we still have ninety nine values and then we average over all of them.

So the root mean square at this scale in the noise is with the noise data is eight point five eight.

So whatever that means, kind of hard to interpret this value on its own.

We want to interpret this relative to all the other values at different scales.

All right.

Very good.

So this is Arms O and now I see this is our message.

This is one and then the scale.

So that actually means that when we defined this Armus variable up here, I did this wrong.

So this should actually be two.

I'm guessing we're going to think a little bit forward.

This is going to need to be two and this is going to be the first element for noise and the second element

for the signal.

So let's redefine that and then we need to recompute the arms for the signal.

Now, we don't need to compute this variable here because this is just the number of segments and the

noise is exactly the same length as the signal.

So I'm going to just copy and paste here and then we need to be really careful about what we are changing.

So we definitely need to change this.

That was called Ex Filt and then this changes to two.

And then I think that's fine.

Right, because all the rest of these variables are OK.

So so let's run through this loop here and we don't get any errors.

That's good.

And we can expect this almshouses vector here or matrix.

So we see here is all of the root mean squared.

Terms over the different scales, so it's pretty interesting to see that they they both start off lower,

relatively low, and they both end up relatively high.

Now, the exact numbers are different between the noise and the signal, and that is not surprising.

That should not be surprising.

And the reason why it's not surprising is that these are just on completely different scales.

So the noise is just pure noise.

It's just, you know, it has an expected average of zero and expected variance of one.

And then we have the signal, which represents powers that's much higher.

So you don't even expect these to be on the same scale here.

And then unfortunately, I've now integrated this noise twice.

So let me let's start again with clearing and running all of this once.

OK, that looks better.

All right.

So now we are ready to compute the linear so fit a linear model to quantify the exponent.

So what I'm doing here is running a simple linear model, so a linear model to fit a design matrix to

the data.

So the design matrix looks like this.

We have an intercept and a slope and the slope is defined by these scales.

And then we are fitting the log of the root mean square to this linear model.

If this code looks a little bit mysterious, then don't worry.

You don't need to get all the details in this.

This is just the linear algebra implementation of a linear fit to a model.

So a general linear model.

OK, so run this.

And of course we run it twice, once for the noise and once again for the signal.

And then so essentially we get two values here.

And I'm a little surprised that these are Enan.

Something went wrong.

Uh, right.

I cleared everything and then I didn't rerun this loop here.

OK, so now we got actual results.

So you see those two numbers here?

The first number corresponds to the intercept and the second number corresponds to the slope.

All right.

So then we want to make a plot of so we're going to plot the scales by the root mean squared in log

space and log log scale, and then we're going to plot a fit line.

So the best fit line.

So let's see what this looks like.

All right, so we see let's look at the noise first so the noise looks a little bit.

Well, it looks a little bit noisy.

It would look cleaner if we had more data.

I mentioned the beginning of this video that two minutes is kind of a little bit on the short side for

a DfE analysis.

Nonetheless, we do see that the slope here, the first exponent is zero point four seven, still respectably

close to the theoretically expected value of zero point five.

Now, how about the real data?

This doesn't really look very good.

It doesn't look like a linear fit is the appropriate model.

And the DfE value is really small.

It's zero point one nine.

Now, actually, the problem here is I used the wrong variable here.

I said X filt, but in fact we want to use the variable X for DfE.

So X Filt was the amplitude time series.

But what we need to do is convert that into a mean centered and then cumulative some time series.

So in fact, this needs to be where this should be X for DfE.

All right.

And then let's rerun this code and see if we get a nicer looking plot.

All right.

This looks much better.

So the noise is the same, of course.

Now, the data are all the way up here.

The data are now more energetic than the noise.

And again, that's because the scale the thing is, we don't care about the scale.

We don't care about the intercept.

We don't care about the values themselves.

What we care about is the relationship between the arms, between the energy in the system at different

times scales.

And now we see that this first exponent is zero point nine, which is very close to the theoretical

or to the often observed empirical value that you see in the neuroscience literature.

OK, so the thing is that I just computed this for 10 hertz.

So we have no idea what this first exponent looks like for a range of different frequencies.

And that's what I want to do in the next cell down here.

So what we are going to do here is basically scan through all of these different frequencies.

So we are going to scan through the the data from one hertz to 40 hertz in 80 steps, 80 linearly spaced

steps.

So that's going to give us a spectrum of DfE, a spectrum of criticality.

And we will be able to determine whether the brain exhibits different amounts of criticality, different

intensities of criticality at different timescales.

So different frequencies.

All right.

So here we have so we're initializing this DfE matrix and that's going to be zeros.

And now we don't need to worry about noise.

We don't care about the noise here.

We're just focusing on the signal.

So the DFAS are going to be the same size as Frex and then we have the arms.

And then so here we're looping over frequencies and we compute again this X for DfE variable.

But you can see this looks really similar to the code above, except this line or this input is different.

Before this was hardcoded at 10 for 10 hertz and now it's specified to be the frequency in over this

loop.

OK, so then we need to integrate and means center so we know how to do that.

That is cume sum and then X for DfE minus the the mean of X for DFA.

All right then we loop over scale's.

This is our code we've seen before.

Ahar here is this tricky, tricky little bit of code where we're again averaging over the wrong dimension

first.

So we want to always compute the arms within each individual epik over time point.

So it's pretty important to keep in mind.

And then here we compute the DfE and keep the second element which corresponds to the slope.

Let's see.

So run this, see if we get any errors and we don't, which is a good time.

This takes, of course, a little bit longer.

So pretty fast takes a little bit longer because this line of code is probably what's what's taking

up the most amount of computation time doing the filtering and then the Hilbert transform.

All right.

And then we get this plot here of the first exponent over a range of frequencies.

This is pretty exciting.

All right.

So this is pretty neat.

You see that there's also actually kind of like a one over F in this first exponent series or spectrum.

But we do see some prominent peaks in particular.

There is a prominent peak here at around 10 hertz, which, of course, is a special frequency range.

It's called the Alpha Band.

And it's the most dominant frequency characteristic that you see in noninvasively recorded signal.

So it's interesting that that is the frequency that shows a lot of.

It shows a very strong first explosion.

Now, to be honest, I'm not so sure that I really trust all of these values down here.

And that's because One Herts is a pretty slow oscillation and we don't have a lot of time.

You know, the signal isn't very long.

So I don't actually trust all of these values down here.

OK, but we do see a nice peak at 10 hertz and it looks like there's another peak at, you know, 18

hertz.

And let's see, this is around 18, 19 hertz.

So in the beta band.

And then maybe there's some other peaks here.

It's I don't want to over interpret this.

It's just a tiny segment of data.

But I wanted to give you a taste of what the DfE, this Hirst's exponent, this measure of criticality

or scalfari dynamics looks like over the spectrum.
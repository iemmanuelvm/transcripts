 Having a good mechanistic understanding of how to perform convolution how to implement convolution leads to some natural coding tips or ways of improving the efficiency, decreasing the computation time of convolution. And that's basically done by leveraging our knowledge of convolution to avoid redundant computations. So let me start by showing you what some pseudocode might look like for doing convolution. So let's say you have a data set with a number of channels and a number of trials and you want to do convolution for a number of frequencies. So you might think of setting up a Triple four loop that would look something like this, where you loop over channels, you loop over frequencies, you loop over trials, and then inside this triple four loop, you do your convolution. So the five steps that I explained a few videos ago about wavelet convolution. So computing the ends for the F.T. taking the FFE, multiplying the spectra, taking the inverse for you, transform and then cutting off the wings. So in theory, you could do that and that's fine. However, we can improve convolution, for example, by getting rid of this loop over trials. So how do we do that? How do we get rid of this loop over trials? Well, we do that by concatenating all the trials together to create one really long super trial. So here you see an example. Imagine these are four separate trials. So these are for individual trials. And then what we do is concatenate all of the trials. So it creates one long time series. So you can see that the end of the first trial is here and then the beginning of the next trial is here. And then that just cuts right down there. And then we have the end of the second trial that's here and that goes immediately into the beginning of the third trial and so on. So now it's like we just have one really, really long time series. And then you run the convolution with this one trial and then you can extract whatever you want to extract the features that you want to extract. The Power Time series of phase angle time series, the band pass filter signal. And then you can split this back up into the individual trials and then, you know, continue with whatever analyses you are planning on doing, for example, such as computing a trial average. Now, at this point, you might be concerned that we are introducing edges here and you're going to get edge effects. That is totally true. That's a great observation. We are going to get some edge effects here at the boundaries between the trials. However, you are going to get edge effects no matter what. Even if you don't concatenate the trials, you are still going to get an edge of fact. You still have an edge here. Edge effects are inevitable in filtering. They are unavoidable. I'm going to talk more about edge effects in a later video and how to deal with them, how to get around them. But the short answer of the story is that you just have to accept that there will always be edge effects in your filtered signal. And so essentially the the best thing to do about edge effects is to make sure you cut sufficiently long epics, sufficiently wide epics, so that the edge effects any possible artifacts, any possible contamination from having edges subsides before the time periods that you are interested in analyzing. So again, I'll talk more about the details with specific recommendations in a later video. But the point is, yes, you get edge effects, but you're going to have edge effects even if you don't concatenate all these trials. OK, so that allows us to get rid of one loop here, which is pretty good. So they will already speed things up quite a bit. Now, let's think about this a little bit more. We have to do the convolutions or we have to do the 50s. We have to compute the fifty of the data and we have to compute the efficacy of the wavelet. So let's try it and think about what's going on here. And if we are redundantly computing any Effie's. So consider that for these different frequencies. These are the frequencies that define the wavelets. The data, the EEG signal is not changing inside this loop. These are this is the loop over wavelet frequencies. The EEG data don't change. We are extracting different features from the data corresponding to different frequencies. But the data themselves don't change. So the Fourier transform are the data certainly doesn't change. So if you are computing the Fourier transform of the signal of the EEG data inside this loop, then that means that you are computing the Fourier transform num frex minus one times redundantly. So let's say, you know, if you have a hundred frequencies, you only need to take the FFE of the. Once, but you're taking it redundantly 100 times, so therefore we can modify convolution, so it actually works like this. So we are taking the Fourier transform of the data only once inside this loop here and then in this loop here, we are just taking the Fourier transform of the wavelets, doing the spectrum multiplication, the inverse FFE and so on. So that will really speed things up, particularly if you have a lot of data and you are computing the 50 over a really, really long super trial because you have lots of trials, maybe also because the trials are really long. By the way, this also shows another advantage of implementing convolution yourself as opposed to just using a built in matlab function like conv, which will compute the convolution so you can actually implement convolution faster and more efficiently than matlab can by leveraging what you know about the mechanisms of convolution. So these are the main two tips that I wanted to discuss in this video. Depending on exactly what kind of data set you have, you might also be able to make this convolution go even faster. For example, you might not need this loop over channels because you can take advantage of the Matrix input into the FFT function so you can compute the 50 and all of your channels simultaneously without having to loop through channels. Now, whether that's a good idea or even possible depends on how much data you have, but it's something to think about. It's something I will also discuss in the code a little bit more. Furthermore, I hope you can also see that even if you are looping through channels, you don't need to create, the more they wavelets inside this loop. And that's because this loop is reoccurring, you know, however, for however many channels you have. So you only need to create the wavelet and take its FFT once not and channels times. So these are even more things to think about, things to keep in mind, to leverage your understanding of convolution and coding, to improve the efficiency and decrease computation time of your time frequency analysis. That is a real advantage because having the difference between, you know, doing a time frequency analysis in three hours versus 15 minutes, that can make a really big difference for your analysis. Now, so far, I've mainly been focusing on using the power data from time frequency analysis. In the next video, the next several videos, I'm going to start talking about what to do with the phase values, how to interpret them, and how to quantify the consistency of phase angle time series data over trials.
 Now that you've seen convolution implemented in Matlab, we are going to take one small step in terms of code, but one giant leap in terms of science. OK, that sounded really stupid. Well, anyway, what we're going to do is essentially follow the same procedure as in the previous video, just replacing the artificial, weird looking little blocky signal with some real LSP data and again, using a Gaussian as a convolution kernel. All right. So we start by loading in our familiar V1 laminar data set. Let's see. And then the signal is going to be the ERP from Channel seven. And here we create a Gaussian. So you can see him using this formula that allows me to specify the full with that half maximum directly in the exponential of the Gaussian. And then this is an amplitude normalization factor, which I've also discussed in one or two videos ago, or maybe several anyway, as some other video. The reason why it's important in this case to use a Gaussian formula that allows us to directly specify the full with the maximum, is that later on in the video we are going to be basically experimenting with different parameters here and seeing what effects that has on the data. OK, so let's already start by plotting this Gaussian. I'm quite curious so I can plot G Time by Gauss and see it is a super narrow Gaussian. It's really, really narrow. It's almost like a little spike. I'm sure if we zoom in we would see more the Gaussian shape. Yeah. So it still is pretty narrow. It has a full with enough maximum of 0.01 seconds, which is ten milliseconds. So remember that the effect of a convulsing with a Gaussian is to smooth a signal. It's a smoothing kernel and with a full with enough maximum of 10 milliseconds, it's actually applying very little smoothing. You can see this is time in seconds here. So it's not really an extreme smoothing, Colonel. All right. So here we compute the ends of convolution so we get the length of the data, the length of the kernel and the length of the result of convolution and half the length of the wavelet. And here we compute the 50s, OK, and make sure to properly zero bed. So here we want this is data. So this is the F.T. of the signal comma. And that's important. And here is the left of the kernel which I call Gauss and also and conv. And then we can make sure that they are both the same length which is three thousand fifty two. That seems like a sensible number. All right. And then here is step three where we multiply the spectra. And actually it looks like we are combining steps three and four. So we are taking immediately the inverse FFE of the multiplication of these spectra. So that part's fine in general. I'd recommend condensing code a little bit. However, here we are. What are we doing here? The inverse F fifty. So actually this line of code is exactly the same as this line of code. So if you like, you could actually just delete this altogether or if you like, you could delete this and then replace the inside of the FFE function here with Confreres X. Now, as I mentioned, normally I recommend just combining step three and four into one line of code. But this can be interesting if you want to like visualize these spectra separately. So for example, we can plot the and now I don't have a frequency's vector, so I'm going to do this little shortcut that I often do. So zero s right. And now what is the end of the FFE here? Well, the end of the FFT. So the number of points between zero and the sampling rate is not the length of the signal, it's the length of the effort here. So that means we need ensconce points or steps between zero and the sampling rate. So let's see then I'm going to plot the amplitude spectrum of the data. And this is an amplitude spectrum that we have seen multiple times before in this course. So you see there's this nice, interesting peak at Gamma in addition to this kind of one over F shape here. OK, so that is that one. And then it's also interesting to look at the kernel. And actually we want to see the current so you can see the kernel is just this negative decay function. And it's also interesting to see. So this has a maximum value at one up here and then it decays, the full with that half maximum is. So this is point five energy. So 50 percent gain looks like somewhere around 50 hertz or so. So we're getting some gentle attenuation and even all the way up to like 110, 120 hertz, we're still having energy from the signal that's going to get through the filter. So what I'd like to do now, just out of curiosity, is plot the data spectrum and the data spectrum times. Uh, let's see then. I want abs of confreres X like this. OK, so now this is pretty interesting. I'm going to set the X limit to go from zero to maybe one hundred and forty hertz. Let's see how that looks. OK, so it's pretty interesting. You see in blue the blue line, I mean, make this thicker just to make sure it's visible. So the blue line here corresponds to the original signal. That's the real signal. And this orange reddish line is going to be the signal after we run convolution. So this is the spectrum of the signal and then the finishing off convolution. We basically just take the inverse Fourier transform of this orange power spectrum here so you can see what the effect of involving with this Gaussian is. All of the low frequencies are almost perfectly preserved. You know, tiny bit of attenuation here. And then we only start getting some really, you know, significant attenuation up around like 50, 60 hertz or so. And then you're getting basically almost complete attenuation above 100 hertz. I guess if you would zoom in here, you would see that it's not total obliteration, but we do get some some pretty severe attenuation here. OK, but I also just want to highlight a more general principle, which is that in data analysis, definitely when you are learning about data analysis, but also when you are just writing code to do analysis or exploring new data sets, it's really great to do this kind of exploration. Just lots and lots of plotting and curiosity. OK, I don't even remember where we were, so we were OK. So we ran this and I guess I ran this line and I think I also ran step five. Yeah. So you can see now the convolution result is fifteen, twenty seven points long, which is the length of the original signal. All right. And then we do some plotting. So here you go. You see in blue is the original ERP and in red is the Gaussian involved ERP. Now it's pretty interesting to look at the effect of convolution with a Gaussian here, for example, where we still preserve some of these faster fluctuations, but there are even faster fluctuations that are attenuated, that are removed. And on the other hand, it's interesting to see that a lot of this phase like Gamma is preserved. Now, it's not so surprising based on what I drew here. You see there's some attenuation, but we still get this gamma response. So here you see the attenuation and we still get the gamma response. So questions, what is the effect of changing the parameter? What value leaves the ERP mostly unchanged. So I'm going to go back and let's change this to how about zero point zero five like this? And to make sure that we can compare this fully, I'm going to put this in figure seven so we get the results in a different figure. So essentially what I'm doing is making the full with the maximum much thinner. So this Gaussian is going to be even thinner. So now we're preserving the features of the ERP even more. Oh, I guess I didn't. Let's see. There is. Some setting the X-axis limit that I guess I didn't run on this figure, OK? Now, it should be easier to compare. OK, so then let's try something else. I'm going to change this to figure eight, and now I want to make this larger. Let's set this to be point one. So now the full with the maximum is zero point one seconds, which is one hundred milliseconds. And while that had quite an effect, all of this Gammer business is now completely gone. We have eradicated this. I think this is actually too much smoothing. And, you know, now it's going to be interesting to make this plot again. Let's see, where was this? This one? OK, so now we can see let me go back to set this x axis limit. OK, so again, this is like figure one. This was with the first galaxy and this was with the Gaussian with a full with half maximum of 10 milliseconds. And then here was with the Gaussian at one hundred milliseconds. So the third exponential decay is much steeper as the Gaussian gets wider in the time domain. So now you see that we have basically obliterated too much. We've gotten rid of frequencies even as low as what is this around, you know, to two hertz or so. We're already starting to get some severe attenuation. And so that's why this plot looks kind of cartoonishly ridiculous. We are definitely filtering out. You know, we're still preserving some information. You see that there's still a big response here to the first stimulus on site and then a big response here. But I would say this is much too strong attenuation. OK, what value makes the ERP unrecognizable? Well, I think we've done a pretty decent job. I guess you could set the smoothing kernel to be even higher or that is the full with enough maximum to be even higher. So let's see. These are you know, these are just some some thought questions. There's no specific answers for this. So here's a somewhat philosophical question. What does the answer to these questions tell you about the temporal precision of the ERP in V1? So what does this question mean? Essentially, what I would like you to do is think about how much information we are losing by applying Gaussian smoothing kernels of different full with half maximums and what effect that has on the loss of information in the signal. And so essentially, what I would like you to start thinking about is the fact that as you smooth more and more, the time constant of smoothing is telling you something about the temporal precision of the information in this signal. And so I would say that that's probably somewhere around here, somewhere around 40 to 60 hertz. There seems to be a lot of interesting dynamics happening, not exclusively in that frequency range, but definitely in that frequency range. So as we smooth more and more extremely, then we're kind of getting rid of too much information, which is bad. We're losing information about the signal by getting rid of all of these signal components. OK, and then down here, there's a little bit more code here. So the mechanism of convolution, I think all this code works out of the jar and. Yeah, OK, so this is essentially just drawing what I already drew here. I guess I probably forgot that I had this code in here. So anything else? I'm forgetting that already the next video. OK, great. I hope you enjoyed this video. I hope you found it illuminating. I look forward to continue working with you in Matlab in the next video. I think we are going to discuss Complex Morleigh Wavelets. See you soon.
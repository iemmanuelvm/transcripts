In this video, I'm going to discuss edge effects and how to deal with them by having buffer zones and

thinking about buffer zones when creating your data.

So let me start by reminding you what edge effects are and why they can introduce artifacts into your

time frequency analysis.

So here you see a lot of time, frequency, power, and it doesn't matter what's going on in the middle.

What I want you to focus your attention on is these red demons here on the side all the way on the left

and all the way on the right.

These are EDG effects.

They're artifacts and they're contaminating their overriding the other signals, the other features

that are actually happening in the EEG data.

So where do these edge effects come from?

Well, they come from having taking a time, frequency, representation or decomposition of an edge

of a sharp edge that looks something like this.

Now, you learned in the section on the year transform that when you have a sharp non stationary in

the time domain signal you need are the Fourier transform needs a lot of energy at a lot of frequencies

to represent that really sharp edge.

And of course, ultimately Wavelet convolution is basically just for transforms.

So here what you see is the time domain signal here.

And this is time, frequency, power and time frequency phase of this edge.

So it's pretty remarkable that there's nothing happening in the signal except for this one little blip.

And look at this ginormous time frequency response that it generates.

So you can imagine if something like this is in your data, then you're going to get this.

Now, this is kind of as expected.

This isn't really wrong per say.

This is the correct answer.

However, these edge effects can be so large that they will overwhelm whatever is the time, frequency

dynamics that are happening in the signal.

Obviously, there's nothing happening in this signal.

But you can imagine that if this kind of an edge is superimposed on top of your EEG signal that this

is going to be really difficult.

This is going to add an artifact that's going to make it difficult to interpret what's actually happening

endogenously in the signal that was coming from the brain.

OK, so what can you do about edge effects?

Unfortunately, there isn't really a whole lot that you can do.

They are just present.

They are just a natural feature of the way the Fourier transform works by decomposing the signal into

sine waves.

So therefore, the solution is to let me go back to this site.

The solution is to accept that edge effects will be present and you just make sure that those edge effects

are not going to contaminate the time windows that you are interested in.

So and that is related to cutting your APOC, so cutting your continuous data into Epic's.

So of course when you record your EEG data, it's being recorded continuously and you get this two dimensional

data set.

Well, assuming you have multiple channels, then you get a two dimensional data set of continuous time

by trials and continuous time.

You know, this might be an hour of recording or half an hour of recording.

So this can be a really long time series.

And then the idea is that one of the initial steps of preprocessing your data are to identify the timing

of different events that happened in the experiment or if it's spontaneous data, resting state data,

you might still cut up the data into, let's say, two seven, two second segments, and then you cut

Epic's around each of these events and these form your trials.

So this would be the data frame from trial one.

You can see it's time by trials and then it's time, time locked.

Do you know maybe this is when a picture appeared on the computer screen.

So trial one trial to up to trial.

And now here's the thing.

There are edges all over the place in these data.

There are edges here at the end of the trial.

There are edges here in the beginning of the trial.

And if you create these super trials by concatenating all the individual trials together into one really

long trial, remember, that's one of the tricks I showed.

Speed up convolution then they're are going to be edges in the data between, you know, this time point

and this time points at the end of the lab, at the end of the data boundary at one trial and the beginning

of the data boundary and the next trial.

But even without these super trials, without trial concatenation, you're still going to get edges

at the boundaries, just like what you see here.

So that means that there will be edge effects, contaminant potentially contaminating the data.

Now, whether you get an edge effect that's really, really large or relatively small depends on the

size of the edge relative to the other dynamics in the signal.

So if the edge is really tiny and the you know, the features in the signal are relatively large, the

edge effect will be tiny and probably unnoticeable.

But it can also happen that you get really large effects.

It's difficult to know apriori whether you're going to have large or small edge effects.

So that leads to two solutions, two possible ways of dealing with edge effects.

And again, the idea is that you cannot eliminate edge effects.

What you can do instead is come up with one of two strategies to make sure that the edge effects are

not going to contaminate the part of the signal that you want to interpret.

So the first solution is what I call the buffer zone approach.

So essentially what you want to do is make sure that you cut your Epic's sufficiently long.

You want your Epic's, your time, Epic's, your trials to be cut sufficiently wide, such that the

edge effects will totally subside by the time you get to the time window that you are actually interested

in.

So here you see we have data from minus a thousand to plus 1500.

But I'm actually not interested in what's going on in this time window and in this time window.

In fact, this time window might even overlap with the previous trial and this time window might even

overlap with the following trial.

But that's totally fine.

The only reason why the specs are cut this long is so that the edge effects can fully subside before

we get to the time period that I'm actually interested in, which is indicated by this gray box here.

So how much time do you need for the buffer zone?

Well, it's hard to compute exactly, because the size of the edge effect depends on the data, not

necessarily on the the time window.

That said, a recommendation that I typically give is to set the buffer zone to be three cycles at the

lowest frequency that you are extracting out of the data.

So, for example, if the lowest frequency that you are extracting is five hertz, then three well,

one cycle at five hertz is two hundred milliseconds.

So three cycles at five hertz is six hundred milliseconds.

So therefore if you are Epic's are six hundred milliseconds long.

I say the buffer zone six hundred milliseconds long and the beginning six hundred milliseconds long.

At the end I would say that is more than enough.

You can sleep comfortably without ever worrying about edge effects contaminating your signal.

And that's because these edge effects will generally subside in less than three cycles.

Now three is not a magic number.

That's just my recommendation.

It's just a rubric.

In fact, when you look in real data, when you see edge effects, they tend to decay in one cycle or

less.

So three cycles is even overdoing it a bit.

But as I mentioned, if you have three cycles, you will never need to worry about edge effects.

OK, so this is my recommended procedure.

I call it the buffer zone approach.

The other possible way to deal with edge effects is what I call the clipping approach.

And here you don't have to worry so much about cutting large apex.

Or you could say this would be a solution for if you are unable to cut really large epics from the data.

And here the idea is that you estimate what parts of the data could be contaminated by edge effects

and then you basically just remove those pixels from the time frequency plot.

In practice, that can be done by setting the values to be Enan.

So not a number, but that's just a detail of of optional implementation.

The idea is that you estimate what parts of the data might be contaminated by effects and you remove

them so that they are definitely not interpreted.

So in here as well.

You could use this from the field trip websites, from a field trip, tutorial and fieldtrip.

The field trip matlab toolbox will implement this.

And I don't know offhand how exactly they compute this clipping effect, but it might be one or two

cycles at each frequency.

You can see these lowest frequencies are basically with this size EPIK Field Trip has determined that

we can't even really reliably estimate activity at this low frequency, whatever this is, maybe this

one or two hertz.
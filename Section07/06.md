 In the previous video, you learned about the convolutions theorem and how to implement convolution as spectral multiplication. So that was a little bit theoretical. And what we were going to do in this video is implement this idea in Matlab code. So that's what we're going to do here, implement the convolution theorem via spectral multiplication. And what we're going to do is basically start off by using the same example of the simple signal and kernel, a little Gaussian kernel that we used a few videos ago. So let's see. So this is actually a lot of this code is just copied and pasted from a previous video and so on. So let's just generate that figure again. So you will remember this figure. And here you can see we are using the Matlab con function and notice that the first input is the signal, the second input is the kernel and the third input is this optional parameter. Same which I have already discussed before. All right. So now let's do convolution via spectral multiplication. So let's see here we define. So these are all the steps we have to go through. So step one is to define all of the ends of convolution. And the most important end is this one here, the end of convolution. And you'll see that that is NP data plus and Col minus one. So in the video I refer to this formula as N plus M minus one. So these are just different variable names. So PN is the length of the signal. M is the length of the kernel and then we get N conv is the length of the result of convolution. And here I have half K for half the length of the kernel. So you can see I'm dividing the kernel length by two and then just, you know, if this is an odd length and then floor will basically round down round towards zero. And the reason why we need this variable is because the length of the result of convolution is too long is longer than the original signal. And so the final step of convolution will be to clip the wings. And this is basically how many points we need to remove. OK, so then we get to step two, which is to take the efforts of our two signals so the data and the kernel. So here we have the 50 of the signal, the left of the kernel, and here we have an important note. Make sure to properly zero pad. So what should be the length of the Fourier transform of these two time series? You guessed it. It is the length of the result of convolution. So it has to be N plus and minus one, which is this variable and conf. And obviously it's the same thing here. And notice actually I think I will even run this without specifying the end of the fifty. Now the thing is in step 3s, I already see we're going to need to change a bit of code here, but in step three, we have to multiply these spectra together. So now this the data spectrum is one hundred and seventy two points and the kernel spectrum is 20 points. So obviously we can even element wise, multiply them. That's not even a sensible operation. So that is another reason why we have to zero pad in order to get them to be the same length. Now they are both 191 elements long. OK, so multiply these spectra. This is supposed to be data X times Kurn X. So there we go. So now we get one Fourier spectrum. That is the mapping of these two. So the element y's or frequency y's multiplication of the spectrum of the signal by the spectrum of the kernel. All right. And then we take the inverse Fourier transform to get back into the time domain. And here I call this confreres for the result of convolution. And then here you can see I'm cutting off the wings of convolution. So and actually I can show you here. So this is now 191 time points long. Now, this is not really wrong, per say, but it's difficult to compare directly against the signal, which is one hundred and seventy two points on. So therefore we trim the wings and we get back to one hundred and seventy two point song, OK? And so now what we are going to do is basically just plot this. So we plot the result of convolution using our method here and we see that it matches perfectly with the result of the matlab con function. All right. So now we have a question at the bottom here. Is the order of multiplication in step three important? So that is here. So the question is asking, does it matter? If we say data times Kurn X or current ex times data, so is there a difference between these two lines? Now, of course, the answer is no. This is just Element Y's multiplication. Each step in his element Y's multiplication turns out to be just a very simple arithmetic multiplication. And so we know that two times three is the same thing as three times two. So obviously data times, Colonel, is the same thing as Colonel Times data. So the order does not matter? Not at all. So but then we have another part to this question. Go back to the previous cell and swap the order in the second function. And is the is that order important? Now, here we get another question. Why might that be? So I'm assuming that the answer is going to be yes. So let's see. So here I think I will let's just actually run this like this. So all of this stuff is the same. The signal is the same, the kernel is the same. I'm just swapping the orders here and maybe I'll set this to be let's see, we already have black and blue. How about M for magenta? And maybe I'll make it magenta squares with lines, make sure it's nice and differentiable. Hmm. OK, that's kind of funny. So all of a sudden the result of convolution looks really, really different. And it's also super short. It's very short and actually it looks like it's about the same length as the kernel. And that is no surprise. The way that the con function works with the same optional input here is that matlab the? Com function will cut the wings off of convolution, assuming that the first input is the signal and the second input is actually the kernel. So in some sense, what we did here is the same as what we did before. However, we cut off too many points. Basically we just trimmed it too much. And in fact, you can see that if you would take this magenta line and translate it over here. So you just slide it over here. You can see it's actually just this center part of the result of convolution. So that would fit exactly into this part here. So what we've done is go to the middle of the result of convolution and basically trim the wings that are that are way too big. So we end up with a result of convolution that's the same size or the same length, the same number of points as the kernel and not as the signal. OK, and so that's just how they come. Function works and it's something to be aware of if you are using the comm function. And of course, if you're doing this manually, you don't have to worry about it. OK, so that was just a bit of an aside, partly to tell you something about how they can function works and also to think about convolution a little bit more. But the main point of this video was essentially this cell here showing you how to implement these five steps of convolution in Matlab code. And I hope you see I'm sure you agree that it's pretty simple. It is nothing super magical. The main thing you have to keep in mind is that the result of convolution has to be M plus and minus one point, Zilong.
Now we are going to explore the effects of separating the total signal into the nonferrous locked in

phase locked components on the time frequency, power spectra, intertribal phase clustering and the

ERP.

We're going to do this in the EEG data set.

And in particular, I picked Channel seven.

This is like sort of towards the back of the head, a bit on the left side after this video, of course,

I encourage you to explore the resulting plots for different channels.

It's pretty interesting to see how the phase lock versus non phase log parts differ for different channels

or different topographical areas.

OK, so let's see.

So what we're doing here is just coming up with this logical array or boolean vector that tells us which

channel index corresponds to the text labeled seven.

This comment here is just a reminder of what I explained in the previous video in the slides.

So and then we want to keep both we want to keep both the phase locked part of the signal and we want

the total part of the signal.

So therefore, it's important not to just overwrite the data structure.

So the instructions are actually just to do this for one channel.

But I'm going to run this in a loop over all the channels, just so you can see.

Also show your shortcut just so you can see how this works out for, um, for computing the non phase

locked part of the signal over all the channels.

So here we are computing the ERP just from this channel.

So that is you mean of Egert data and then we have Channe I and then of course we are averaging over

the third dimension, which is the trial dimension.

So now the thing is.

So let's set this for Channel one.

And so this channel IRP, this variable is a vector, it's a 640 element vector.

However, what we want to do is subtract that ERP from each trial individually.

Now we could do this over a loop and if you implemented this over a loop, then that's totally fine.

Nothing wrong with that.

However, we can also implement this directly without having to have a loop over channel over trials.

And that's done by using this B.S. fun function, which stands for binary expansion and then function.

So the function that we want to do is minus.

And now notice the size here.

So the size of this second input here is 640 by ninety nine.

So time by trials and then this channel ERP is six hundred and forty.

So when we run this function, Matlab is going to analyze this matrix and this vector and matlab will

guess.

Matlab will come to the conclusion that the way to get this subtraction to work validly is to repeat

this vector ninety nine times and that's going to expand or replicate this vector for every trial identically.

So let's run this code.

So now we have used this phone function to avoid having to have a second loop over trials and it gets

even better than that because the best X1 function is actually pretty smart.

It's going to try to do its best job to guess what you want.

So I'm going to implement basically identical the exact same thing that this loop is doing, but without

any for loops at all.

So I'm going to say minus that data and then mean that data comma three.

So again, we are averaging through here.

We're creating the ERP, we're averaging over trials.

But now this matrix here is of size six hundred sixty four by six forty.

So channels by time.

And of course all the data are channels by time, by trials.

So and then fun is going to figure out how to replicate this two dimensional matrix so that the subtraction

is valid with this three dimensional matrix.

Okay.

And then here is another note, which I have already also mentioned in the previous video.

And basically that's that if you have multiple conditions in your experiment, you need to run this

line separately for each condition.

So just subtracting the ERP for each single trial, according to the experiment condition that that

trial is taken from.

All right.

So let us start with some visual inspection.

So we're going to plot the ERP from this channel, from the looks like there's a mistake from the the

total signal and the non-physical part of the signal.

So let's see what is the error in here?

I see it here, you can tell already here, so I was, in fact looking for a multiplication sign here,

which there isn't, but there is actually a function called Times.

Times is a function we can see edit times, and that is its own function for multiplication.

So so, for example, you know, you could write times three, comma two gives us six.

This is actually supposed to be IEG Times.

Tricky.

Tricky.

OK, so let's see.

So we see the ERP for the total signal in blue and the ERP for the non phasuk part of the signal and

red, which is a flat line exactly at zero.

Now maybe you saw this and you were initially concerned that you made a mistake somewhere.

But we can see this question here.

Are you surprised at the red line?

Is it a feature or a bug?

So the question is, you know, why is this red line totally flat?

And the answer is, well, it's kind of trivial because this is the ERP.

We literally subtracted the ERP from each single trial.

So when you subtract the ERP from the single trials, then you average the single trials together.

The ERP is going to be flat.

It's going to be all zero because we subtracted it from itself.

OK, and so in fact, plotting the ERP of the non-physical part of the signal is actually a good sanity

check.

It's a good code check that you've actually done the code in the right way, that you've actually done

the right thing.

And I just want to point out one thing about computer rounding errors and making sure to interpret computer

rounding errors correctly.

So I'm going to do is plot the non phase, lock ERP from Channel 10, doesn't really matter which channel

we're doing and then the averaging over the third dimension.

Now, when you first look at this, you might think, oh, there is something, you know, we see a

big ERP.

It looks like a lot of noise, but there's something here.

But then you have to look at the Y axis scale.

This is ten to the minus six and the actual ERP is ten to the one.

So this line this line here is basically a flat line.

This is really, you know, zeros plus some rounding errors and averaging errors and so forth.

So just be mindful that often in computers and I'm sure I've said this elsewhere in the course, in

computers, when you expect something to be absolutely zero, but you're doing a bunch of mathematical

operations, it might be close to zero, but not exactly zero.

These are rounding errors.

All right.

Now for the time frequency analysis.

So apply wavelet convolution to both signal components.

And this is referring to the total signal and the non-physical part of the signal extract power.

And it's OK, we can pick the parameters.

OK, reasonable frequency range is two to 40 hertz.

So why don't we extract how about forty three frequencies between one point nine and forty point one

hertz?

Because if these are reasonable then I think going slightly outside those boundaries is equally reasonable.

OK, so let's see.

This part looks good, this part looks good, this part looks fine.

And here we specify the length of the wavelet the and data and income is and plus and minus one.

All right.

So far it all looks good here.

We're doing a baseline normalization, so we are picking a window of minus five hundred to minus two

hundred.

And you know, from a few videos ago about baseline normalization, that this is a reasonable time window.

This is a good time window to pick here.

We take the fifty of the data and let's see, we went all time points in all trials and we want to reshape

this into a vector.

So it's a super trial.

And this is for the the total part of the signal and the non phase locked part of the signal.

OK, so this also looks good.

Now we initialize the time frequency matrix.

So we have zeros and we have frequencies by time.

So that's as expected.

And then we have this two here and two in the beginning.

So in fact, this is a four dimensional matrix.

So you can see that these time frequency matrices can start getting really big.

For example, we don't even have all of the channels in here.

So that could add, you know, if we were doing this for multiple channels, this would be in B channel.

And let's say we had like five experiment conditions.

So it might end up being something like this.

So it's pretty feasible in your experiment that you might end up with a six dimensional time frequency

matrix.

So let me get rid of these extra dimensions before someone starts getting nervous.

It's probably going to be me.

OK, going back to four dimensions, that seems somehow relatively four dimensional matrices in.

Pretty manageable, OK, anyway, so the first dimension here is for the total and non phase locked

and the last dimension here is for power versus ETPs.

All right.

So looks like we are looping over.

Frequency's is a pretty big for loop here.

And what we are doing is creating the wavelet and the wavelet is the same for both the total and the

non phase locked.

And then we extract the.

So we do convolution to extract the analytic signal baseline normalization.

And then here we get ITC and then this all repeats for the nonphysical part of the signal.

So let me just have a quick look through this.

Make sure there's no error.

So specify so hard coding that the forward that half maximum is three hundred milliseconds for all frequencies.

Again, normally I would recommend changing this a bit per frequency, but I think it's OK here.

So we have the complex more.

They wavelet is a complex sine wave, so it's E to the I to pi f t and then times element wise element

multiplication by a Gaussian and it's minus four log two times time squared and then divide it by the

four with that half maximum.

OK, so that looks legit.

Notice we are not doing any amplitude normalization of the wavelet in the frequency domain.

Do we need that.

Is that missing here.

Is that a mistake that is missing from this code?

Actually, the answer is that it doesn't matter here.

And the reason why it doesn't matter is because there are two features that we are extracting out of

these data power and phase four phase.

This stuff doesn't matter because the phase values are independent of the amplitude values and for power,

it actually does matter.

However, we are normalizing.

We're dividing by the baseline here.

So when you're normalizing power, you don't need to worry about normalizing the wavelet.

You're already you know, this normalization will take care of any other normalizations.

All right.

So let's see.

We do, uh, the wavelet spectrum times, the data spectrum and, uh, then we clip the wings and reshape

to time by trials.

So this part looks legit.

Let's see.

I think I will start running some of this stuff.

So then, OK, so that's all fine.

Here we compute the baseline power.

So this is the analytic signal in this baseline time window from these time points and then all the

trials and then we take the abs and we square and then we have to average twice.

And that makes sense because first we have to average over this time window and then we want to average

over all of the trials.

And then here's where we compute power.

So you can see the last dimension is one and that is ten times log ten of.

So this is all this power average over trials from all the time points for not separating or downsampling

the results of wavelet convolution here in general.

That's something I recommend only when you're doing multichannel wavelet convolution.

If it's only one channel, it doesn't really matter so much.

OK, and then we divide by the baseline power.

Actually, it's good to confirm this thing should be one.

No, this is exactly one number, so.

That's correct.

OK, and then here we have the ETPs so it's E to the eye angles and then we average over trials.

And so this gives us the the average vector and then we take the magnitude of that average vector.

All right.

Very nice.

And if we are lucky, I can just run all this and notice this is all the same code.

The only thing that's different is that this variable is data X NPL for non phasuk locked and up here

it's data X total.

And then here we are putting the results into the second element of the first dimension, whereas here

they were going into the first element.

All right.

So let's run all of this loop here.

Superfast runs really fast now for plotting.

And I think if we are also lucky, I'm just going to try running all this code and let's see what it

looks like.

OK, so here we get the total power phase like power, total ETPs and non-ferrous locked ETPs.

Question, are you surprised at the nonferrous locked ETPs result here?

So it's basically like all zeros plus some rounding errors.

Now, you shouldn't be surprised that it is the phase locked part of the signal and we subtracted the

phase lock part of the signal in the time domain.

And now this is the time frequency representation of the phase like part of the signal which we've removed

from the data.

So in fact, you shouldn't be surprised at all.

There's a little bit of this cloud.

You know, this looks like like the the large scale structure of the universe.

You know, it's just kind of this this cosmic noise here.

And this is essentially just the residuals of the computer rounding errors in tiny arithmetic errors

that we saw here when I showed this.

So I showed you that the nonferrous locked ERP still has some non-zero values.

They're tiny, but they are still present.

And that you see coming through here at this kind of fuzz, this noise.

OK, and then we have another question.

What features of the data are the same versus different between the power plots?

So here again, this is actually a bit similar to the example that I showed in the slides that we have

this early bump here this early let's call this theta alpha complex in the total signal that seems to

be almost entirely gone in the non phase locked part of the signal.

On the other hand, all of these other smaller features seem to be present.

And notice here that this is not just about the timing.

It's not just about whatever is early in the trial is a phase locked and whatever is late in the trial

is non phase locked.

We still have all of this this blue stuff here, a little bit of this orange stuff here.

You know, this stuff up here, this is all still present in the non phase, locked part of the signal,

and it's also present in the total signal.

So the difference between total and non phase locked, generally, that difference will occur in the

early phases of the trial.

But it's not necessarily the case that whatever happens early is going to be phase locked and whatever

happens later is going to be non phase locked.

OK, now for phase locked power.

So what we are going to do here is basically just plot the difference between these two.

So and then there's a comment here which you can read through.

It's actually just the same thing that I discussed in the previous slide.

OK, so a couple more questions.

How does the phase locked power compared to the total ETPs?

So that's pretty interesting.

You see that the phase locked power looks pretty similar.

The total.

Now, I'm not going to make the argument that they're identical, you could also change the color scaling

a little bit to see, you know, this looks a little bit washed out here and this could probably have

a somewhat tighter color scaling.

So they might look a bit even closer to each other with some additional color scaling.

But qualitatively, they they certainly look more like each other than any other two maps on this figure.

And that should not be surprising.

This is the face locked power.

This is the phase locking.

So these are not identical.

These are not redundant features of the data, but they are very similar to each other.

All right.

And then we have let's see, does it make sense to compute the phase locked ICP?

So that's here?

Uh, no, sorry.

The phase locked.

It would be this minus this.

Does it make sense to plot this map minus this map, the way that we plotted this map, minus this map?

And I think the answer is no.

And the reason is that theoretically the non-ferrous locked, it is all zeros.

In theory, this map should be all zeros everywhere in practice, as I mentioned, it's not purely zeros

because there's some just tiny little numerical errors here and there that that collect eventually.

But so the expected value of this map is zero.

So it doesn't really make sense to subtract zero off of this map.

So that's the end of the code for this section.

There still is the problem sets for this section, which are coming up in a few videos from now.

But I just want to point out that I think it's pretty impressive.

We've gone through sixteen hundred lines of code and a lot of this code is actually missing.

So in fact, when you finished writing all of the code in here, it might even be closer to eighteen

hundred lines of code.

That is really impressive.

I hope you're proud of yourself and I hope you feel like you've really learned a lot and improved your

knowledge of time, frequency analysis and neural signal processing.
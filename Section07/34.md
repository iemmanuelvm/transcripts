In this video, we are going to put into practice the concept that I explained in the previous video,

which is down sampling the results after time frequency decomposition.

And just as a reminder, we are not down sampling the data.

We are down sampling the results of complex Morleigh wavelike convolution.

So let's see what we want to do.

Take one channel from the V1 data set and extract time frequency power from 10 hertz to 100 hertz in

42 steps and then average power over all of the trials.

And then we want to do is save two maps.

We want to save the full temporal resolution and a version that is Temperley downsampled to 40 hertz.

And that means one time point each.

Twenty five milliseconds.

That's approximate.

We don't need to be super exact about this.

OK, and then show both the maps in the same figure.

If you haven't already gone through this code, then of course I strongly encourage you to pause the

video here, get through as much of this code as you can and then come back and we can solve it together.

So let's see.

We start by loading in the data set and these are the time points that we want to save.

OK, so I want to start by having a look at time.

Veck one and end.

I want to see what the overall boundaries are.

So this time Vector goes are the data go from minus one half a second to plus one and a half seconds.

But that's the total span of the data.

We don't necessarily need to save all of these time points.

So in fact, what I'm going to do is save from, let's say, minus point two seconds and then insteps

of point to five.

Oops, sorry.

That should be point zero to five otherwise for saving one time point every two hundred and fifty milliseconds.

And so we start at minus two hundred milliseconds and then we go up to let's try going up to one point

two seconds.

OK, so these are the time points that we are going to save after wavelet convolution and then we need

to convert these time points from seconds.

So this is in seconds.

We make a little comment in seconds and then we need to convert that into indices.

So I'm going to call this actually, what I think I will do is scroll down and see if we already use

that.

OK, we don't know.

Sometimes I've already defined or I've already used the variables that I can see how it needs to be

defined.

But I guess in this case, I haven't done that anyway.

So I'll call this idea and that's going to be set to search and time vec and times to save.

So let's run this and see what happens.

OK, error using dispersion and then something, something same column dimension.

So I have discussed this error before and basically, oops, that's not what I meant to do.

Basically the two inputs into D search and both need to be column vectors.

So time vec is a row vector, but then I transpose it so it's a column vector times to save is a row

vector, so it also needs to be transposed.

So now let's run this line and now this is interesting to see.

So who's t idex and time vector.

So the data immediately after Wavelet convolution will have fifteen hundred twenty seven time points,

but we are only going to store fifty seven time points.

So a whole order of magnitude smaller compared to the original time vector.

And then it will be interesting to see when we look at the visualization, whether that makes a difference,

whether that's a real significant amount of downsampling.

OK, so then we specify some parameters.

Now sometimes in the code I will write two separate variables, one that would be called like Min Frex

and one that would be called Max Frex.

Here.

I'm just creating one variable and looking down a bit.

I can see that the variable, this vector Frex is defined from Frech range, the first element to the

second element.

So in fact this is going to be in square brackets.

I'm going to set this to be ten to one hundred because that's what the instructions say.

And I always followed the instructions.

OK, it's not totally true.

I often follow the instructions.

After all, I think I wrote these instructions, so might be a bit weird if I don't follow them myself.

Anyway, here we are specifying the time vector for the wavelet and the frequencies ln data.

This is one of the parameters for convolution.

Now we know that we are going to need to extract the time frequency data from the time points and all

the trials as well.

So I'm going to specify end data to be the size of.

Did come at two times the size of CSD, comma three, and then we can look at this the size of CFD,

in case you've forgotten which dimensions correspond to what it's always channels by time, by trial.

That's the each lab format.

And that's the format that I try to stick to for all of my data.

So we want time points by trials.

That is going to be NP data.

So let's see, here is the end of the kernel and then we have the end of convolution, which is N plus

and minus one.

Hmm.

This is not correct.

This has to be an M and plus minus one.

So there you go.

That seems correct now.

All right.

So let's run all of this and oops, I think I didn't run those two lines.

All right, so here we create the wavelets in a loop.

Now notice I'm creating the wavelets in a loop here and then they're only going to be used later on

in a subsequent loop.

Now, sometimes it makes sense to have the wavelets created in a separate loop from where the rest of

convolution happens.

And sometimes it doesn't really matter in this particular case, because we are only extracting the

time, frequency of results from one single channel, then it actually doesn't make a whole lot of sense

to do it in a separate loop.

We could create the wavelets also in this frequency loop.

However, if you're also looping over channels in this loop, then you could actually have the frequencies

be outside of the wavelets, be created in a separate loop because you don't need to recreate the wavelet

for each channel.

Anyway, here we create the time domain complex Morleigh Wavelet Convolution.

So that was E so we need the complex sine parts.

That's E to the eye two times pi times the frequency and that's going to be Frex of F I times the time

which I think was called w time.

We have time.

Yeah.

So times we have time.

So that's the complex sine wave and then we need the Gaussian.

So that's E to the.

And then we have two ways of specifying the Gaussian and I don't see any variable set up here for either

for the full with maximum or for the number of cycles.

So I guess we are free to do to specify this however we like.

I'm going to use the full with that half maximum formula.

So that was E to the minus minus four times the natural log of two times time, which is called wav

time squared and then divided by the full with that half maximum squared.

So we could specify this for with that half maximum to be changing over frequencies, which is fine.

I think I will just for simplicity, I will hardcoded to be three hundred milliseconds.

So this is going to be a three hundred millisecond forward that have maximum Gaussian, which is constant

for all of the frequencies.

OK, and then we compute Fourier coefficients of the wavelet and normalize.

So let's see.

So here we want the complex moily wavelet and of course this needs to be in points long.

So M plus and minus one point long.

And then here we are, max value normalizing.

So the wavelet in the frequency domain divided by the maximum of the wavelet and that gives us a unit.

Max Naum Wavelet.

So this is Min and the minimum is actually going to be something really close to zero.

So that's going to be a ginormous number if we leave that mistake in there.

Here's a little tip, by the way.

I hope you got that.

OK, anyway, let's see.

Let's run all of this code and.

OK, so that works and, you know, I think it's good to have a look at this thing just to make sure

that we've that all this code actually is correct.

So I'm going to look at the magnitude of Complex Morleigh, Wavelet X, and how about, like, the fourth

frequency?

Doesn't really matter which one we we use.

Remember, this is not for Hertz.

This is the fourth index we can actually see.

So this is 16 and a half hertz, although that doesn't even really tell us that much anyway, because

this is in this is just in frequency indices mostly.

I just want to check two things.

I want to check that the peak of the Gaussian in the frequency domain is one.

And so that means that this line was correct.

And I want to make sure that it actually looks like a Gaussian.

All right.

Now, notice also it's pretty interesting.

We're not actually saving the wavelet inside this loop.

We're only saving the spectrum of the wavelet.

And that's also sensible.

We don't actually need the wavelet.

We just create the wavelet in the time domain where we actually need for convolution is the frequency

representation of the wavelet.

OK, so here we are initializing this time frequency matrix, and here I'm actually initializing as

a cell instead of initializing it as a matrix.

And I would like you to spend a moment to meditate on why that might be the case.

Why do we want to for this particular assignment as initialize the T.F. variable as a cell and not as

a matrix?

OK, so here we compute the free coefficients of the LSP data.

So let's see, this all looks correct.

So we want all the data from one channel for all time points and all trials.

It gets reshaped to a column vector and then we take the fifty the end point fifteen.

All right.

That looks good.

So here we do the actual convolution.

We loop over frequencies again.

We get here the second and third steps of convolution.

And that was the second step is to do the spectral multiplication.

So that's EEG X dot star.

So Element Y's multiplication and then complex Marlay Wavelet X and then we want only for this frequency.

And let me check whether it was the first.

I almost got that wrong.

It's actually in the first dimension, not the second dimension.

OK, so that's the second step of convolution.

And then we want to take the inverse Fourier transform to get back into the time domain.

So and of course, this is too long, this is half the length of the wavelet, too long in the beginning

and half the length of the wavelet, too long at the end.

And then let's see, we will see that this variable as is a vector and it's really, really long.

We actually need to reshape this to time by trials.

And so that is the length of time back by the number of trials, which I'll say is size 63.

Let's see how that was a stupid mistake.

We have to say, what are we reshaping?

Of course we want to reshape the vector as.

There you go.

Now we get fifteen hundred by two hundred matrix.

So that's ten points by trials.

So then we want to compute the power from all of the time points.

So that's the magnitude of X squared.

So this gives us the power and then we average over it the second dimension and then here compute power

from only the downsampled time point.

So I'm actually going to start by copying and pasting.

And now the thing is, we don't want all of the time points.

We want all of the trials and only the time points from t idex.

So let's see.

I think this is all going to work.

All right, very nice.

It worked and it's very fast now we can visualize and let's see.

So this I'm doing as a loop over the two features of the day are the two sort of versions of the time

frequency plot.

They get their own subplot.

And here I say so.

So the contour plot, the frequencies are the same.

This variable is suitable for the loop.

And the thing is that the time vector is different for the these two different loops, these two different

iterations.

So that's why I have this statement here.

So if I equals one, then it's like temp variable is time back.

Otherwise it's the vector that we created above times to save.

OK, and then we need to specify a title.

So I'm going to write Time, Frequency, Power, and actually I think I'll put this in the beginning.

So I'm going to say titles I and then time, frequency, power like this.

OK, so.

Let's have a look and see how this oops and a little typo there.

So pretty remarkable, wouldn't you agree, the full time frequency version and the downsampled time

frequency version look more or less the same.

In fact, let's you know, we have to like look around a little bit to see if we find any differences.

So it's pretty hard to see any differences between them.

And we can see looking at the contents of this cell array, T.F. that they differ quite, quite a bit

there, quite a bit different.

All right.

So that was pretty cool.

We could downsampled the results of time frequency decomposition to 40 hertz here.

The sampling rate was something weird.

It was like seven hundred and sixty two point nine three nine five hertz here.

Here, the sampling rate is approximately 40 hertz.

So question repeat with more downsampling, and how low can the new sampling rate be before the data

become difficult to interpret?

I think I'm going to go a little bit extreme because you remember in the very beginning, I accidentally

wrote two hundred and fifty milliseconds.

So this is totally crazy.

We are down sampling to one data point every two hundred and fifty milliseconds.

So now we need to run all of this again.

And then I'm going to put this in figure two, so we'll be able to compare, let's see, so that's that

and then run and OK, so this is actually quite interesting.

You see that it's a pretty significant amount of downsampling.

I would say this is excessive.

This is too much data loss, information loss.

However, you can still see that the primary you know, the main features of the time frequency analysis

are preserved, even though we now only have a remarkable six data points.

Now, normally, I would not recommend downsampling the data to four hertz to one point every two hundred

and fifty milliseconds.

However, it is pretty interesting to see that in this particular data set, we still can extract the

main features, the most prominent features of the signal at a resolution of four hertz.

Now, I don't think that's generally going to be the case.

I think you will also find other data sets where the dynamics are changing faster.

And so downsampling to two hundred one point every 250 milliseconds is is going to be excessive.

As I mentioned at the end of the previous video, this is a fairly typical resolution for me in practice,

for my analysis.

So I typically do somewhere around 40 to 50 hertz.

So getting one data point every twenty five milliseconds or twenty milliseconds.


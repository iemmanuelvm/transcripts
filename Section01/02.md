 I would like to begin this course with a discussion focused on the claim that all of neuroscience, maybe even all of science, but at least let's stick to neuroscience. All of neuroscience is fundamentally just solving a problem of source separation. So what does this term mean? Source separation? Well, a source is a process or an operation that you measure with your equipment, with your measurement equipment. And the thing is that you have a complex system like the brain, and there are going to be multiple sources that are operating simultaneously. So just to take one simple example, you have visual processing and memory. These are two distinct processes, mental operations, but they are happening at the same time. So you have different sources that are mixed together and then you have things like measurement noise, there's 50Hz or 60Hz line noise that are contaminating your signals if you don't have a perfectly electrically isolated setup. So there are multiple sources of signal, multiple sources of noise, and they all get mixed together in the datasets that we work with in neuroscience. And so the goal is to separate these different sources that are mixed together. I'm going to explain this concept a little bit more using this diagram. This is a diagram that you might have seen before, but I'm going to explain it in a slightly more open, more abstracted way than what you might have previously encountered. So what you're looking at here are three microphones. Imagine these are microphones and let's call these the sensors. We can call these the manifest variables. These are the measurement points. These are the things in the universe that we can actually measure. We can attach numbers to them. So this is now showing microphones. But I would like you to think about this in a more abstract way. Maybe this is three different neurons. Maybe this is three different items on a questionnaire. Let's say you give someone a questionnaire to try to measure some aspect of their personality or their lifestyle choices. So these might be three different questions on the same questionnaire. Maybe you're measuring a time series from an electrode. So these would be three different time points. This would be the, let's say, the voltage value at time point one, the voltage value at time point two and so on. So the idea is that these are reflecting things that we can measure in the universe. So sensors or manifest variables and where do these things come from or where do the data that these measure come from? Well, they're coming from some source. So there is some source that is projecting onto these electrodes or these sensors. So in this case, the way it's drawn here, let's say here's a person and he is talking and his voice is projecting. So the sound waves are being recorded by these three different microphones. But again, I would like you to abstract this a little bit more. So let's say this is a cognitive process that is called attention. Now, we don't actually know what attention is or how to measure attention directly, but what we can do is measure the effects of attention on activity in different brain regions. So maybe this is, you know, three different neurons in the brain. We can measure the activity of the neurons. We can't actually directly measure attention. Okay. But then so here is one source. Maybe this is attention. Maybe this is a person, some, you know, neural computation, maybe this is some personality characteristic. And that personality characteristic is like, quote unquote, projecting onto these different items in the questionnaire. And then we have multiple sources at the same time. So maybe these two are signals and maybe this one is noise that's also contributing to this electrode. So now you can see what the problem is in the real world. We don't have access to these true sources. Sometimes these are called latent constructs in statistics. These might be called latent constructs. These are things in the universe that we are interested in understanding, but we cannot directly measure. So these are kind of invisible. We cannot directly measure attention. We cannot directly measure your personality style. But what we can measure directly are the observables. So neurons or time points and a time series or choices on some exam or and so forth. So you can start to see what the problem is. If we want to isolate this one source, that's not possible to isolate just from measuring, let's say this one electrode. And that's because this one sensor, this manifest variable, contains a mixture of. Multiple sources, some of which are signals and some of which are noise. Okay. So you can probably guess where this is going. And the idea is that we want to come up with some way of weighting these three different sensors such that the weighted combination. So some number times this plus some number times this, plus some number times this, that weighted combination is going to give us some estimate of this reconstructed source. So these are the things that we can measure directly. These are the things that we cannot measure directly, but we would like to understand. And the idea is that we make some assumptions, we do some mathematical calculations, and we come up with these kinds of weights that we hope will get us to something, you know, some kind of component, some signal that we extract from these data that is more or less similar to the true underlying source. Okay. And then maybe we are also interested in reconstructing this one. You know, I drew them differently with slightly different shapes to show that this reconstruction is not necessarily perfect based on what actually happened in the brain or in the universe. And then perhaps this one is noise. So we don't even want to reconstruct this. We want to suppress this source so that its activity does not propagate from the sensors to the components. Or sometimes these are also called sources. I put sources in quotes here because it gets the terminology gets a little bit confusing because these are often also called sources. So these are like recovered sources that we estimate. Okay. So I hope that this diagram makes sense. Again, the idea is that just looking at the manifest variables by themselves is insufficient to isolate and therefore understand these true sources. Instead, we take multiple measurements. Maybe it's over time, maybe it's over space, maybe it's different kinds of tests. And then we combine them in a smart way, hopefully smart way to be able to separate out the different sources to unmix the mixing that happens here. All right. So how do we do this? How do we go about isolating these different processes? There are actually many ways that we can do this. So one is anatomical source separation. So for example, you say, well, the brain is really complicated. I can't possibly hope to understand all of it, so I'm just going to study one part of the brain based on anatomy. So let's say I'm just going to study the amygdala. I know that the amygdala is only one small piece of the brain, but I'm going to just study the amygdala and not anything else. So that is anatomical source separation. We can also have cognitive source separation. And here you say, well, you know, human beings are capable of many cognitive processes and I can't hope to understand all of them. They all get mixed together. So I'm going to design some clever experiments that will allow me to study, let's say, short term memory without studying long term memory, without studying attention, without studying language production. So I'm using an experiment to isolate a single cognitive source. Okay, so these are just some examples. What I'm actually going to focus on in this course is statistical source separation, where the idea is that we are using the statistical characteristics of the data to perform this source separation. And by statistics here, I'm not referring to inferential statistics like P values and F values. I'm referring to the descriptive statistics like variance covariance spectral features and so on. And once you start talking about statistical source separation that leads to temporal or spectral source separation and spatial source separation. Now statistical source separation is really all about applying filters to the data. So what are filters? Filters are an important concept to understand because in fact, basically this entire course is all about source separation via temporal filtering or spectral filtering. And then there's also spatial filtering. And I have a whole separate course called dimension reduction and source separation. That course is all about spatial filtering. So what does filtering mean? What does it mean to filter data? Well, filtering means to take the observed data, the measured data and combine a bunch of the data points. So add together a bunch of the data points in a way that they get weighted by some function. And this is a function that you get to define. You get to pick this function based on some, you know, optimizing some. Statistical characteristics. So, for example, here we see a broadband signal. It is non temporally filtered and here we see the filtered version of this signal. And so how do we do this? How do we get this filtered signal from this broadband signal? Well, we set each data point in the filtered signal to be a weighted combination of many time points in the original signal. So we have all of these time points here, and they get weighted according to this function here, which is called a kernel. And essentially what that means is we take this data point times this point in the kernel plus this data point, times this point in the kernel plus and so on. And we do all of these multiplications and we sum up all of those and that gives us a single data point and that's the resulting data point in this filtered signal. So temporal filtering is just taking all of the time points, weighting them together and summing them. And then let me go back to this diagram. So then the idea is that the filter defines these. I'll draw it like this. So each one of these lines here reflects the weight or the filter kernel value at each time point in the signal. So notice we have a lot of time points here and we are summing them together in a weighted fashion. All right. So that is for temporal filtering. Spatial filtering is a really similar concept, except instead of taking the time series from one single electrode and weighting time points over time, we are computing the spatial filter at each time point. So we have each individual channel multiplied by a weight and then we sum up over all the channels. So this is happening over time for one channel and the spatial filtering is happening over space at one time point. So I hope you see that these are kind of just two sides of the same operation. All right. In this course, as I mentioned, we are going to be focusing on temporal filtering. So this course is all about source separation via temporal filtering. Temporal filtering is almost the same thing as spectral filtering. So I want to talk a little bit about spectral filtering, spectral source separation, and importantly, the key underlying assumption for spectral separation to be a valid operation. If this assumption does not hold in your data, then spectral separation or temporal separation is not going to be a useful approach. So what you're looking at here is a power spectrum of a signal. So you see the amount of energy in the signal at a range of frequencies. So these are low frequencies. This indicates like slow fluctuations in the signal. These are higher fluctuations. This reflects faster fluctuations in the signal. If you are not comfortable with looking at a power spectrum like this, then don't worry. That is basically one of the main goals of this course, is to figure out how to produce and interpret a plot that looks like this. Okay, so now let's imagine. So this is simulated data. I just generated these data. So because I generated the data, I know what are the different sources that are contained in the data. So let's say I told you that this was the two sources that went into creating these data. We have a signal and we have a noise. So notice the signal has zero energy at all frequencies, except for this range from ten to like 18Hz or so where it has a lot of energy. And then we have the noise, which has positive energy everywhere, and it has this kind of downward slope thing. It's called one over F, So the energy is decreasing with increasing frequency. Now the question is, can we separate the noise from the signal here? Is it possible to separate noise from signal here, given that this is a mixed signal and given that this is the true underlying configuration of sources? The answer is kind of. So we cannot actually do a perfect source separation in this case. And the reason why we cannot do a perfect source separation using spectral methods is because the signal and noise are mixed here. They are mixed in the spectrum. And once something is mixed in the spectrum, it is totally impossible to separate it using purely spectral methods. Now there are other methods that are spatial methods that would allow you to better separate this cyan signal from this blue noise. But in this course we are focusing on spectral separation. So our conclusion here, based on what we know about the ground truth is that source separation is going to be fairly good, but not perfect. Again, it's going to be fairly good because when we just isolate the signal in the spectrum from 10 to 18Hz, that's going to be mostly signal, but it's also going to contain a little bit of noise corresponding to some overlapping energy down here. So this is kind of the main goal of this course to learn various techniques. We're going to learn quite a few techniques for separating sources based on the assumption that those sources have a different signature. They have different representation in the spectrum like this.
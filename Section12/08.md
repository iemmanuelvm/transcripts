 Now, I have to warn you, this is probably the most challenging project of the entire course, you will need to integrate things that you learned across at least three different sections of this course. So simulating data time, frequency analysis by way of the coalition and inferential statistics, including permutation, testing and cluster correction. So the goal of this project. Oh, and it's even worse because I'm not giving you a single line of starter code. I'm not even telling you the names of the variables that you should use. All I'm giving you is a couple of instructions about the data set, about the noise characteristics, the analysis and the statistics. OK, so here is what you are going to do. Generate two signals and each signal has two components. Two features the signal they both have to be time, frequency features and they both have to be non phase locked. Now, you want to generate these two signals and I'll show you what these look like in a minute. You want to generate these two signals so that there are at least some differences between him calling conditions, but between the two signals. And so then the idea is signal one plus trial, unique noise goes into condition one and signal two plus trial. Unique noise goes into condition to say you can do one hundred trials per condition. The noise should be generated on each trial. So it's trial, unique noise and you should make this one over F noise. So there's a few different ways to generate one over F noise and you can pick which way you prefer. Once you have generated that data, you want to apply a time frequency analysis either through wavelet convolution. And that's what I recommend you do as well. And I'm not telling you which parameters to use for the wavelet convolution so you can pick which parameters you think are appropriate. Now this is what the RPS look like. So the event related potential to trial as our time domain trial average and you really don't see much. So there is kind of some action here maybe. But you know, these are phase locked features of the signal. So in fact, the time domain is not really the right way to investigate or to to understand the characteristics of these features. Instead, the time frequency analysis is going to give you a lot of insight. So here you see the trial average plots, time frequency plots for condition one and condition two. So here you see what I was talking about. So you have each signal has two features. So this is one feature and this is the other feature for signal one, which becomes condition one and then for signal two. And because they are non phase locked, you see them in the time frequency plane. You don't see them in the time domain plot where you can also see in these time frequency power plots is the one over F noise feature. So you can see that with increasing frequency, the color is getting more and more towards cold colors and more and more blue. And that reflects that the amplitude of the noise is decreasing with increasing frequency. So once you've done that, so that's kind of the first major goal of this project, is to just get this far. Now you want to do statistics, and the idea is to ask whether this condition is statistically significantly different from this condition. And you want to do this pixel wise. So is this pixel different from this pixel? Is this pixel driven from this pixel, blah, blah, blah and so on? So you want to compare these two conditions map wise? For this reason, you want to make sure when you are simulating the data that at least some features between the two conditions are different now, you can make that a little more extreme by having, you know, this feature here and this feature be all the way up here. So they're completely different. I went about this in a slightly more subtle way. So you can see this feature of the data. Looks like it's at 15 hertz. And here for this condition, it's a little bit lower. Maybe this is 14 hertz and same thing here. This looks like it's maybe six hertz and this is maybe seven hertz or something. So they differ just a little bit. OK, so you can compare these using permutation testing, MapQuest, permutation testing. Then you want to generate a plot that looks something like this. Here you see the difference map. So this is literally the difference between this map and this map. So you see there's some red and some blue in there and that whether you know which way is red and blue depends on whether you're subtracting one from two or two from one. So this is the raw difference map. This is the Z maps are relative to the null hypothesis that you empirically generate through permutation testing. So it's interesting to see that there are features in the Z map that are not really apparent just from the raw difference map, and that is really attributable to the noise. So when you have this different map, you are scaling by the denominator so that this different map is the numerator and then the denominator is the variance across the different permutation iterations. And of course that variance can be pixel or time frequency point specific. Then you apply a P value threshold. You can use a P value of zero point zero five. And when you apply the P value threshold, you'll get to a map that looks like this or this. This is so what you see here is this map. But then with all of these significant regions outlined here now, there's something very interesting that's happening here, which is that the clusters are not really the same size for the positive and negative sets of pixels. So therefore, what you want to do is actually apply the cluster correction separately. So you come up with a separate cluster thresholds for the positive features. So both positive and negative, I'm referring to the color on this map. So positive features versus the negative features. And again, you know, whether it's positive or negative, it's fairly arbitrary. That's really just what they are saying, two minus one or one minus two. But regardless, you want to come up with two separate cluster thresholds for these two things. And that's probably to avoid a situation like this where it looks like there is one single cluster that's actually encompassing both blue and red. So these go in the opposite directions, but they they fall into exactly the same cluster. OK, so now what you're going to generate is the distribution of cluster sizes under the null hypothesis, and you're going to get two distributions, one for the same column, positive and negative clusters. But you understand what I mean. It's that cluster is coming from the positive features and clusters coming from the negative features. So you can see these two distributions look very similar, not identical, but very similar. So the thresholds for these two are going to also be similar. You know, I think based on this visually, it's probably somewhere around two thousand. This actually should say time, frequency points or maybe pixels would be better. But you want the flexibility to have slightly different thresholds for the positive and negative that will bring you to this final result. So here you see again this difference plot. But now this is with cluster correction in addition to the pixel correction. So we are now correcting for multiple comparisons. And it's interesting to see that now these two features of the data of the map have segregated into two clusters. This is not one cluster anymore. You can see there's a line here. So these are two separate clusters. This one happened to be non statistically significant. So we get three regions of statistical significance in this particular iteration. All right. So good luck working your way through this project. Like I said in the beginning of this video, this is a really challenging project. This is quite difficult. So, you know, take a deep breath, take your time and don't give up in the next video. I will walk you through my solutions.